<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html><head><meta http-equiv="Content-Type" content="text/html;charset=UTF-8">
<title>OpenNN: OpenNN::GradientDescent Class Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css">
<link href="doxygen.css" rel="stylesheet" type="text/css">
</head><body>
<!-- Generated by Doxygen 1.5.9 -->
<div class="navigation" id="top">
  <div class="tabs">
    <ul>
      <li><a href="index.html"><span>Main&nbsp;Page</span></a></li>
      <li><a href="pages.html"><span>Related&nbsp;Pages</span></a></li>
      <li class="current"><a href="annotated.html"><span>Classes</span></a></li>
      <li><a href="files.html"><span>Files</span></a></li>
    </ul>
  </div>
  <div class="tabs">
    <ul>
      <li><a href="annotated.html"><span>Class&nbsp;List</span></a></li>
      <li><a href="hierarchy.html"><span>Class&nbsp;Hierarchy</span></a></li>
      <li><a href="functions.html"><span>Class&nbsp;Members</span></a></li>
    </ul>
  </div>
  <div class="navpath"><b>OpenNN</b>::<a class="el" href="class_open_n_n_1_1_gradient_descent.html">GradientDescent</a>
  </div>
</div>
<div class="contents">
<h1>OpenNN::GradientDescent Class Reference</h1><!-- doxytag: class="OpenNN::GradientDescent" --><!-- doxytag: inherits="OpenNN::TrainingAlgorithm" --><code>#include &lt;<a class="el" href="gradient__descent_8h_source.html">gradient_descent.h</a>&gt;</code>
<p>
<div class="dynheader">
Inheritance diagram for OpenNN::GradientDescent:</div>
<div class="dynsection">

<p><center><img src="class_open_n_n_1_1_gradient_descent.png" usemap="#OpenNN::GradientDescent_map" border="0" alt=""></center>
<map name="OpenNN::GradientDescent_map">
<area href="class_open_n_n_1_1_training_algorithm.html" alt="OpenNN::TrainingAlgorithm" shape="rect" coords="0,0,166,24">
</map>
</div>

<p>
<a href="class_open_n_n_1_1_gradient_descent-members.html">List of all members.</a><table border="0" cellpadding="0" cellspacing="0">
<tr><td></td></tr>
<tr><td colspan="2"><br><h2>Classes</h2></td></tr>
<tr><td class="memItemLeft" nowrap align="right" valign="top">struct &nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="struct_open_n_n_1_1_gradient_descent_1_1_gradient_descent_results.html">GradientDescentResults</a></td></tr>

<tr><td colspan="2"><br><h2>Public Member Functions</h2></td></tr>
<tr><td class="memItemLeft" nowrap align="right" valign="top">&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_gradient_descent.html#d4c53dcaa3371726975a35df1978629c">GradientDescent</a> (void)</td></tr>

<tr><td class="memItemLeft" nowrap align="right" valign="top">&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_gradient_descent.html#dc19d4061896e1bef6c91afb5addd17d">GradientDescent</a> (<a class="el" href="class_open_n_n_1_1_performance_functional.html">PerformanceFunctional</a> *)</td></tr>

<tr><td class="memItemLeft" nowrap align="right" valign="top">&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_gradient_descent.html#40f5385a356150abef61dfbe282a5e74">GradientDescent</a> (TiXmlElement *)</td></tr>

<tr><td class="memItemLeft" nowrap align="right" valign="top">virtual&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_gradient_descent.html#681a0ffccb2b004a1406dfe500addd8a">~GradientDescent</a> (void)</td></tr>

<tr><td class="memItemLeft" nowrap align="right" valign="top">const <a class="el" href="class_open_n_n_1_1_training_rate_algorithm.html">TrainingRateAlgorithm</a> &amp;&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_gradient_descent.html#f56fbbae486b692bb84d4e0da4b0f0f8">get_training_rate_algorithm</a> (void) const </td></tr>

<tr><td class="memItemLeft" nowrap align="right" valign="top"><a class="el" href="class_open_n_n_1_1_training_rate_algorithm.html">TrainingRateAlgorithm</a> *&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_gradient_descent.html#dc28271b363aad570eaa0a3ab33a4db0">get_training_rate_algorithm_pointer</a> (void)</td></tr>

<tr><td class="memItemLeft" nowrap align="right" valign="top">const double &amp;&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_gradient_descent.html#8c79c02292682be10175dd88e49df847">get_warning_parameters_norm</a> (void) const </td></tr>

<tr><td class="memItemLeft" nowrap align="right" valign="top">const double &amp;&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_gradient_descent.html#d670d10c866f2db246824998bc58b103">get_warning_gradient_norm</a> (void) const </td></tr>

<tr><td class="memItemLeft" nowrap align="right" valign="top">const double &amp;&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_gradient_descent.html#cff823bf71a1fbc7df17939ddab9912b">get_warning_training_rate</a> (void) const </td></tr>

<tr><td class="memItemLeft" nowrap align="right" valign="top">const double &amp;&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_gradient_descent.html#abf083d521b38d878afc58b7cf744ad9">get_error_parameters_norm</a> (void) const </td></tr>

<tr><td class="memItemLeft" nowrap align="right" valign="top">const double &amp;&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_gradient_descent.html#5d28f85181e21d4c074bb1871206fb5c">get_error_gradient_norm</a> (void) const </td></tr>

<tr><td class="memItemLeft" nowrap align="right" valign="top">const double &amp;&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_gradient_descent.html#43c43e8fa25ece6586133dbbaf5403c4">get_error_training_rate</a> (void) const </td></tr>

<tr><td class="memItemLeft" nowrap align="right" valign="top">const double &amp;&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_gradient_descent.html#977e8321cd4b1027a2d47bd10bcf47ca">get_minimum_parameters_increment_norm</a> (void) const </td></tr>

<tr><td class="memItemLeft" nowrap align="right" valign="top">const double &amp;&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_gradient_descent.html#460c313eb05a471addf301f8691827fb">get_minimum_performance_increase</a> (void) const </td></tr>

<tr><td class="memItemLeft" nowrap align="right" valign="top">const double &amp;&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_gradient_descent.html#b2a6b927e38a1dfe173bb866f27d2b96">get_performance_goal</a> (void) const </td></tr>

<tr><td class="memItemLeft" nowrap align="right" valign="top">const double &amp;&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_gradient_descent.html#096b7ba798dd03e82670ea5263e194b5">get_gradient_norm_goal</a> (void) const </td></tr>

<tr><td class="memItemLeft" nowrap align="right" valign="top">const unsigned int &amp;&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_gradient_descent.html#ef2c9be7d3ae74c843117414c4588be7">get_maximum_generalization_evaluation_decreases</a> (void) const </td></tr>

<tr><td class="memItemLeft" nowrap align="right" valign="top">const unsigned int &amp;&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_gradient_descent.html#7d2670b88ec8ba50df21b9a0763b5d04">get_maximum_epochs_number</a> (void) const </td></tr>

<tr><td class="memItemLeft" nowrap align="right" valign="top">const double &amp;&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_gradient_descent.html#e8fe1dd09d144f2ece993cf9338f5830">get_maximum_time</a> (void) const </td></tr>

<tr><td class="memItemLeft" nowrap align="right" valign="top">const bool &amp;&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_gradient_descent.html#0adf17968a23452099c3a3af7788de07">get_reserve_parameters_history</a> (void) const </td></tr>

<tr><td class="memItemLeft" nowrap align="right" valign="top">const bool &amp;&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_gradient_descent.html#a34afdc9f24b77546a0417c2136fa005">get_reserve_parameters_norm_history</a> (void) const </td></tr>

<tr><td class="memItemLeft" nowrap align="right" valign="top">const bool &amp;&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_gradient_descent.html#4a117b0b0bb4eb10d78d397aaa2dc2ff">get_reserve_evaluation_history</a> (void) const </td></tr>

<tr><td class="memItemLeft" nowrap align="right" valign="top">const bool &amp;&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_gradient_descent.html#6c78744fa192aee34b9bbe2fd7419ed1">get_reserve_gradient_history</a> (void) const </td></tr>

<tr><td class="memItemLeft" nowrap align="right" valign="top">const bool &amp;&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_gradient_descent.html#b0eef1b50c1003bf779b3f7658e0ac8f">get_reserve_gradient_norm_history</a> (void) const </td></tr>

<tr><td class="memItemLeft" nowrap align="right" valign="top">const bool &amp;&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_gradient_descent.html#e8eda1d13c5f4fd1aca52e9971336730">get_reserve_generalization_evaluation_history</a> (void) const </td></tr>

<tr><td class="memItemLeft" nowrap align="right" valign="top">const bool &amp;&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_gradient_descent.html#003543fe0d6f7a5d1bfae52837b19d8a">get_reserve_training_direction_history</a> (void) const </td></tr>

<tr><td class="memItemLeft" nowrap align="right" valign="top">const bool &amp;&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_gradient_descent.html#038114122cf181642076b7e76e494abc">get_reserve_training_rate_history</a> (void) const </td></tr>

<tr><td class="memItemLeft" nowrap align="right" valign="top">const bool &amp;&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_gradient_descent.html#b1721d85c7aab1ee42ee55ec24e296c5">get_reserve_elapsed_time_history</a> (void) const </td></tr>

<tr><td class="memItemLeft" nowrap align="right" valign="top">const unsigned int &amp;&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_gradient_descent.html#0598d1a344e0b4a0589998c3402ff22a">get_display_period</a> (void) const </td></tr>

<tr><td class="memItemLeft" nowrap align="right" valign="top">void&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_gradient_descent.html#3e29b2699a9b3b4eee80d17e493a3c6d">set_training_rate_algorithm</a> (const <a class="el" href="class_open_n_n_1_1_training_rate_algorithm.html">TrainingRateAlgorithm</a> &amp;)</td></tr>

<tr><td class="memItemLeft" nowrap align="right" valign="top">void&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_gradient_descent.html#de5a4d5ec6b048ca182ba2e17e182055">set_default</a> (void)</td></tr>

<tr><td class="memItemLeft" nowrap align="right" valign="top">void&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_gradient_descent.html#8b7860afbf36d0aac837091f35a63e84">set_reserve_all_training_history</a> (const bool &amp;)</td></tr>

<tr><td class="memItemLeft" nowrap align="right" valign="top">void&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_gradient_descent.html#c525a49652ff909ec76613b721e33739">set_warning_parameters_norm</a> (const double &amp;)</td></tr>

<tr><td class="memItemLeft" nowrap align="right" valign="top">void&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_gradient_descent.html#c7f1c7a84ab5067aa2550b3e36537c21">set_warning_gradient_norm</a> (const double &amp;)</td></tr>

<tr><td class="memItemLeft" nowrap align="right" valign="top">void&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_gradient_descent.html#9359ff2faa9eab75167a5867381a6b34">set_warning_training_rate</a> (const double &amp;)</td></tr>

<tr><td class="memItemLeft" nowrap align="right" valign="top">void&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_gradient_descent.html#2625e879f726b1501ce33ab5710bbb88">set_error_parameters_norm</a> (const double &amp;)</td></tr>

<tr><td class="memItemLeft" nowrap align="right" valign="top">void&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_gradient_descent.html#e8d1a6991a7a735195ed65b15315d233">set_error_gradient_norm</a> (const double &amp;)</td></tr>

<tr><td class="memItemLeft" nowrap align="right" valign="top">void&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_gradient_descent.html#1d3b83e0e926af808f2d6a3b2bde050c">set_error_training_rate</a> (const double &amp;)</td></tr>

<tr><td class="memItemLeft" nowrap align="right" valign="top">void&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_gradient_descent.html#6ebdcab74360e712408d2b5f734cc2d8">set_minimum_parameters_increment_norm</a> (const double &amp;)</td></tr>

<tr><td class="memItemLeft" nowrap align="right" valign="top">void&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_gradient_descent.html#a1a12c07c1db1420bb59f58c3a17fea4">set_minimum_performance_increase</a> (const double &amp;)</td></tr>

<tr><td class="memItemLeft" nowrap align="right" valign="top">void&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_gradient_descent.html#8e10381a376476d92e3c96a56a7cf257">set_performance_goal</a> (const double &amp;)</td></tr>

<tr><td class="memItemLeft" nowrap align="right" valign="top">void&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_gradient_descent.html#1ad68485a9faa5a39c134b4177551c48">set_gradient_norm_goal</a> (const double &amp;)</td></tr>

<tr><td class="memItemLeft" nowrap align="right" valign="top">void&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_gradient_descent.html#de9212832bd5d3a23f751d830f153e8a">set_maximum_generalization_evaluation_decreases</a> (const unsigned int &amp;)</td></tr>

<tr><td class="memItemLeft" nowrap align="right" valign="top">void&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_gradient_descent.html#f66661bb709e3b68c748a4307e8bee45">set_maximum_epochs_number</a> (const unsigned int &amp;)</td></tr>

<tr><td class="memItemLeft" nowrap align="right" valign="top">void&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_gradient_descent.html#79b6c48c3f392baeaabff840d22cb5b3">set_maximum_time</a> (const double &amp;)</td></tr>

<tr><td class="memItemLeft" nowrap align="right" valign="top">void&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_gradient_descent.html#3d828a36bf0df6069f04d5c7ac2eeb51">set_reserve_parameters_history</a> (const bool &amp;)</td></tr>

<tr><td class="memItemLeft" nowrap align="right" valign="top">void&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_gradient_descent.html#daf7e1540cc81138bd541bee36269464">set_reserve_parameters_norm_history</a> (const bool &amp;)</td></tr>

<tr><td class="memItemLeft" nowrap align="right" valign="top">void&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_gradient_descent.html#aa21d82bbe0fd3bb31295e97da9593c9">set_reserve_evaluation_history</a> (const bool &amp;)</td></tr>

<tr><td class="memItemLeft" nowrap align="right" valign="top">void&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_gradient_descent.html#8ec7e29c6611ca1d0e3d03d543d62ce7">set_reserve_gradient_history</a> (const bool &amp;)</td></tr>

<tr><td class="memItemLeft" nowrap align="right" valign="top">void&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_gradient_descent.html#c35bd72977a353a1edbc01178c1965e1">set_reserve_gradient_norm_history</a> (const bool &amp;)</td></tr>

<tr><td class="memItemLeft" nowrap align="right" valign="top">void&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_gradient_descent.html#05e2aedc5889583d5cfcdd3e69ea24ce">set_reserve_generalization_evaluation_history</a> (const bool &amp;)</td></tr>

<tr><td class="memItemLeft" nowrap align="right" valign="top">void&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_gradient_descent.html#9c2553d655440601e779a3d093de593c">set_reserve_training_direction_history</a> (const bool &amp;)</td></tr>

<tr><td class="memItemLeft" nowrap align="right" valign="top">void&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_gradient_descent.html#7adc9d5149d9599aa3df9d254974d503">set_reserve_training_rate_history</a> (const bool &amp;)</td></tr>

<tr><td class="memItemLeft" nowrap align="right" valign="top">void&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_gradient_descent.html#8e98003d637460b1a6f57cc5063b77d8">set_reserve_elapsed_time_history</a> (const bool &amp;)</td></tr>

<tr><td class="memItemLeft" nowrap align="right" valign="top">void&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_gradient_descent.html#a296ed469c45fd0db6a301f120c3b257">set_display_period</a> (const unsigned int &amp;)</td></tr>

<tr><td class="memItemLeft" nowrap align="right" valign="top"><a class="el" href="class_open_n_n_1_1_vector.html">Vector</a>&lt; double &gt;&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_gradient_descent.html#c77548469088ea0f6256a531aff79cd1">calculate_training_direction</a> (const <a class="el" href="class_open_n_n_1_1_vector.html">Vector</a>&lt; double &gt; &amp;) const </td></tr>

<tr><td class="memItemLeft" nowrap align="right" valign="top"><a class="el" href="struct_open_n_n_1_1_gradient_descent_1_1_gradient_descent_results.html">GradientDescentResults</a> *&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_gradient_descent.html#35748714df5dcc4f03c642084b5d16cb">perform_training</a> (void)</td></tr>

<tr><td class="memItemLeft" nowrap align="right" valign="top">std::string&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_gradient_descent.html#9feb1b4939513b37febe25ed0adbba2f">write_training_algorithm_type</a> (void) const </td></tr>

<tr><td class="memItemLeft" nowrap align="right" valign="top">TiXmlElement *&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_gradient_descent.html#2d790ddb6884db0ec6d0a7fe7ebd6768">to_XML</a> (void) const </td></tr>

<tr><td class="memItemLeft" nowrap align="right" valign="top">void&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_gradient_descent.html#ee5b6a70c80e41df05f583193ec52045">from_XML</a> (TiXmlElement *)</td></tr>

</table>
<hr><a name="_details"></a><h2>Detailed Description</h2>
This concrete class represents the gradient descent training algorithm for a performance functional of a multilayer perceptron. 
<p>Definition at line <a class="el" href="gradient__descent_8h_source.html#l00033">33</a> of file <a class="el" href="gradient__descent_8h_source.html">gradient_descent.h</a>.</p>
<hr><h2>Constructor &amp; Destructor Documentation</h2>
<a class="anchor" name="d4c53dcaa3371726975a35df1978629c"></a><!-- doxytag: member="OpenNN::GradientDescent::GradientDescent" ref="d4c53dcaa3371726975a35df1978629c" args="(void)" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">OpenNN::GradientDescent::GradientDescent           </td>
          <td>(</td>
          <td class="paramtype">void&nbsp;</td>
          <td class="paramname">          </td>
          <td>&nbsp;)&nbsp;</td>
          <td><code> [explicit]</code></td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
Default constructor. It creates a gradient descent training algorithm not associated to any performance functional object. It also initializes the class members to their default values. 
<p>Definition at line <a class="el" href="gradient__descent_8cpp_source.html#l00041">41</a> of file <a class="el" href="gradient__descent_8cpp_source.html">gradient_descent.cpp</a>.</p>

</div>
</div><p>
<a class="anchor" name="dc19d4061896e1bef6c91afb5addd17d"></a><!-- doxytag: member="OpenNN::GradientDescent::GradientDescent" ref="dc19d4061896e1bef6c91afb5addd17d" args="(PerformanceFunctional *)" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">OpenNN::GradientDescent::GradientDescent           </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="class_open_n_n_1_1_performance_functional.html">PerformanceFunctional</a> *&nbsp;</td>
          <td class="paramname"> <em>new_performance_functional_pointer</em>          </td>
          <td>&nbsp;)&nbsp;</td>
          <td><code> [explicit]</code></td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
Performance functional constructor. It creates a gradient descent training algorithm associated to a performance functional. It also initializes the class members to their default values. <dl compact><dt><b>Parameters:</b></dt><dd>
  <table border="0" cellspacing="2" cellpadding="0">
    <tr><td valign="top"></td><td valign="top"><em>new_performance_functional_pointer</em>&nbsp;</td><td>Pointer to a performance functional object. </td></tr>
  </table>
</dl>

<p>Definition at line <a class="el" href="gradient__descent_8cpp_source.html#l00055">55</a> of file <a class="el" href="gradient__descent_8cpp_source.html">gradient_descent.cpp</a>.</p>

</div>
</div><p>
<a class="anchor" name="40f5385a356150abef61dfbe282a5e74"></a><!-- doxytag: member="OpenNN::GradientDescent::GradientDescent" ref="40f5385a356150abef61dfbe282a5e74" args="(TiXmlElement *)" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">OpenNN::GradientDescent::GradientDescent           </td>
          <td>(</td>
          <td class="paramtype">TiXmlElement *&nbsp;</td>
          <td class="paramname"> <em>gradient_descent_element</em>          </td>
          <td>&nbsp;)&nbsp;</td>
          <td><code> [explicit]</code></td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
XML constructor. It creates a gradient descent training algorithm not associated to any performance functional object. It also loads the class members from a XML element. <dl compact><dt><b>Parameters:</b></dt><dd>
  <table border="0" cellspacing="2" cellpadding="0">
    <tr><td valign="top"></td><td valign="top"><em>gradient_descent_element</em>&nbsp;</td><td>Tiny XML element with the members of a gradient descent object. </td></tr>
  </table>
</dl>

<p>Definition at line <a class="el" href="gradient__descent_8cpp_source.html#l00071">71</a> of file <a class="el" href="gradient__descent_8cpp_source.html">gradient_descent.cpp</a>.</p>

</div>
</div><p>
<a class="anchor" name="681a0ffccb2b004a1406dfe500addd8a"></a><!-- doxytag: member="OpenNN::GradientDescent::~GradientDescent" ref="681a0ffccb2b004a1406dfe500addd8a" args="(void)" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">OpenNN::GradientDescent::~GradientDescent           </td>
          <td>(</td>
          <td class="paramtype">void&nbsp;</td>
          <td class="paramname">          </td>
          <td>&nbsp;)&nbsp;</td>
          <td><code> [virtual]</code></td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
Destructor. 
<p>

<p>Definition at line <a class="el" href="gradient__descent_8cpp_source.html#l00083">83</a> of file <a class="el" href="gradient__descent_8cpp_source.html">gradient_descent.cpp</a>.</p>

</div>
</div><p>
<hr><h2>Member Function Documentation</h2>
<a class="anchor" name="f56fbbae486b692bb84d4e0da4b0f0f8"></a><!-- doxytag: member="OpenNN::GradientDescent::get_training_rate_algorithm" ref="f56fbbae486b692bb84d4e0da4b0f0f8" args="(void) const " -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">const <a class="el" href="class_open_n_n_1_1_training_rate_algorithm.html">TrainingRateAlgorithm</a> &amp; OpenNN::GradientDescent::get_training_rate_algorithm           </td>
          <td>(</td>
          <td class="paramtype">void&nbsp;</td>
          <td class="paramname">          </td>
          <td>&nbsp;)&nbsp;</td>
          <td> const</td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
This method returns a constant reference to the training rate algorithm object inside the gradient descent object. 
<p>

<p>Definition at line <a class="el" href="gradient__descent_8cpp_source.html#l00094">94</a> of file <a class="el" href="gradient__descent_8cpp_source.html">gradient_descent.cpp</a>.</p>

</div>
</div><p>
<a class="anchor" name="dc28271b363aad570eaa0a3ab33a4db0"></a><!-- doxytag: member="OpenNN::GradientDescent::get_training_rate_algorithm_pointer" ref="dc28271b363aad570eaa0a3ab33a4db0" args="(void)" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="class_open_n_n_1_1_training_rate_algorithm.html">TrainingRateAlgorithm</a> * OpenNN::GradientDescent::get_training_rate_algorithm_pointer           </td>
          <td>(</td>
          <td class="paramtype">void&nbsp;</td>
          <td class="paramname">          </td>
          <td>&nbsp;)&nbsp;</td>
          <td></td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
This method returns a pointer to the training rate algorithm object inside the gradient descent object. 
<p>

<p>Definition at line <a class="el" href="gradient__descent_8cpp_source.html#l00104">104</a> of file <a class="el" href="gradient__descent_8cpp_source.html">gradient_descent.cpp</a>.</p>

</div>
</div><p>
<a class="anchor" name="8c79c02292682be10175dd88e49df847"></a><!-- doxytag: member="OpenNN::GradientDescent::get_warning_parameters_norm" ref="8c79c02292682be10175dd88e49df847" args="(void) const " -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">const double &amp; OpenNN::GradientDescent::get_warning_parameters_norm           </td>
          <td>(</td>
          <td class="paramtype">void&nbsp;</td>
          <td class="paramname">          </td>
          <td>&nbsp;)&nbsp;</td>
          <td> const</td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
This method returns the minimum value for the norm of the parameters vector at wich a warning message is written to the screen. 
<p>Definition at line <a class="el" href="gradient__descent_8cpp_source.html#l00115">115</a> of file <a class="el" href="gradient__descent_8cpp_source.html">gradient_descent.cpp</a>.</p>

</div>
</div><p>
<a class="anchor" name="d670d10c866f2db246824998bc58b103"></a><!-- doxytag: member="OpenNN::GradientDescent::get_warning_gradient_norm" ref="d670d10c866f2db246824998bc58b103" args="(void) const " -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">const double &amp; OpenNN::GradientDescent::get_warning_gradient_norm           </td>
          <td>(</td>
          <td class="paramtype">void&nbsp;</td>
          <td class="paramname">          </td>
          <td>&nbsp;)&nbsp;</td>
          <td> const</td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
This method returns the minimum value for the norm of the gradient vector at wich a warning message is written to the screen. 
<p>Definition at line <a class="el" href="gradient__descent_8cpp_source.html#l00126">126</a> of file <a class="el" href="gradient__descent_8cpp_source.html">gradient_descent.cpp</a>.</p>

</div>
</div><p>
<a class="anchor" name="cff823bf71a1fbc7df17939ddab9912b"></a><!-- doxytag: member="OpenNN::GradientDescent::get_warning_training_rate" ref="cff823bf71a1fbc7df17939ddab9912b" args="(void) const " -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">const double &amp; OpenNN::GradientDescent::get_warning_training_rate           </td>
          <td>(</td>
          <td class="paramtype">void&nbsp;</td>
          <td class="paramname">          </td>
          <td>&nbsp;)&nbsp;</td>
          <td> const</td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
This method returns the training rate value at wich a warning message is written to the screen during line minimization. 
<p>Definition at line <a class="el" href="gradient__descent_8cpp_source.html#l00137">137</a> of file <a class="el" href="gradient__descent_8cpp_source.html">gradient_descent.cpp</a>.</p>

</div>
</div><p>
<a class="anchor" name="abf083d521b38d878afc58b7cf744ad9"></a><!-- doxytag: member="OpenNN::GradientDescent::get_error_parameters_norm" ref="abf083d521b38d878afc58b7cf744ad9" args="(void) const " -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">const double &amp; OpenNN::GradientDescent::get_error_parameters_norm           </td>
          <td>(</td>
          <td class="paramtype">void&nbsp;</td>
          <td class="paramname">          </td>
          <td>&nbsp;)&nbsp;</td>
          <td> const</td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
This method returns the value for the norm of the parameters vector at wich an error message is written to the screen and the program exits. 
<p>Definition at line <a class="el" href="gradient__descent_8cpp_source.html#l00148">148</a> of file <a class="el" href="gradient__descent_8cpp_source.html">gradient_descent.cpp</a>.</p>

</div>
</div><p>
<a class="anchor" name="5d28f85181e21d4c074bb1871206fb5c"></a><!-- doxytag: member="OpenNN::GradientDescent::get_error_gradient_norm" ref="5d28f85181e21d4c074bb1871206fb5c" args="(void) const " -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">const double &amp; OpenNN::GradientDescent::get_error_gradient_norm           </td>
          <td>(</td>
          <td class="paramtype">void&nbsp;</td>
          <td class="paramname">          </td>
          <td>&nbsp;)&nbsp;</td>
          <td> const</td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
This method returns the value for the norm of the gradient vector at wich an error message is written to the screen and the program exits. 
<p>Definition at line <a class="el" href="gradient__descent_8cpp_source.html#l00159">159</a> of file <a class="el" href="gradient__descent_8cpp_source.html">gradient_descent.cpp</a>.</p>

</div>
</div><p>
<a class="anchor" name="43c43e8fa25ece6586133dbbaf5403c4"></a><!-- doxytag: member="OpenNN::GradientDescent::get_error_training_rate" ref="43c43e8fa25ece6586133dbbaf5403c4" args="(void) const " -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">const double &amp; OpenNN::GradientDescent::get_error_training_rate           </td>
          <td>(</td>
          <td class="paramtype">void&nbsp;</td>
          <td class="paramname">          </td>
          <td>&nbsp;)&nbsp;</td>
          <td> const</td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
This method returns the training rate value at wich the line minimization algorithm is assumed to fail when bracketing a minimum. 
<p>Definition at line <a class="el" href="gradient__descent_8cpp_source.html#l00170">170</a> of file <a class="el" href="gradient__descent_8cpp_source.html">gradient_descent.cpp</a>.</p>

</div>
</div><p>
<a class="anchor" name="977e8321cd4b1027a2d47bd10bcf47ca"></a><!-- doxytag: member="OpenNN::GradientDescent::get_minimum_parameters_increment_norm" ref="977e8321cd4b1027a2d47bd10bcf47ca" args="(void) const " -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">const double &amp; OpenNN::GradientDescent::get_minimum_parameters_increment_norm           </td>
          <td>(</td>
          <td class="paramtype">void&nbsp;</td>
          <td class="paramname">          </td>
          <td>&nbsp;)&nbsp;</td>
          <td> const</td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
This method returns the minimum norm of the parameter increment vector used as a stopping criteria when training. 
<p>

<p>Definition at line <a class="el" href="gradient__descent_8cpp_source.html#l00180">180</a> of file <a class="el" href="gradient__descent_8cpp_source.html">gradient_descent.cpp</a>.</p>

</div>
</div><p>
<a class="anchor" name="460c313eb05a471addf301f8691827fb"></a><!-- doxytag: member="OpenNN::GradientDescent::get_minimum_performance_increase" ref="460c313eb05a471addf301f8691827fb" args="(void) const " -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">const double &amp; OpenNN::GradientDescent::get_minimum_performance_increase           </td>
          <td>(</td>
          <td class="paramtype">void&nbsp;</td>
          <td class="paramname">          </td>
          <td>&nbsp;)&nbsp;</td>
          <td> const</td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
This method returns the minimum performance improvement during training. 
<p>

<p>Definition at line <a class="el" href="gradient__descent_8cpp_source.html#l00190">190</a> of file <a class="el" href="gradient__descent_8cpp_source.html">gradient_descent.cpp</a>.</p>

</div>
</div><p>
<a class="anchor" name="b2a6b927e38a1dfe173bb866f27d2b96"></a><!-- doxytag: member="OpenNN::GradientDescent::get_performance_goal" ref="b2a6b927e38a1dfe173bb866f27d2b96" args="(void) const " -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">const double &amp; OpenNN::GradientDescent::get_performance_goal           </td>
          <td>(</td>
          <td class="paramtype">void&nbsp;</td>
          <td class="paramname">          </td>
          <td>&nbsp;)&nbsp;</td>
          <td> const</td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
This method returns the goal value for the performance. This is used as a stopping criterium when training a multilayer perceptron 
<p>Definition at line <a class="el" href="gradient__descent_8cpp_source.html#l00201">201</a> of file <a class="el" href="gradient__descent_8cpp_source.html">gradient_descent.cpp</a>.</p>

</div>
</div><p>
<a class="anchor" name="096b7ba798dd03e82670ea5263e194b5"></a><!-- doxytag: member="OpenNN::GradientDescent::get_gradient_norm_goal" ref="096b7ba798dd03e82670ea5263e194b5" args="(void) const " -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">const double &amp; OpenNN::GradientDescent::get_gradient_norm_goal           </td>
          <td>(</td>
          <td class="paramtype">void&nbsp;</td>
          <td class="paramname">          </td>
          <td>&nbsp;)&nbsp;</td>
          <td> const</td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
This method returns the goal value for the norm of the objective function gradient. This is used as a stopping criterium when training a multilayer perceptron 
<p>Definition at line <a class="el" href="gradient__descent_8cpp_source.html#l00212">212</a> of file <a class="el" href="gradient__descent_8cpp_source.html">gradient_descent.cpp</a>.</p>

</div>
</div><p>
<a class="anchor" name="ef2c9be7d3ae74c843117414c4588be7"></a><!-- doxytag: member="OpenNN::GradientDescent::get_maximum_generalization_evaluation_decreases" ref="ef2c9be7d3ae74c843117414c4588be7" args="(void) const " -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">const unsigned int &amp; OpenNN::GradientDescent::get_maximum_generalization_evaluation_decreases           </td>
          <td>(</td>
          <td class="paramtype">void&nbsp;</td>
          <td class="paramname">          </td>
          <td>&nbsp;)&nbsp;</td>
          <td> const</td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
This method returns the maximum number of generalization failures during the training process. 
<p>

<p>Definition at line <a class="el" href="gradient__descent_8cpp_source.html#l00222">222</a> of file <a class="el" href="gradient__descent_8cpp_source.html">gradient_descent.cpp</a>.</p>

</div>
</div><p>
<a class="anchor" name="7d2670b88ec8ba50df21b9a0763b5d04"></a><!-- doxytag: member="OpenNN::GradientDescent::get_maximum_epochs_number" ref="7d2670b88ec8ba50df21b9a0763b5d04" args="(void) const " -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">const unsigned int &amp; OpenNN::GradientDescent::get_maximum_epochs_number           </td>
          <td>(</td>
          <td class="paramtype">void&nbsp;</td>
          <td class="paramname">          </td>
          <td>&nbsp;)&nbsp;</td>
          <td> const</td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
This method returns the maximum number of epochs for training. 
<p>

<p>Definition at line <a class="el" href="gradient__descent_8cpp_source.html#l00232">232</a> of file <a class="el" href="gradient__descent_8cpp_source.html">gradient_descent.cpp</a>.</p>

</div>
</div><p>
<a class="anchor" name="e8fe1dd09d144f2ece993cf9338f5830"></a><!-- doxytag: member="OpenNN::GradientDescent::get_maximum_time" ref="e8fe1dd09d144f2ece993cf9338f5830" args="(void) const " -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">const double &amp; OpenNN::GradientDescent::get_maximum_time           </td>
          <td>(</td>
          <td class="paramtype">void&nbsp;</td>
          <td class="paramname">          </td>
          <td>&nbsp;)&nbsp;</td>
          <td> const</td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
This method returns the maximum training time. 
<p>

<p>Definition at line <a class="el" href="gradient__descent_8cpp_source.html#l00242">242</a> of file <a class="el" href="gradient__descent_8cpp_source.html">gradient_descent.cpp</a>.</p>

</div>
</div><p>
<a class="anchor" name="0adf17968a23452099c3a3af7788de07"></a><!-- doxytag: member="OpenNN::GradientDescent::get_reserve_parameters_history" ref="0adf17968a23452099c3a3af7788de07" args="(void) const " -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">const bool &amp; OpenNN::GradientDescent::get_reserve_parameters_history           </td>
          <td>(</td>
          <td class="paramtype">void&nbsp;</td>
          <td class="paramname">          </td>
          <td>&nbsp;)&nbsp;</td>
          <td> const</td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
This method returns true if the parameters history matrix is to be reserved, and false otherwise. 
<p>

<p>Definition at line <a class="el" href="gradient__descent_8cpp_source.html#l00252">252</a> of file <a class="el" href="gradient__descent_8cpp_source.html">gradient_descent.cpp</a>.</p>

</div>
</div><p>
<a class="anchor" name="a34afdc9f24b77546a0417c2136fa005"></a><!-- doxytag: member="OpenNN::GradientDescent::get_reserve_parameters_norm_history" ref="a34afdc9f24b77546a0417c2136fa005" args="(void) const " -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">const bool &amp; OpenNN::GradientDescent::get_reserve_parameters_norm_history           </td>
          <td>(</td>
          <td class="paramtype">void&nbsp;</td>
          <td class="paramname">          </td>
          <td>&nbsp;)&nbsp;</td>
          <td> const</td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
This method returns true if the parameters norm history vector is to be reserved, and false otherwise. 
<p>

<p>Definition at line <a class="el" href="gradient__descent_8cpp_source.html#l00262">262</a> of file <a class="el" href="gradient__descent_8cpp_source.html">gradient_descent.cpp</a>.</p>

</div>
</div><p>
<a class="anchor" name="4a117b0b0bb4eb10d78d397aaa2dc2ff"></a><!-- doxytag: member="OpenNN::GradientDescent::get_reserve_evaluation_history" ref="4a117b0b0bb4eb10d78d397aaa2dc2ff" args="(void) const " -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">const bool &amp; OpenNN::GradientDescent::get_reserve_evaluation_history           </td>
          <td>(</td>
          <td class="paramtype">void&nbsp;</td>
          <td class="paramname">          </td>
          <td>&nbsp;)&nbsp;</td>
          <td> const</td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
This method returns true if the evaluation history vector is to be reserved, and false otherwise. 
<p>

<p>Definition at line <a class="el" href="gradient__descent_8cpp_source.html#l00272">272</a> of file <a class="el" href="gradient__descent_8cpp_source.html">gradient_descent.cpp</a>.</p>

</div>
</div><p>
<a class="anchor" name="6c78744fa192aee34b9bbe2fd7419ed1"></a><!-- doxytag: member="OpenNN::GradientDescent::get_reserve_gradient_history" ref="6c78744fa192aee34b9bbe2fd7419ed1" args="(void) const " -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">const bool &amp; OpenNN::GradientDescent::get_reserve_gradient_history           </td>
          <td>(</td>
          <td class="paramtype">void&nbsp;</td>
          <td class="paramname">          </td>
          <td>&nbsp;)&nbsp;</td>
          <td> const</td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
This method returns true if the gradient history vector of vectors is to be reserved, and false otherwise. 
<p>

<p>Definition at line <a class="el" href="gradient__descent_8cpp_source.html#l00282">282</a> of file <a class="el" href="gradient__descent_8cpp_source.html">gradient_descent.cpp</a>.</p>

</div>
</div><p>
<a class="anchor" name="b0eef1b50c1003bf779b3f7658e0ac8f"></a><!-- doxytag: member="OpenNN::GradientDescent::get_reserve_gradient_norm_history" ref="b0eef1b50c1003bf779b3f7658e0ac8f" args="(void) const " -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">const bool &amp; OpenNN::GradientDescent::get_reserve_gradient_norm_history           </td>
          <td>(</td>
          <td class="paramtype">void&nbsp;</td>
          <td class="paramname">          </td>
          <td>&nbsp;)&nbsp;</td>
          <td> const</td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
This method returns true if the gradient norm history vector is to be reserved, and false otherwise. 
<p>

<p>Definition at line <a class="el" href="gradient__descent_8cpp_source.html#l00292">292</a> of file <a class="el" href="gradient__descent_8cpp_source.html">gradient_descent.cpp</a>.</p>

</div>
</div><p>
<a class="anchor" name="e8eda1d13c5f4fd1aca52e9971336730"></a><!-- doxytag: member="OpenNN::GradientDescent::get_reserve_generalization_evaluation_history" ref="e8eda1d13c5f4fd1aca52e9971336730" args="(void) const " -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">const bool &amp; OpenNN::GradientDescent::get_reserve_generalization_evaluation_history           </td>
          <td>(</td>
          <td class="paramtype">void&nbsp;</td>
          <td class="paramname">          </td>
          <td>&nbsp;)&nbsp;</td>
          <td> const</td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
This method returns true if the Generalization evaluation history vector is to be reserved, and false otherwise. 
<p>

<p>Definition at line <a class="el" href="gradient__descent_8cpp_source.html#l00332">332</a> of file <a class="el" href="gradient__descent_8cpp_source.html">gradient_descent.cpp</a>.</p>

</div>
</div><p>
<a class="anchor" name="003543fe0d6f7a5d1bfae52837b19d8a"></a><!-- doxytag: member="OpenNN::GradientDescent::get_reserve_training_direction_history" ref="003543fe0d6f7a5d1bfae52837b19d8a" args="(void) const " -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">const bool &amp; OpenNN::GradientDescent::get_reserve_training_direction_history           </td>
          <td>(</td>
          <td class="paramtype">void&nbsp;</td>
          <td class="paramname">          </td>
          <td>&nbsp;)&nbsp;</td>
          <td> const</td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
This method returns true if the training direction history matrix is to be reserved, and false otherwise. 
<p>

<p>Definition at line <a class="el" href="gradient__descent_8cpp_source.html#l00302">302</a> of file <a class="el" href="gradient__descent_8cpp_source.html">gradient_descent.cpp</a>.</p>

</div>
</div><p>
<a class="anchor" name="038114122cf181642076b7e76e494abc"></a><!-- doxytag: member="OpenNN::GradientDescent::get_reserve_training_rate_history" ref="038114122cf181642076b7e76e494abc" args="(void) const " -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">const bool &amp; OpenNN::GradientDescent::get_reserve_training_rate_history           </td>
          <td>(</td>
          <td class="paramtype">void&nbsp;</td>
          <td class="paramname">          </td>
          <td>&nbsp;)&nbsp;</td>
          <td> const</td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
This method returns true if the training rate history vector is to be reserved, and false otherwise. 
<p>

<p>Definition at line <a class="el" href="gradient__descent_8cpp_source.html#l00312">312</a> of file <a class="el" href="gradient__descent_8cpp_source.html">gradient_descent.cpp</a>.</p>

</div>
</div><p>
<a class="anchor" name="b1721d85c7aab1ee42ee55ec24e296c5"></a><!-- doxytag: member="OpenNN::GradientDescent::get_reserve_elapsed_time_history" ref="b1721d85c7aab1ee42ee55ec24e296c5" args="(void) const " -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">const bool &amp; OpenNN::GradientDescent::get_reserve_elapsed_time_history           </td>
          <td>(</td>
          <td class="paramtype">void&nbsp;</td>
          <td class="paramname">          </td>
          <td>&nbsp;)&nbsp;</td>
          <td> const</td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
This method returns true if the elapsed time history vector is to be reserved, and false otherwise. 
<p>

<p>Definition at line <a class="el" href="gradient__descent_8cpp_source.html#l00322">322</a> of file <a class="el" href="gradient__descent_8cpp_source.html">gradient_descent.cpp</a>.</p>

</div>
</div><p>
<a class="anchor" name="0598d1a344e0b4a0589998c3402ff22a"></a><!-- doxytag: member="OpenNN::GradientDescent::get_display_period" ref="0598d1a344e0b4a0589998c3402ff22a" args="(void) const " -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">const unsigned int &amp; OpenNN::GradientDescent::get_display_period           </td>
          <td>(</td>
          <td class="paramtype">void&nbsp;</td>
          <td class="paramname">          </td>
          <td>&nbsp;)&nbsp;</td>
          <td> const</td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
This method returns the number of epochs between the training showing progress. 
<p>

<p>Definition at line <a class="el" href="gradient__descent_8cpp_source.html#l00342">342</a> of file <a class="el" href="gradient__descent_8cpp_source.html">gradient_descent.cpp</a>.</p>

</div>
</div><p>
<a class="anchor" name="3e29b2699a9b3b4eee80d17e493a3c6d"></a><!-- doxytag: member="OpenNN::GradientDescent::set_training_rate_algorithm" ref="3e29b2699a9b3b4eee80d17e493a3c6d" args="(const TrainingRateAlgorithm &amp;)" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void OpenNN::GradientDescent::set_training_rate_algorithm           </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="class_open_n_n_1_1_training_rate_algorithm.html">TrainingRateAlgorithm</a> &amp;&nbsp;</td>
          <td class="paramname"> <em>new_training_rate_algorithm</em>          </td>
          <td>&nbsp;)&nbsp;</td>
          <td></td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
This method sets a new training rate algorithm object into the gradient descent object. <dl compact><dt><b>Parameters:</b></dt><dd>
  <table border="0" cellspacing="2" cellpadding="0">
    <tr><td valign="top"></td><td valign="top"><em>new_training_rate_algorithm</em>&nbsp;</td><td>Object of the class <a class="el" href="class_open_n_n_1_1_training_rate_algorithm.html">TrainingRateAlgorithm</a> </td></tr>
  </table>
</dl>

<p>Definition at line <a class="el" href="gradient__descent_8cpp_source.html#l00353">353</a> of file <a class="el" href="gradient__descent_8cpp_source.html">gradient_descent.cpp</a>.</p>

</div>
</div><p>
<a class="anchor" name="de5a4d5ec6b048ca182ba2e17e182055"></a><!-- doxytag: member="OpenNN::GradientDescent::set_default" ref="de5a4d5ec6b048ca182ba2e17e182055" args="(void)" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void OpenNN::GradientDescent::set_default           </td>
          <td>(</td>
          <td class="paramtype">void&nbsp;</td>
          <td class="paramname">          </td>
          <td>&nbsp;)&nbsp;</td>
          <td><code> [virtual]</code></td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
This method sets the members of the training algorithm object to their default values. 
<p>

<p>Reimplemented from <a class="el" href="class_open_n_n_1_1_training_algorithm.html#856d53c16da6bf5726da0f8403a13349">OpenNN::TrainingAlgorithm</a>.</p>

<p>Definition at line <a class="el" href="gradient__descent_8cpp_source.html#l00361">361</a> of file <a class="el" href="gradient__descent_8cpp_source.html">gradient_descent.cpp</a>.</p>

</div>
</div><p>
<a class="anchor" name="8b7860afbf36d0aac837091f35a63e84"></a><!-- doxytag: member="OpenNN::GradientDescent::set_reserve_all_training_history" ref="8b7860afbf36d0aac837091f35a63e84" args="(const bool &amp;)" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void OpenNN::GradientDescent::set_reserve_all_training_history           </td>
          <td>(</td>
          <td class="paramtype">const bool &amp;&nbsp;</td>
          <td class="paramname"> <em>new_reserve_all_training_history</em>          </td>
          <td>&nbsp;)&nbsp;</td>
          <td></td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
This method makes the training history of all variables to reseved or not in memory: <ul>
<li>
Parameters. </li>
<li>
Parameters norm. </li>
<li>
Performance. </li>
<li>
Gradient. </li>
<li>
Gradient norm. </li>
<li>
Generalization performance. </li>
<li>
Training direction. </li>
<li>
Training direction norm. </li>
<li>
Training rate. </li>
</ul>
<dl compact><dt><b>Parameters:</b></dt><dd>
  <table border="0" cellspacing="2" cellpadding="0">
    <tr><td valign="top"></td><td valign="top"><em>new_reserve_all_training_history</em>&nbsp;</td><td>True if the training history of all variables is to be reserved, false otherwise. </td></tr>
  </table>
</dl>

<p>Definition at line <a class="el" href="gradient__descent_8cpp_source.html#l00422">422</a> of file <a class="el" href="gradient__descent_8cpp_source.html">gradient_descent.cpp</a>.</p>

</div>
</div><p>
<a class="anchor" name="c525a49652ff909ec76613b721e33739"></a><!-- doxytag: member="OpenNN::GradientDescent::set_warning_parameters_norm" ref="c525a49652ff909ec76613b721e33739" args="(const double &amp;)" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void OpenNN::GradientDescent::set_warning_parameters_norm           </td>
          <td>(</td>
          <td class="paramtype">const double &amp;&nbsp;</td>
          <td class="paramname"> <em>new_warning_parameters_norm</em>          </td>
          <td>&nbsp;)&nbsp;</td>
          <td></td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
This method sets a new value for the parameters vector norm at which a warning message is written to the screen. <dl compact><dt><b>Parameters:</b></dt><dd>
  <table border="0" cellspacing="2" cellpadding="0">
    <tr><td valign="top"></td><td valign="top"><em>new_warning_parameters_norm</em>&nbsp;</td><td>Warning norm of parameters vector value. </td></tr>
  </table>
</dl>

<p>Definition at line <a class="el" href="gradient__descent_8cpp_source.html#l00452">452</a> of file <a class="el" href="gradient__descent_8cpp_source.html">gradient_descent.cpp</a>.</p>

</div>
</div><p>
<a class="anchor" name="c7f1c7a84ab5067aa2550b3e36537c21"></a><!-- doxytag: member="OpenNN::GradientDescent::set_warning_gradient_norm" ref="c7f1c7a84ab5067aa2550b3e36537c21" args="(const double &amp;)" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void OpenNN::GradientDescent::set_warning_gradient_norm           </td>
          <td>(</td>
          <td class="paramtype">const double &amp;&nbsp;</td>
          <td class="paramname"> <em>new_warning_gradient_norm</em>          </td>
          <td>&nbsp;)&nbsp;</td>
          <td></td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
This method sets a new value for the gradient vector norm at which a warning message is written to the screen. <dl compact><dt><b>Parameters:</b></dt><dd>
  <table border="0" cellspacing="2" cellpadding="0">
    <tr><td valign="top"></td><td valign="top"><em>new_warning_gradient_norm</em>&nbsp;</td><td>Warning norm of gradient vector value. </td></tr>
  </table>
</dl>

<p>Definition at line <a class="el" href="gradient__descent_8cpp_source.html#l00483">483</a> of file <a class="el" href="gradient__descent_8cpp_source.html">gradient_descent.cpp</a>.</p>

</div>
</div><p>
<a class="anchor" name="9359ff2faa9eab75167a5867381a6b34"></a><!-- doxytag: member="OpenNN::GradientDescent::set_warning_training_rate" ref="9359ff2faa9eab75167a5867381a6b34" args="(const double &amp;)" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void OpenNN::GradientDescent::set_warning_training_rate           </td>
          <td>(</td>
          <td class="paramtype">const double &amp;&nbsp;</td>
          <td class="paramname"> <em>new_warning_training_rate</em>          </td>
          <td>&nbsp;)&nbsp;</td>
          <td></td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
This method sets a new training rate value at wich a warning message is written to the screen during line minimization. <dl compact><dt><b>Parameters:</b></dt><dd>
  <table border="0" cellspacing="2" cellpadding="0">
    <tr><td valign="top"></td><td valign="top"><em>new_warning_training_rate</em>&nbsp;</td><td>Warning training rate value. </td></tr>
  </table>
</dl>

<p>Definition at line <a class="el" href="gradient__descent_8cpp_source.html#l00514">514</a> of file <a class="el" href="gradient__descent_8cpp_source.html">gradient_descent.cpp</a>.</p>

</div>
</div><p>
<a class="anchor" name="2625e879f726b1501ce33ab5710bbb88"></a><!-- doxytag: member="OpenNN::GradientDescent::set_error_parameters_norm" ref="2625e879f726b1501ce33ab5710bbb88" args="(const double &amp;)" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void OpenNN::GradientDescent::set_error_parameters_norm           </td>
          <td>(</td>
          <td class="paramtype">const double &amp;&nbsp;</td>
          <td class="paramname"> <em>new_error_parameters_norm</em>          </td>
          <td>&nbsp;)&nbsp;</td>
          <td></td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
This method sets a new value for the parameters vector norm at which an error message is written to the screen and the program exits. <dl compact><dt><b>Parameters:</b></dt><dd>
  <table border="0" cellspacing="2" cellpadding="0">
    <tr><td valign="top"></td><td valign="top"><em>new_error_parameters_norm</em>&nbsp;</td><td>Error norm of parameters vector value. </td></tr>
  </table>
</dl>

<p>Definition at line <a class="el" href="gradient__descent_8cpp_source.html#l00543">543</a> of file <a class="el" href="gradient__descent_8cpp_source.html">gradient_descent.cpp</a>.</p>

</div>
</div><p>
<a class="anchor" name="e8d1a6991a7a735195ed65b15315d233"></a><!-- doxytag: member="OpenNN::GradientDescent::set_error_gradient_norm" ref="e8d1a6991a7a735195ed65b15315d233" args="(const double &amp;)" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void OpenNN::GradientDescent::set_error_gradient_norm           </td>
          <td>(</td>
          <td class="paramtype">const double &amp;&nbsp;</td>
          <td class="paramname"> <em>new_error_gradient_norm</em>          </td>
          <td>&nbsp;)&nbsp;</td>
          <td></td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
This method sets a new value for the gradient vector norm at which an error message is written to the screen and the program exits. <dl compact><dt><b>Parameters:</b></dt><dd>
  <table border="0" cellspacing="2" cellpadding="0">
    <tr><td valign="top"></td><td valign="top"><em>new_error_gradient_norm</em>&nbsp;</td><td>Error norm of gradient vector value. </td></tr>
  </table>
</dl>

<p>Definition at line <a class="el" href="gradient__descent_8cpp_source.html#l00574">574</a> of file <a class="el" href="gradient__descent_8cpp_source.html">gradient_descent.cpp</a>.</p>

</div>
</div><p>
<a class="anchor" name="1d3b83e0e926af808f2d6a3b2bde050c"></a><!-- doxytag: member="OpenNN::GradientDescent::set_error_training_rate" ref="1d3b83e0e926af808f2d6a3b2bde050c" args="(const double &amp;)" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void OpenNN::GradientDescent::set_error_training_rate           </td>
          <td>(</td>
          <td class="paramtype">const double &amp;&nbsp;</td>
          <td class="paramname"> <em>new_error_training_rate</em>          </td>
          <td>&nbsp;)&nbsp;</td>
          <td></td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
This method sets a new training rate value at wich a the line minimization algorithm is assumed to fail when bracketing a minimum. <dl compact><dt><b>Parameters:</b></dt><dd>
  <table border="0" cellspacing="2" cellpadding="0">
    <tr><td valign="top"></td><td valign="top"><em>new_error_training_rate</em>&nbsp;</td><td>Error training rate value. </td></tr>
  </table>
</dl>

<p>Definition at line <a class="el" href="gradient__descent_8cpp_source.html#l00605">605</a> of file <a class="el" href="gradient__descent_8cpp_source.html">gradient_descent.cpp</a>.</p>

</div>
</div><p>
<a class="anchor" name="6ebdcab74360e712408d2b5f734cc2d8"></a><!-- doxytag: member="OpenNN::GradientDescent::set_minimum_parameters_increment_norm" ref="6ebdcab74360e712408d2b5f734cc2d8" args="(const double &amp;)" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void OpenNN::GradientDescent::set_minimum_parameters_increment_norm           </td>
          <td>(</td>
          <td class="paramtype">const double &amp;&nbsp;</td>
          <td class="paramname"> <em>new_minimum_parameters_increment_norm</em>          </td>
          <td>&nbsp;)&nbsp;</td>
          <td></td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
This method sets a new value for the minimum parameters increment norm stopping criterium. <dl compact><dt><b>Parameters:</b></dt><dd>
  <table border="0" cellspacing="2" cellpadding="0">
    <tr><td valign="top"></td><td valign="top"><em>new_minimum_parameters_increment_norm</em>&nbsp;</td><td>Value of norm of parameters increment norm used to stop training. </td></tr>
  </table>
</dl>

<p>Definition at line <a class="el" href="gradient__descent_8cpp_source.html#l00635">635</a> of file <a class="el" href="gradient__descent_8cpp_source.html">gradient_descent.cpp</a>.</p>

</div>
</div><p>
<a class="anchor" name="a1a12c07c1db1420bb59f58c3a17fea4"></a><!-- doxytag: member="OpenNN::GradientDescent::set_minimum_performance_increase" ref="a1a12c07c1db1420bb59f58c3a17fea4" args="(const double &amp;)" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void OpenNN::GradientDescent::set_minimum_performance_increase           </td>
          <td>(</td>
          <td class="paramtype">const double &amp;&nbsp;</td>
          <td class="paramname"> <em>new_minimum_performance_increase</em>          </td>
          <td>&nbsp;)&nbsp;</td>
          <td></td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
This method sets a new minimum performance improvement during training. <dl compact><dt><b>Parameters:</b></dt><dd>
  <table border="0" cellspacing="2" cellpadding="0">
    <tr><td valign="top"></td><td valign="top"><em>new_minimum_performance_increase</em>&nbsp;</td><td>Minimum improvement in the performance between two epochs. </td></tr>
  </table>
</dl>

<p>Definition at line <a class="el" href="gradient__descent_8cpp_source.html#l00665">665</a> of file <a class="el" href="gradient__descent_8cpp_source.html">gradient_descent.cpp</a>.</p>

</div>
</div><p>
<a class="anchor" name="8e10381a376476d92e3c96a56a7cf257"></a><!-- doxytag: member="OpenNN::GradientDescent::set_performance_goal" ref="8e10381a376476d92e3c96a56a7cf257" args="(const double &amp;)" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void OpenNN::GradientDescent::set_performance_goal           </td>
          <td>(</td>
          <td class="paramtype">const double &amp;&nbsp;</td>
          <td class="paramname"> <em>new_performance_goal</em>          </td>
          <td>&nbsp;)&nbsp;</td>
          <td></td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
This method sets a new goal value for the performance. This is used as a stopping criterium when training a multilayer perceptron <dl compact><dt><b>Parameters:</b></dt><dd>
  <table border="0" cellspacing="2" cellpadding="0">
    <tr><td valign="top"></td><td valign="top"><em>new_performance_goal</em>&nbsp;</td><td>Goal value for the performance. </td></tr>
  </table>
</dl>

<p>Definition at line <a class="el" href="gradient__descent_8cpp_source.html#l00696">696</a> of file <a class="el" href="gradient__descent_8cpp_source.html">gradient_descent.cpp</a>.</p>

</div>
</div><p>
<a class="anchor" name="1ad68485a9faa5a39c134b4177551c48"></a><!-- doxytag: member="OpenNN::GradientDescent::set_gradient_norm_goal" ref="1ad68485a9faa5a39c134b4177551c48" args="(const double &amp;)" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void OpenNN::GradientDescent::set_gradient_norm_goal           </td>
          <td>(</td>
          <td class="paramtype">const double &amp;&nbsp;</td>
          <td class="paramname"> <em>new_gradient_norm_goal</em>          </td>
          <td>&nbsp;)&nbsp;</td>
          <td></td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
This method sets a new the goal value for the norm of the objective function gradient. This is used as a stopping criterium when training a multilayer perceptron <dl compact><dt><b>Parameters:</b></dt><dd>
  <table border="0" cellspacing="2" cellpadding="0">
    <tr><td valign="top"></td><td valign="top"><em>new_gradient_norm_goal</em>&nbsp;</td><td>Goal value for the norm of the objective function gradient. </td></tr>
  </table>
</dl>

<p>Definition at line <a class="el" href="gradient__descent_8cpp_source.html#l00708">708</a> of file <a class="el" href="gradient__descent_8cpp_source.html">gradient_descent.cpp</a>.</p>

</div>
</div><p>
<a class="anchor" name="de9212832bd5d3a23f751d830f153e8a"></a><!-- doxytag: member="OpenNN::GradientDescent::set_maximum_generalization_evaluation_decreases" ref="de9212832bd5d3a23f751d830f153e8a" args="(const unsigned int &amp;)" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void OpenNN::GradientDescent::set_maximum_generalization_evaluation_decreases           </td>
          <td>(</td>
          <td class="paramtype">const unsigned int &amp;&nbsp;</td>
          <td class="paramname"> <em>new_maximum_generalization_evaluation_decreases</em>          </td>
          <td>&nbsp;)&nbsp;</td>
          <td></td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
This method sets a new maximum number of generalization failures. <dl compact><dt><b>Parameters:</b></dt><dd>
  <table border="0" cellspacing="2" cellpadding="0">
    <tr><td valign="top"></td><td valign="top"><em>new_maximum_generalization_evaluation_decreases</em>&nbsp;</td><td>Maximum number of epochs in which the generalization evalutation decreases. </td></tr>
  </table>
</dl>

<p>Definition at line <a class="el" href="gradient__descent_8cpp_source.html#l00738">738</a> of file <a class="el" href="gradient__descent_8cpp_source.html">gradient_descent.cpp</a>.</p>

</div>
</div><p>
<a class="anchor" name="f66661bb709e3b68c748a4307e8bee45"></a><!-- doxytag: member="OpenNN::GradientDescent::set_maximum_epochs_number" ref="f66661bb709e3b68c748a4307e8bee45" args="(const unsigned int &amp;)" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void OpenNN::GradientDescent::set_maximum_epochs_number           </td>
          <td>(</td>
          <td class="paramtype">const unsigned int &amp;&nbsp;</td>
          <td class="paramname"> <em>new_maximum_epochs_number</em>          </td>
          <td>&nbsp;)&nbsp;</td>
          <td></td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
This method sets a maximum number of epochs for training. <dl compact><dt><b>Parameters:</b></dt><dd>
  <table border="0" cellspacing="2" cellpadding="0">
    <tr><td valign="top"></td><td valign="top"><em>new_maximum_epochs_number</em>&nbsp;</td><td>Maximum number of epochs for training. </td></tr>
  </table>
</dl>

<p>Definition at line <a class="el" href="gradient__descent_8cpp_source.html#l00768">768</a> of file <a class="el" href="gradient__descent_8cpp_source.html">gradient_descent.cpp</a>.</p>

</div>
</div><p>
<a class="anchor" name="79b6c48c3f392baeaabff840d22cb5b3"></a><!-- doxytag: member="OpenNN::GradientDescent::set_maximum_time" ref="79b6c48c3f392baeaabff840d22cb5b3" args="(const double &amp;)" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void OpenNN::GradientDescent::set_maximum_time           </td>
          <td>(</td>
          <td class="paramtype">const double &amp;&nbsp;</td>
          <td class="paramname"> <em>new_maximum_time</em>          </td>
          <td>&nbsp;)&nbsp;</td>
          <td></td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
This method sets a new maximum training time. <dl compact><dt><b>Parameters:</b></dt><dd>
  <table border="0" cellspacing="2" cellpadding="0">
    <tr><td valign="top"></td><td valign="top"><em>new_maximum_time</em>&nbsp;</td><td>Maximum training time. </td></tr>
  </table>
</dl>

<p>Definition at line <a class="el" href="gradient__descent_8cpp_source.html#l00798">798</a> of file <a class="el" href="gradient__descent_8cpp_source.html">gradient_descent.cpp</a>.</p>

</div>
</div><p>
<a class="anchor" name="3d828a36bf0df6069f04d5c7ac2eeb51"></a><!-- doxytag: member="OpenNN::GradientDescent::set_reserve_parameters_history" ref="3d828a36bf0df6069f04d5c7ac2eeb51" args="(const bool &amp;)" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void OpenNN::GradientDescent::set_reserve_parameters_history           </td>
          <td>(</td>
          <td class="paramtype">const bool &amp;&nbsp;</td>
          <td class="paramname"> <em>new_reserve_parameters_history</em>          </td>
          <td>&nbsp;)&nbsp;</td>
          <td></td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
This method makes the parameters history vector of vectors to be reseved or not in memory. <dl compact><dt><b>Parameters:</b></dt><dd>
  <table border="0" cellspacing="2" cellpadding="0">
    <tr><td valign="top"></td><td valign="top"><em>new_reserve_parameters_history</em>&nbsp;</td><td>True if the parameters history vector of vectors is to be reserved, false otherwise. </td></tr>
  </table>
</dl>

<p>Definition at line <a class="el" href="gradient__descent_8cpp_source.html#l00828">828</a> of file <a class="el" href="gradient__descent_8cpp_source.html">gradient_descent.cpp</a>.</p>

</div>
</div><p>
<a class="anchor" name="daf7e1540cc81138bd541bee36269464"></a><!-- doxytag: member="OpenNN::GradientDescent::set_reserve_parameters_norm_history" ref="daf7e1540cc81138bd541bee36269464" args="(const bool &amp;)" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void OpenNN::GradientDescent::set_reserve_parameters_norm_history           </td>
          <td>(</td>
          <td class="paramtype">const bool &amp;&nbsp;</td>
          <td class="paramname"> <em>new_reserve_parameters_norm_history</em>          </td>
          <td>&nbsp;)&nbsp;</td>
          <td></td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
This method makes the parameters norm history vector to be reseved or not in memory. <dl compact><dt><b>Parameters:</b></dt><dd>
  <table border="0" cellspacing="2" cellpadding="0">
    <tr><td valign="top"></td><td valign="top"><em>new_reserve_parameters_norm_history</em>&nbsp;</td><td>True if the parameters norm history vector is to be reserved, false otherwise. </td></tr>
  </table>
</dl>

<p>Definition at line <a class="el" href="gradient__descent_8cpp_source.html#l00839">839</a> of file <a class="el" href="gradient__descent_8cpp_source.html">gradient_descent.cpp</a>.</p>

</div>
</div><p>
<a class="anchor" name="aa21d82bbe0fd3bb31295e97da9593c9"></a><!-- doxytag: member="OpenNN::GradientDescent::set_reserve_evaluation_history" ref="aa21d82bbe0fd3bb31295e97da9593c9" args="(const bool &amp;)" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void OpenNN::GradientDescent::set_reserve_evaluation_history           </td>
          <td>(</td>
          <td class="paramtype">const bool &amp;&nbsp;</td>
          <td class="paramname"> <em>new_reserve_evaluation_history</em>          </td>
          <td>&nbsp;)&nbsp;</td>
          <td></td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
This method makes the evaluation history vector to be reseved or not in memory. <dl compact><dt><b>Parameters:</b></dt><dd>
  <table border="0" cellspacing="2" cellpadding="0">
    <tr><td valign="top"></td><td valign="top"><em>new_reserve_evaluation_history</em>&nbsp;</td><td>True if the evaluation history vector is to be reserved, false otherwise. </td></tr>
  </table>
</dl>

<p>Definition at line <a class="el" href="gradient__descent_8cpp_source.html#l00850">850</a> of file <a class="el" href="gradient__descent_8cpp_source.html">gradient_descent.cpp</a>.</p>

</div>
</div><p>
<a class="anchor" name="8ec7e29c6611ca1d0e3d03d543d62ce7"></a><!-- doxytag: member="OpenNN::GradientDescent::set_reserve_gradient_history" ref="8ec7e29c6611ca1d0e3d03d543d62ce7" args="(const bool &amp;)" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void OpenNN::GradientDescent::set_reserve_gradient_history           </td>
          <td>(</td>
          <td class="paramtype">const bool &amp;&nbsp;</td>
          <td class="paramname"> <em>new_reserve_gradient_history</em>          </td>
          <td>&nbsp;)&nbsp;</td>
          <td></td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
This method makes the gradient history vector of vectors to be reseved or not in memory. <dl compact><dt><b>Parameters:</b></dt><dd>
  <table border="0" cellspacing="2" cellpadding="0">
    <tr><td valign="top"></td><td valign="top"><em>new_reserve_gradient_history</em>&nbsp;</td><td>True if the gradient history matrix is to be reserved, false otherwise. </td></tr>
  </table>
</dl>

<p>Definition at line <a class="el" href="gradient__descent_8cpp_source.html#l00861">861</a> of file <a class="el" href="gradient__descent_8cpp_source.html">gradient_descent.cpp</a>.</p>

</div>
</div><p>
<a class="anchor" name="c35bd72977a353a1edbc01178c1965e1"></a><!-- doxytag: member="OpenNN::GradientDescent::set_reserve_gradient_norm_history" ref="c35bd72977a353a1edbc01178c1965e1" args="(const bool &amp;)" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void OpenNN::GradientDescent::set_reserve_gradient_norm_history           </td>
          <td>(</td>
          <td class="paramtype">const bool &amp;&nbsp;</td>
          <td class="paramname"> <em>new_reserve_gradient_norm_history</em>          </td>
          <td>&nbsp;)&nbsp;</td>
          <td></td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
This method makes the gradient norm history vector to be reseved or not in memory. <dl compact><dt><b>Parameters:</b></dt><dd>
  <table border="0" cellspacing="2" cellpadding="0">
    <tr><td valign="top"></td><td valign="top"><em>new_reserve_gradient_norm_history</em>&nbsp;</td><td>True if the gradient norm history matrix is to be reserved, false otherwise. </td></tr>
  </table>
</dl>

<p>Definition at line <a class="el" href="gradient__descent_8cpp_source.html#l00873">873</a> of file <a class="el" href="gradient__descent_8cpp_source.html">gradient_descent.cpp</a>.</p>

</div>
</div><p>
<a class="anchor" name="05e2aedc5889583d5cfcdd3e69ea24ce"></a><!-- doxytag: member="OpenNN::GradientDescent::set_reserve_generalization_evaluation_history" ref="05e2aedc5889583d5cfcdd3e69ea24ce" args="(const bool &amp;)" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void OpenNN::GradientDescent::set_reserve_generalization_evaluation_history           </td>
          <td>(</td>
          <td class="paramtype">const bool &amp;&nbsp;</td>
          <td class="paramname"> <em>new_reserve_generalization_evaluation_history</em>          </td>
          <td>&nbsp;)&nbsp;</td>
          <td></td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
This method makes the Generalization evaluation history to be reserved or not in memory. This is a vector. <dl compact><dt><b>Parameters:</b></dt><dd>
  <table border="0" cellspacing="2" cellpadding="0">
    <tr><td valign="top"></td><td valign="top"><em>new_reserve_generalization_evaluation_history</em>&nbsp;</td><td>True if the Generalization evaluation history is to be reserved, false otherwise. </td></tr>
  </table>
</dl>

<p>Definition at line <a class="el" href="gradient__descent_8cpp_source.html#l00921">921</a> of file <a class="el" href="gradient__descent_8cpp_source.html">gradient_descent.cpp</a>.</p>

</div>
</div><p>
<a class="anchor" name="9c2553d655440601e779a3d093de593c"></a><!-- doxytag: member="OpenNN::GradientDescent::set_reserve_training_direction_history" ref="9c2553d655440601e779a3d093de593c" args="(const bool &amp;)" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void OpenNN::GradientDescent::set_reserve_training_direction_history           </td>
          <td>(</td>
          <td class="paramtype">const bool &amp;&nbsp;</td>
          <td class="paramname"> <em>new_reserve_training_direction_history</em>          </td>
          <td>&nbsp;)&nbsp;</td>
          <td></td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
This method makes the training direction history vector of vectors to be reseved or not in memory. <dl compact><dt><b>Parameters:</b></dt><dd>
  <table border="0" cellspacing="2" cellpadding="0">
    <tr><td valign="top"></td><td valign="top"><em>new_reserve_training_direction_history</em>&nbsp;</td><td>True if the training direction history matrix is to be reserved, false otherwise. </td></tr>
  </table>
</dl>

<p>Definition at line <a class="el" href="gradient__descent_8cpp_source.html#l00885">885</a> of file <a class="el" href="gradient__descent_8cpp_source.html">gradient_descent.cpp</a>.</p>

</div>
</div><p>
<a class="anchor" name="7adc9d5149d9599aa3df9d254974d503"></a><!-- doxytag: member="OpenNN::GradientDescent::set_reserve_training_rate_history" ref="7adc9d5149d9599aa3df9d254974d503" args="(const bool &amp;)" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void OpenNN::GradientDescent::set_reserve_training_rate_history           </td>
          <td>(</td>
          <td class="paramtype">const bool &amp;&nbsp;</td>
          <td class="paramname"> <em>new_reserve_training_rate_history</em>          </td>
          <td>&nbsp;)&nbsp;</td>
          <td></td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
This method makes the training rate history vector to be reseved or not in memory. <dl compact><dt><b>Parameters:</b></dt><dd>
  <table border="0" cellspacing="2" cellpadding="0">
    <tr><td valign="top"></td><td valign="top"><em>new_reserve_training_rate_history</em>&nbsp;</td><td>True if the training rate history vector is to be reserved, false otherwise. </td></tr>
  </table>
</dl>

<p>Definition at line <a class="el" href="gradient__descent_8cpp_source.html#l00897">897</a> of file <a class="el" href="gradient__descent_8cpp_source.html">gradient_descent.cpp</a>.</p>

</div>
</div><p>
<a class="anchor" name="8e98003d637460b1a6f57cc5063b77d8"></a><!-- doxytag: member="OpenNN::GradientDescent::set_reserve_elapsed_time_history" ref="8e98003d637460b1a6f57cc5063b77d8" args="(const bool &amp;)" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void OpenNN::GradientDescent::set_reserve_elapsed_time_history           </td>
          <td>(</td>
          <td class="paramtype">const bool &amp;&nbsp;</td>
          <td class="paramname"> <em>new_reserve_elapsed_time_history</em>          </td>
          <td>&nbsp;)&nbsp;</td>
          <td></td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
This method makes the elapsed time over the epochs to be reseved or not in memory. This is a vector. <dl compact><dt><b>Parameters:</b></dt><dd>
  <table border="0" cellspacing="2" cellpadding="0">
    <tr><td valign="top"></td><td valign="top"><em>new_reserve_elapsed_time_history</em>&nbsp;</td><td>True if the elapsed time history vector is to be reserved, false otherwise. </td></tr>
  </table>
</dl>

<p>Definition at line <a class="el" href="gradient__descent_8cpp_source.html#l00909">909</a> of file <a class="el" href="gradient__descent_8cpp_source.html">gradient_descent.cpp</a>.</p>

</div>
</div><p>
<a class="anchor" name="a296ed469c45fd0db6a301f120c3b257"></a><!-- doxytag: member="OpenNN::GradientDescent::set_display_period" ref="a296ed469c45fd0db6a301f120c3b257" args="(const unsigned int &amp;)" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void OpenNN::GradientDescent::set_display_period           </td>
          <td>(</td>
          <td class="paramtype">const unsigned int &amp;&nbsp;</td>
          <td class="paramname"> <em>new_display_period</em>          </td>
          <td>&nbsp;)&nbsp;</td>
          <td></td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
This method sets a new number of epochs between the training showing progress. <dl compact><dt><b>Parameters:</b></dt><dd>
  <table border="0" cellspacing="2" cellpadding="0">
    <tr><td valign="top"></td><td valign="top"><em>new_display_period</em>&nbsp;</td><td>Number of epochs between the training showing progress. </td></tr>
  </table>
</dl>

<p>Definition at line <a class="el" href="gradient__descent_8cpp_source.html#l00933">933</a> of file <a class="el" href="gradient__descent_8cpp_source.html">gradient_descent.cpp</a>.</p>

</div>
</div><p>
<a class="anchor" name="c77548469088ea0f6256a531aff79cd1"></a><!-- doxytag: member="OpenNN::GradientDescent::calculate_training_direction" ref="c77548469088ea0f6256a531aff79cd1" args="(const Vector&lt; double &gt; &amp;) const " -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="class_open_n_n_1_1_vector.html">Vector</a>&lt; double &gt; OpenNN::GradientDescent::calculate_training_direction           </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="class_open_n_n_1_1_vector.html">Vector</a>&lt; double &gt; &amp;&nbsp;</td>
          <td class="paramname"> <em>gradient</em>          </td>
          <td>&nbsp;)&nbsp;</td>
          <td> const</td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
This method returns the gradient descent training direction, which is the negative of the normalized gradient. 
<p>

<p>Definition at line <a class="el" href="gradient__descent_8cpp_source.html#l00962">962</a> of file <a class="el" href="gradient__descent_8cpp_source.html">gradient_descent.cpp</a>.</p>

</div>
</div><p>
<a class="anchor" name="35748714df5dcc4f03c642084b5d16cb"></a><!-- doxytag: member="OpenNN::GradientDescent::perform_training" ref="35748714df5dcc4f03c642084b5d16cb" args="(void)" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="struct_open_n_n_1_1_gradient_descent_1_1_gradient_descent_results.html">GradientDescent::GradientDescentResults</a> * OpenNN::GradientDescent::perform_training           </td>
          <td>(</td>
          <td class="paramtype">void&nbsp;</td>
          <td class="paramname">          </td>
          <td>&nbsp;)&nbsp;</td>
          <td><code> [virtual]</code></td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
<dl class="todo" compact><dt><b><a class="el" href="todo.html#_todo000095">Todo:</a></b></dt><dd></dd></dl>

<p>Implements <a class="el" href="class_open_n_n_1_1_training_algorithm.html#3ed4426c63e74939ae52730e3505cfdf">OpenNN::TrainingAlgorithm</a>.</p>

<p>Definition at line <a class="el" href="gradient__descent_8cpp_source.html#l01086">1086</a> of file <a class="el" href="gradient__descent_8cpp_source.html">gradient_descent.cpp</a>.</p>

</div>
</div><p>
<a class="anchor" name="9feb1b4939513b37febe25ed0adbba2f"></a><!-- doxytag: member="OpenNN::GradientDescent::write_training_algorithm_type" ref="9feb1b4939513b37febe25ed0adbba2f" args="(void) const " -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">std::string OpenNN::GradientDescent::write_training_algorithm_type           </td>
          <td>(</td>
          <td class="paramtype">void&nbsp;</td>
          <td class="paramname">          </td>
          <td>&nbsp;)&nbsp;</td>
          <td> const<code> [virtual]</code></td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
This method writes a string with the type of training algoritm. 
<p>

<p>Reimplemented from <a class="el" href="class_open_n_n_1_1_training_algorithm.html#a24b5c6f5571d780d1b61c684fd0eb2d">OpenNN::TrainingAlgorithm</a>.</p>

<p>Definition at line <a class="el" href="gradient__descent_8cpp_source.html#l01408">1408</a> of file <a class="el" href="gradient__descent_8cpp_source.html">gradient_descent.cpp</a>.</p>

</div>
</div><p>
<a class="anchor" name="2d790ddb6884db0ec6d0a7fe7ebd6768"></a><!-- doxytag: member="OpenNN::GradientDescent::to_XML" ref="2d790ddb6884db0ec6d0a7fe7ebd6768" args="(void) const " -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">TiXmlElement * OpenNN::GradientDescent::to_XML           </td>
          <td>(</td>
          <td class="paramtype">void&nbsp;</td>
          <td class="paramname">          </td>
          <td>&nbsp;)&nbsp;</td>
          <td> const<code> [virtual]</code></td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
This method prints to the screen the training parameters, the stopping criteria and other user stuff concerning the gradient descent object. 
<p>Reimplemented from <a class="el" href="class_open_n_n_1_1_training_algorithm.html#ed80f94b3ad79dbe95c49097c9302be8">OpenNN::TrainingAlgorithm</a>.</p>

<p>Definition at line <a class="el" href="gradient__descent_8cpp_source.html#l01419">1419</a> of file <a class="el" href="gradient__descent_8cpp_source.html">gradient_descent.cpp</a>.</p>

</div>
</div><p>
<a class="anchor" name="ee5b6a70c80e41df05f583193ec52045"></a><!-- doxytag: member="OpenNN::GradientDescent::from_XML" ref="ee5b6a70c80e41df05f583193ec52045" args="(TiXmlElement *)" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void OpenNN::GradientDescent::from_XML           </td>
          <td>(</td>
          <td class="paramtype">TiXmlElement *&nbsp;</td>
          <td class="paramname"> <em>training_algorithm_element</em>          </td>
          <td>&nbsp;)&nbsp;</td>
          <td><code> [virtual]</code></td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
This method loads a training algorithm object from a XML element. <dl compact><dt><b>Parameters:</b></dt><dd>
  <table border="0" cellspacing="2" cellpadding="0">
    <tr><td valign="top"></td><td valign="top"><em>training_algorithm_element</em>&nbsp;</td><td>Pointer to a Tiny XML element containing the training algorithm members. </td></tr>
  </table>
</dl>

<p>Reimplemented from <a class="el" href="class_open_n_n_1_1_training_algorithm.html#29d7f1ea8665e574f31aee359a58f505">OpenNN::TrainingAlgorithm</a>.</p>

<p>Definition at line <a class="el" href="gradient__descent_8cpp_source.html#l01699">1699</a> of file <a class="el" href="gradient__descent_8cpp_source.html">gradient_descent.cpp</a>.</p>

</div>
</div><p>
<hr>The documentation for this class was generated from the following files:<ul>
<li><a class="el" href="gradient__descent_8h_source.html">gradient_descent.h</a><li><a class="el" href="gradient__descent_8cpp_source.html">gradient_descent.cpp</a></ul>
</div>
<hr size="1"><address style="text-align: right;"><small>Generated on Sun Aug 26 11:58:20 2012 for OpenNN by&nbsp;
<a href="http://www.doxygen.org/index.html">
<img src="doxygen.png" alt="doxygen" align="middle" border="0"></a> 1.5.9 </small></address>
</body>
</html>
