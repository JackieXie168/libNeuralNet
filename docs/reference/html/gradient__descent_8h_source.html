<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html><head><meta http-equiv="Content-Type" content="text/html;charset=UTF-8">
<title>OpenNN: gradient_descent.h Source File</title>
<link href="tabs.css" rel="stylesheet" type="text/css">
<link href="doxygen.css" rel="stylesheet" type="text/css">
</head><body>
<!-- Generated by Doxygen 1.5.9 -->
<div class="navigation" id="top">
  <div class="tabs">
    <ul>
      <li><a href="index.html"><span>Main&nbsp;Page</span></a></li>
      <li><a href="pages.html"><span>Related&nbsp;Pages</span></a></li>
      <li><a href="annotated.html"><span>Classes</span></a></li>
      <li class="current"><a href="files.html"><span>Files</span></a></li>
    </ul>
  </div>
  <div class="tabs">
    <ul>
      <li><a href="files.html"><span>File&nbsp;List</span></a></li>
    </ul>
  </div>
<h1>gradient_descent.h</h1><div class="fragment"><pre class="fragment"><a name="l00001"></a>00001 <span class="comment">/****************************************************************************************************************/</span>
<a name="l00002"></a>00002 <span class="comment">/*                                                                                                              */</span>
<a name="l00003"></a>00003 <span class="comment">/*   OpenNN: Open Neural Networks Library                                                                       */</span>
<a name="l00004"></a>00004 <span class="comment">/*   www.opennn.cimne.com                                                                                       */</span>
<a name="l00005"></a>00005 <span class="comment">/*                                                                                                              */</span>
<a name="l00006"></a>00006 <span class="comment">/*   G R A D I E N T   D E S C E N T   C L A S S   H E A D E R                                                  */</span>
<a name="l00007"></a>00007 <span class="comment">/*                                                                                                              */</span>
<a name="l00008"></a>00008 <span class="comment">/*   Roberto Lopez                                                                                              */</span>
<a name="l00009"></a>00009 <span class="comment">/*   International Center for Numerical Methods in Engineering (CIMNE)                                          */</span>
<a name="l00010"></a>00010 <span class="comment">/*   Technical University of Catalonia (UPC)                                                                    */</span>
<a name="l00011"></a>00011 <span class="comment">/*   Barcelona, Spain                                                                                           */</span>
<a name="l00012"></a>00012 <span class="comment">/*   E-mail: rlopez@cimne.upc.edu                                                                               */</span>
<a name="l00013"></a>00013 <span class="comment">/*                                                                                                              */</span>
<a name="l00014"></a>00014 <span class="comment">/****************************************************************************************************************/</span>
<a name="l00015"></a>00015 
<a name="l00016"></a>00016 <span class="preprocessor">#ifndef __GRADIENTDESCENT_H__</span>
<a name="l00017"></a>00017 <span class="preprocessor"></span><span class="preprocessor">#define __GRADIENTDESCENT_H__</span>
<a name="l00018"></a>00018 <span class="preprocessor"></span>
<a name="l00019"></a>00019 <span class="comment">// OpenNN includes</span>
<a name="l00020"></a>00020 
<a name="l00021"></a>00021 <span class="preprocessor">#include "../performance_functional/performance_functional.h"</span>
<a name="l00022"></a>00022 
<a name="l00023"></a>00023 <span class="preprocessor">#include "training_algorithm.h"</span>
<a name="l00024"></a>00024 <span class="preprocessor">#include "training_rate_algorithm.h"</span>
<a name="l00025"></a>00025 
<a name="l00026"></a>00026 
<a name="l00027"></a>00027 <span class="keyword">namespace </span>OpenNN
<a name="l00028"></a>00028 {
<a name="l00029"></a>00029 
<a name="l00032"></a>00032 
<a name="l00033"></a><a class="code" href="class_open_n_n_1_1_gradient_descent.html">00033</a> <span class="keyword">class </span><a class="code" href="class_open_n_n_1_1_gradient_descent.html">GradientDescent</a> : <span class="keyword">public</span> <a class="code" href="class_open_n_n_1_1_training_algorithm.html">TrainingAlgorithm</a>
<a name="l00034"></a>00034 {
<a name="l00035"></a>00035 
<a name="l00036"></a>00036 <span class="keyword">public</span>:
<a name="l00037"></a>00037 
<a name="l00038"></a>00038    <span class="comment">// DEFAULT CONSTRUCTOR</span>
<a name="l00039"></a>00039 
<a name="l00040"></a>00040    <span class="keyword">explicit</span> <a class="code" href="class_open_n_n_1_1_gradient_descent.html#d4c53dcaa3371726975a35df1978629c">GradientDescent</a>(<span class="keywordtype">void</span>); 
<a name="l00041"></a>00041 
<a name="l00042"></a>00042    <span class="comment">// PERFORMANCE FUNCTIONAL CONSTRUCTOR</span>
<a name="l00043"></a>00043 
<a name="l00044"></a>00044    <span class="keyword">explicit</span> <a class="code" href="class_open_n_n_1_1_gradient_descent.html#d4c53dcaa3371726975a35df1978629c">GradientDescent</a>(<a class="code" href="class_open_n_n_1_1_performance_functional.html">PerformanceFunctional</a>*);
<a name="l00045"></a>00045 
<a name="l00046"></a>00046    <span class="comment">// XML CONSTRUCTOR</span>
<a name="l00047"></a>00047 
<a name="l00048"></a>00048    <span class="keyword">explicit</span> <a class="code" href="class_open_n_n_1_1_gradient_descent.html#d4c53dcaa3371726975a35df1978629c">GradientDescent</a>(TiXmlElement*); 
<a name="l00049"></a>00049 
<a name="l00050"></a>00050 
<a name="l00051"></a>00051    <span class="comment">// DESTRUCTOR</span>
<a name="l00052"></a>00052 
<a name="l00053"></a>00053    <span class="keyword">virtual</span> <a class="code" href="class_open_n_n_1_1_gradient_descent.html#681a0ffccb2b004a1406dfe500addd8a" title="Destructor.">~GradientDescent</a>(<span class="keywordtype">void</span>);
<a name="l00054"></a>00054 
<a name="l00055"></a>00055    <span class="comment">// STRUCTURES</span>
<a name="l00056"></a>00056 
<a name="l00060"></a>00060 
<a name="l00061"></a><a class="code" href="struct_open_n_n_1_1_gradient_descent_1_1_gradient_descent_results.html">00061</a>    <span class="keyword">struct </span><a class="code" href="struct_open_n_n_1_1_gradient_descent_1_1_gradient_descent_results.html">GradientDescentResults</a> : <span class="keyword">public</span> <a class="code" href="class_open_n_n_1_1_training_algorithm.html">TrainingAlgorithm</a>::<a class="code" href="struct_open_n_n_1_1_training_algorithm_1_1_results.html">Results</a>
<a name="l00062"></a>00062    {                                      
<a name="l00063"></a>00063       <span class="comment">// Training history</span>
<a name="l00064"></a>00064 
<a name="l00066"></a>00066 
<a name="l00067"></a><a class="code" href="struct_open_n_n_1_1_gradient_descent_1_1_gradient_descent_results.html#601013254de93dee73b9f278ca4f87e5">00067</a>       <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt; Vector&lt;double&gt;</a> &gt; <a class="code" href="struct_open_n_n_1_1_gradient_descent_1_1_gradient_descent_results.html#601013254de93dee73b9f278ca4f87e5" title="History of the neural network parameters over the training epochs.">parameters_history</a>;
<a name="l00068"></a>00068 
<a name="l00070"></a>00070 
<a name="l00071"></a><a class="code" href="struct_open_n_n_1_1_gradient_descent_1_1_gradient_descent_results.html#a59d49e7b828f3afc265f7936ad0d482">00071</a>       <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt;double&gt;</a> <a class="code" href="struct_open_n_n_1_1_gradient_descent_1_1_gradient_descent_results.html#a59d49e7b828f3afc265f7936ad0d482" title="History of the parameters norm over the training epochs.">parameters_norm_history</a>;
<a name="l00072"></a>00072 
<a name="l00074"></a>00074 
<a name="l00075"></a><a class="code" href="struct_open_n_n_1_1_gradient_descent_1_1_gradient_descent_results.html#dec274a4e28543f27a56756555b7e696">00075</a>       <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt;double&gt;</a> <a class="code" href="struct_open_n_n_1_1_gradient_descent_1_1_gradient_descent_results.html#dec274a4e28543f27a56756555b7e696" title="History of the performance function evaluation over the training epochs.">evaluation_history</a>;
<a name="l00076"></a>00076 
<a name="l00078"></a>00078 
<a name="l00079"></a><a class="code" href="struct_open_n_n_1_1_gradient_descent_1_1_gradient_descent_results.html#d662b30acce160b20ae6d33be506e74b">00079</a>       <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt;double&gt;</a> <a class="code" href="struct_open_n_n_1_1_gradient_descent_1_1_gradient_descent_results.html#d662b30acce160b20ae6d33be506e74b" title="History of the generalization evaluation over the training epochs.">generalization_evaluation_history</a>;
<a name="l00080"></a>00080 
<a name="l00082"></a>00082 
<a name="l00083"></a><a class="code" href="struct_open_n_n_1_1_gradient_descent_1_1_gradient_descent_results.html#fd665a438eea61c97e9e1cef34be499c">00083</a>       <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt; Vector&lt;double&gt;</a> &gt;  <a class="code" href="struct_open_n_n_1_1_gradient_descent_1_1_gradient_descent_results.html#fd665a438eea61c97e9e1cef34be499c" title="History of the performance function gradient over the training epochs.">gradient_history</a>;
<a name="l00084"></a>00084 
<a name="l00086"></a>00086 
<a name="l00087"></a><a class="code" href="struct_open_n_n_1_1_gradient_descent_1_1_gradient_descent_results.html#16479a6cf522e556aa03ba696a092348">00087</a>       <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt;double&gt;</a> <a class="code" href="struct_open_n_n_1_1_gradient_descent_1_1_gradient_descent_results.html#16479a6cf522e556aa03ba696a092348" title="History of the gradient norm over the training epochs.">gradient_norm_history</a>;
<a name="l00088"></a>00088 
<a name="l00090"></a>00090 
<a name="l00091"></a><a class="code" href="struct_open_n_n_1_1_gradient_descent_1_1_gradient_descent_results.html#18aa4be2d6ad1b117e42999b6917b302">00091</a>       <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt; Vector&lt;double&gt;</a> &gt;  <a class="code" href="struct_open_n_n_1_1_gradient_descent_1_1_gradient_descent_results.html#18aa4be2d6ad1b117e42999b6917b302" title="History of the random search training direction over the training epochs.">training_direction_history</a>;
<a name="l00092"></a>00092 
<a name="l00094"></a>00094 
<a name="l00095"></a><a class="code" href="struct_open_n_n_1_1_gradient_descent_1_1_gradient_descent_results.html#bc17ab2b4182b9433bb1727361e5577a">00095</a>       <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt;double&gt;</a> <a class="code" href="struct_open_n_n_1_1_gradient_descent_1_1_gradient_descent_results.html#bc17ab2b4182b9433bb1727361e5577a" title="History of the random search training rate over the training epochs.">training_rate_history</a>;
<a name="l00096"></a>00096 
<a name="l00098"></a>00098 
<a name="l00099"></a><a class="code" href="struct_open_n_n_1_1_gradient_descent_1_1_gradient_descent_results.html#06298caa84b2778d0cca72a5a0a46e99">00099</a>       <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt;double&gt;</a> <a class="code" href="struct_open_n_n_1_1_gradient_descent_1_1_gradient_descent_results.html#06298caa84b2778d0cca72a5a0a46e99" title="History of the elapsed time over the training epochs.">elapsed_time_history</a>;
<a name="l00100"></a>00100 
<a name="l00101"></a>00101       <span class="comment">// Final values</span>
<a name="l00102"></a>00102 
<a name="l00104"></a>00104 
<a name="l00105"></a><a class="code" href="struct_open_n_n_1_1_gradient_descent_1_1_gradient_descent_results.html#19913f591f6b1b064393103173a71f02">00105</a>       <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt;double&gt;</a> <a class="code" href="struct_open_n_n_1_1_gradient_descent_1_1_gradient_descent_results.html#19913f591f6b1b064393103173a71f02" title="Final neural network parameters vector.">final_parameters</a>;
<a name="l00106"></a>00106 
<a name="l00108"></a>00108 
<a name="l00109"></a><a class="code" href="struct_open_n_n_1_1_gradient_descent_1_1_gradient_descent_results.html#c1282abf48f6accc025cdea89592d306">00109</a>       <span class="keywordtype">double</span> <a class="code" href="struct_open_n_n_1_1_gradient_descent_1_1_gradient_descent_results.html#c1282abf48f6accc025cdea89592d306" title="Final neural network parameters norm.">final_parameters_norm</a>;
<a name="l00110"></a>00110 
<a name="l00112"></a>00112 
<a name="l00113"></a><a class="code" href="struct_open_n_n_1_1_gradient_descent_1_1_gradient_descent_results.html#00de53f68eaee921fb1c5b6e80b11d0b">00113</a>       <span class="keywordtype">double</span> <a class="code" href="struct_open_n_n_1_1_gradient_descent_1_1_gradient_descent_results.html#00de53f68eaee921fb1c5b6e80b11d0b" title="Final performance function evaluation.">final_evaluation</a>;
<a name="l00114"></a>00114 
<a name="l00116"></a>00116 
<a name="l00117"></a><a class="code" href="struct_open_n_n_1_1_gradient_descent_1_1_gradient_descent_results.html#0daf21a22a7577206cdd6e7a0e93dae8">00117</a>       <span class="keywordtype">double</span> <a class="code" href="struct_open_n_n_1_1_gradient_descent_1_1_gradient_descent_results.html#0daf21a22a7577206cdd6e7a0e93dae8" title="Final generalization evaluation.">final_generalization_evaluation</a>;
<a name="l00118"></a>00118 
<a name="l00120"></a>00120 
<a name="l00121"></a><a class="code" href="struct_open_n_n_1_1_gradient_descent_1_1_gradient_descent_results.html#a81659690fca80c94b2b6f30809265bc">00121</a>       <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt;double&gt;</a> <a class="code" href="struct_open_n_n_1_1_gradient_descent_1_1_gradient_descent_results.html#a81659690fca80c94b2b6f30809265bc" title="Final performance function gradient.">final_gradient</a>;
<a name="l00122"></a>00122 
<a name="l00124"></a>00124 
<a name="l00125"></a><a class="code" href="struct_open_n_n_1_1_gradient_descent_1_1_gradient_descent_results.html#a490eb7ff55a14878c3c1b59527bc83a">00125</a>       <span class="keywordtype">double</span> <a class="code" href="struct_open_n_n_1_1_gradient_descent_1_1_gradient_descent_results.html#a490eb7ff55a14878c3c1b59527bc83a" title="Final gradient norm.">final_gradient_norm</a>;
<a name="l00126"></a>00126 
<a name="l00128"></a>00128 
<a name="l00129"></a><a class="code" href="struct_open_n_n_1_1_gradient_descent_1_1_gradient_descent_results.html#71e98247c268cb559acd55c307a5522e">00129</a>       <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt;double&gt;</a> <a class="code" href="struct_open_n_n_1_1_gradient_descent_1_1_gradient_descent_results.html#71e98247c268cb559acd55c307a5522e" title="Final gradient descent training direction.">final_training_direction</a>;
<a name="l00130"></a>00130 
<a name="l00132"></a>00132 
<a name="l00133"></a><a class="code" href="struct_open_n_n_1_1_gradient_descent_1_1_gradient_descent_results.html#ba19e2c18c9d1f7e6c71fc4b31173ceb">00133</a>       <span class="keywordtype">double</span> <a class="code" href="struct_open_n_n_1_1_gradient_descent_1_1_gradient_descent_results.html#ba19e2c18c9d1f7e6c71fc4b31173ceb" title="Final gradient descent training rate.">final_training_rate</a>;
<a name="l00134"></a>00134 
<a name="l00136"></a>00136 
<a name="l00137"></a><a class="code" href="struct_open_n_n_1_1_gradient_descent_1_1_gradient_descent_results.html#817a27b0e38ee3bfbf9340bacfafe526">00137</a>       <span class="keywordtype">double</span> <a class="code" href="struct_open_n_n_1_1_gradient_descent_1_1_gradient_descent_results.html#817a27b0e38ee3bfbf9340bacfafe526" title="Elapsed time of the training process.">elapsed_time</a>;
<a name="l00138"></a>00138 
<a name="l00139"></a>00139       <span class="keywordtype">void</span> <a class="code" href="struct_open_n_n_1_1_gradient_descent_1_1_gradient_descent_results.html#899325ad55f53de29083af88a0f6e6a3">resize_training_history</a>(<span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span>&amp;);
<a name="l00140"></a>00140       std::string <a class="code" href="struct_open_n_n_1_1_gradient_descent_1_1_gradient_descent_results.html#2dd38073cfa1e2a36947cd51c52a082f" title="This method returns a string representation of the results structure.">to_string</a>(<span class="keywordtype">void</span>) <span class="keyword">const</span>;
<a name="l00141"></a>00141    };
<a name="l00142"></a>00142 
<a name="l00143"></a>00143    <span class="comment">// METHODS</span>
<a name="l00144"></a>00144 
<a name="l00145"></a>00145    <span class="keyword">const</span> <a class="code" href="class_open_n_n_1_1_training_rate_algorithm.html">TrainingRateAlgorithm</a>&amp; <a class="code" href="class_open_n_n_1_1_gradient_descent.html#f56fbbae486b692bb84d4e0da4b0f0f8" title="This method returns a constant reference to the training rate algorithm object inside...">get_training_rate_algorithm</a>(<span class="keywordtype">void</span>) <span class="keyword">const</span>;
<a name="l00146"></a>00146    <a class="code" href="class_open_n_n_1_1_training_rate_algorithm.html">TrainingRateAlgorithm</a>* <a class="code" href="class_open_n_n_1_1_gradient_descent.html#dc28271b363aad570eaa0a3ab33a4db0" title="This method returns a pointer to the training rate algorithm object inside the gradient...">get_training_rate_algorithm_pointer</a>(<span class="keywordtype">void</span>);
<a name="l00147"></a>00147 
<a name="l00148"></a>00148    <span class="comment">// Training parameters</span>
<a name="l00149"></a>00149 
<a name="l00150"></a>00150    <span class="keyword">const</span> <span class="keywordtype">double</span>&amp; <a class="code" href="class_open_n_n_1_1_gradient_descent.html#8c79c02292682be10175dd88e49df847">get_warning_parameters_norm</a>(<span class="keywordtype">void</span>) <span class="keyword">const</span>;
<a name="l00151"></a>00151    <span class="keyword">const</span> <span class="keywordtype">double</span>&amp; <a class="code" href="class_open_n_n_1_1_gradient_descent.html#d670d10c866f2db246824998bc58b103">get_warning_gradient_norm</a>(<span class="keywordtype">void</span>) <span class="keyword">const</span>;
<a name="l00152"></a>00152    <span class="keyword">const</span> <span class="keywordtype">double</span>&amp; <a class="code" href="class_open_n_n_1_1_gradient_descent.html#cff823bf71a1fbc7df17939ddab9912b">get_warning_training_rate</a>(<span class="keywordtype">void</span>) <span class="keyword">const</span>;
<a name="l00153"></a>00153 
<a name="l00154"></a>00154    <span class="keyword">const</span> <span class="keywordtype">double</span>&amp; <a class="code" href="class_open_n_n_1_1_gradient_descent.html#abf083d521b38d878afc58b7cf744ad9">get_error_parameters_norm</a>(<span class="keywordtype">void</span>) <span class="keyword">const</span>;
<a name="l00155"></a>00155    <span class="keyword">const</span> <span class="keywordtype">double</span>&amp; <a class="code" href="class_open_n_n_1_1_gradient_descent.html#5d28f85181e21d4c074bb1871206fb5c">get_error_gradient_norm</a>(<span class="keywordtype">void</span>) <span class="keyword">const</span>;
<a name="l00156"></a>00156    <span class="keyword">const</span> <span class="keywordtype">double</span>&amp; <a class="code" href="class_open_n_n_1_1_gradient_descent.html#43c43e8fa25ece6586133dbbaf5403c4">get_error_training_rate</a>(<span class="keywordtype">void</span>) <span class="keyword">const</span>;
<a name="l00157"></a>00157 
<a name="l00158"></a>00158    <span class="comment">// Stopping criteria</span>
<a name="l00159"></a>00159 
<a name="l00160"></a>00160    <span class="keyword">const</span> <span class="keywordtype">double</span>&amp; <a class="code" href="class_open_n_n_1_1_gradient_descent.html#977e8321cd4b1027a2d47bd10bcf47ca" title="This method returns the minimum norm of the parameter increment vector used as a...">get_minimum_parameters_increment_norm</a>(<span class="keywordtype">void</span>) <span class="keyword">const</span>;
<a name="l00161"></a>00161 
<a name="l00162"></a>00162    <span class="keyword">const</span> <span class="keywordtype">double</span>&amp; <a class="code" href="class_open_n_n_1_1_gradient_descent.html#460c313eb05a471addf301f8691827fb" title="This method returns the minimum performance improvement during training.">get_minimum_performance_increase</a>(<span class="keywordtype">void</span>) <span class="keyword">const</span>;
<a name="l00163"></a>00163    <span class="keyword">const</span> <span class="keywordtype">double</span>&amp; <a class="code" href="class_open_n_n_1_1_gradient_descent.html#b2a6b927e38a1dfe173bb866f27d2b96">get_performance_goal</a>(<span class="keywordtype">void</span>) <span class="keyword">const</span>;
<a name="l00164"></a>00164    <span class="keyword">const</span> <span class="keywordtype">double</span>&amp; <a class="code" href="class_open_n_n_1_1_gradient_descent.html#096b7ba798dd03e82670ea5263e194b5">get_gradient_norm_goal</a>(<span class="keywordtype">void</span>) <span class="keyword">const</span>;
<a name="l00165"></a>00165    <span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span>&amp; <a class="code" href="class_open_n_n_1_1_gradient_descent.html#ef2c9be7d3ae74c843117414c4588be7" title="This method returns the maximum number of generalization failures during the training...">get_maximum_generalization_evaluation_decreases</a>(<span class="keywordtype">void</span>) <span class="keyword">const</span>;
<a name="l00166"></a>00166 
<a name="l00167"></a>00167    <span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span>&amp; <a class="code" href="class_open_n_n_1_1_gradient_descent.html#7d2670b88ec8ba50df21b9a0763b5d04" title="This method returns the maximum number of epochs for training.">get_maximum_epochs_number</a>(<span class="keywordtype">void</span>) <span class="keyword">const</span>;
<a name="l00168"></a>00168    <span class="keyword">const</span> <span class="keywordtype">double</span>&amp; <a class="code" href="class_open_n_n_1_1_gradient_descent.html#e8fe1dd09d144f2ece993cf9338f5830" title="This method returns the maximum training time.">get_maximum_time</a>(<span class="keywordtype">void</span>) <span class="keyword">const</span>;
<a name="l00169"></a>00169 
<a name="l00170"></a>00170    <span class="comment">// Reserve training history</span>
<a name="l00171"></a>00171 
<a name="l00172"></a>00172    <span class="keyword">const</span> <span class="keywordtype">bool</span>&amp; <a class="code" href="class_open_n_n_1_1_gradient_descent.html#0adf17968a23452099c3a3af7788de07" title="This method returns true if the parameters history matrix is to be reserved, and...">get_reserve_parameters_history</a>(<span class="keywordtype">void</span>) <span class="keyword">const</span>;
<a name="l00173"></a>00173    <span class="keyword">const</span> <span class="keywordtype">bool</span>&amp; <a class="code" href="class_open_n_n_1_1_gradient_descent.html#a34afdc9f24b77546a0417c2136fa005" title="This method returns true if the parameters norm history vector is to be reserved...">get_reserve_parameters_norm_history</a>(<span class="keywordtype">void</span>) <span class="keyword">const</span>;
<a name="l00174"></a>00174 
<a name="l00175"></a>00175    <span class="keyword">const</span> <span class="keywordtype">bool</span>&amp; <a class="code" href="class_open_n_n_1_1_gradient_descent.html#4a117b0b0bb4eb10d78d397aaa2dc2ff" title="This method returns true if the evaluation history vector is to be reserved, and...">get_reserve_evaluation_history</a>(<span class="keywordtype">void</span>) <span class="keyword">const</span>;
<a name="l00176"></a>00176    <span class="keyword">const</span> <span class="keywordtype">bool</span>&amp; <a class="code" href="class_open_n_n_1_1_gradient_descent.html#6c78744fa192aee34b9bbe2fd7419ed1" title="This method returns true if the gradient history vector of vectors is to be reserved...">get_reserve_gradient_history</a>(<span class="keywordtype">void</span>) <span class="keyword">const</span>;
<a name="l00177"></a>00177    <span class="keyword">const</span> <span class="keywordtype">bool</span>&amp; <a class="code" href="class_open_n_n_1_1_gradient_descent.html#b0eef1b50c1003bf779b3f7658e0ac8f" title="This method returns true if the gradient norm history vector is to be reserved, and...">get_reserve_gradient_norm_history</a>(<span class="keywordtype">void</span>) <span class="keyword">const</span>;
<a name="l00178"></a>00178    <span class="keyword">const</span> <span class="keywordtype">bool</span>&amp; <a class="code" href="class_open_n_n_1_1_gradient_descent.html#e8eda1d13c5f4fd1aca52e9971336730" title="This method returns true if the Generalization evaluation history vector is to be...">get_reserve_generalization_evaluation_history</a>(<span class="keywordtype">void</span>) <span class="keyword">const</span>;
<a name="l00179"></a>00179 
<a name="l00180"></a>00180    <span class="keyword">const</span> <span class="keywordtype">bool</span>&amp; <a class="code" href="class_open_n_n_1_1_gradient_descent.html#003543fe0d6f7a5d1bfae52837b19d8a" title="This method returns true if the training direction history matrix is to be reserved...">get_reserve_training_direction_history</a>(<span class="keywordtype">void</span>) <span class="keyword">const</span>;
<a name="l00181"></a>00181    <span class="keyword">const</span> <span class="keywordtype">bool</span>&amp; <a class="code" href="class_open_n_n_1_1_gradient_descent.html#038114122cf181642076b7e76e494abc" title="This method returns true if the training rate history vector is to be reserved, and...">get_reserve_training_rate_history</a>(<span class="keywordtype">void</span>) <span class="keyword">const</span>;
<a name="l00182"></a>00182    <span class="keyword">const</span> <span class="keywordtype">bool</span>&amp; <a class="code" href="class_open_n_n_1_1_gradient_descent.html#b1721d85c7aab1ee42ee55ec24e296c5" title="This method returns true if the elapsed time history vector is to be reserved, and...">get_reserve_elapsed_time_history</a>(<span class="keywordtype">void</span>) <span class="keyword">const</span>;
<a name="l00183"></a>00183 
<a name="l00184"></a>00184    <span class="comment">// Utilities</span>
<a name="l00185"></a>00185 
<a name="l00186"></a>00186    <span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span>&amp; <a class="code" href="class_open_n_n_1_1_gradient_descent.html#0598d1a344e0b4a0589998c3402ff22a" title="This method returns the number of epochs between the training showing progress.">get_display_period</a>(<span class="keywordtype">void</span>) <span class="keyword">const</span>;
<a name="l00187"></a>00187 
<a name="l00188"></a>00188    <span class="comment">// Set methods</span>
<a name="l00189"></a>00189 
<a name="l00190"></a>00190    <span class="keywordtype">void</span> <a class="code" href="class_open_n_n_1_1_gradient_descent.html#3e29b2699a9b3b4eee80d17e493a3c6d">set_training_rate_algorithm</a>(<span class="keyword">const</span> <a class="code" href="class_open_n_n_1_1_training_rate_algorithm.html">TrainingRateAlgorithm</a>&amp;);
<a name="l00191"></a>00191 
<a name="l00192"></a>00192 
<a name="l00193"></a>00193    <span class="keywordtype">void</span> <a class="code" href="class_open_n_n_1_1_gradient_descent.html#de5a4d5ec6b048ca182ba2e17e182055" title="This method sets the members of the training algorithm object to their default values...">set_default</a>(<span class="keywordtype">void</span>);
<a name="l00194"></a>00194 
<a name="l00195"></a>00195    <span class="keywordtype">void</span> <a class="code" href="class_open_n_n_1_1_gradient_descent.html#8b7860afbf36d0aac837091f35a63e84">set_reserve_all_training_history</a>(<span class="keyword">const</span> <span class="keywordtype">bool</span>&amp;);
<a name="l00196"></a>00196 
<a name="l00197"></a>00197 
<a name="l00198"></a>00198    <span class="comment">// Training parameters</span>
<a name="l00199"></a>00199 
<a name="l00200"></a>00200    <span class="keywordtype">void</span> <a class="code" href="class_open_n_n_1_1_gradient_descent.html#c525a49652ff909ec76613b721e33739">set_warning_parameters_norm</a>(<span class="keyword">const</span> <span class="keywordtype">double</span>&amp;);
<a name="l00201"></a>00201    <span class="keywordtype">void</span> <a class="code" href="class_open_n_n_1_1_gradient_descent.html#c7f1c7a84ab5067aa2550b3e36537c21">set_warning_gradient_norm</a>(<span class="keyword">const</span> <span class="keywordtype">double</span>&amp;);
<a name="l00202"></a>00202    <span class="keywordtype">void</span> <a class="code" href="class_open_n_n_1_1_gradient_descent.html#9359ff2faa9eab75167a5867381a6b34">set_warning_training_rate</a>(<span class="keyword">const</span> <span class="keywordtype">double</span>&amp;);
<a name="l00203"></a>00203 
<a name="l00204"></a>00204    <span class="keywordtype">void</span> <a class="code" href="class_open_n_n_1_1_gradient_descent.html#2625e879f726b1501ce33ab5710bbb88">set_error_parameters_norm</a>(<span class="keyword">const</span> <span class="keywordtype">double</span>&amp;);
<a name="l00205"></a>00205    <span class="keywordtype">void</span> <a class="code" href="class_open_n_n_1_1_gradient_descent.html#e8d1a6991a7a735195ed65b15315d233">set_error_gradient_norm</a>(<span class="keyword">const</span> <span class="keywordtype">double</span>&amp;);
<a name="l00206"></a>00206    <span class="keywordtype">void</span> <a class="code" href="class_open_n_n_1_1_gradient_descent.html#1d3b83e0e926af808f2d6a3b2bde050c">set_error_training_rate</a>(<span class="keyword">const</span> <span class="keywordtype">double</span>&amp;);
<a name="l00207"></a>00207 
<a name="l00208"></a>00208    <span class="comment">// Stopping criteria</span>
<a name="l00209"></a>00209 
<a name="l00210"></a>00210    <span class="keywordtype">void</span> <a class="code" href="class_open_n_n_1_1_gradient_descent.html#6ebdcab74360e712408d2b5f734cc2d8">set_minimum_parameters_increment_norm</a>(<span class="keyword">const</span> <span class="keywordtype">double</span>&amp;);
<a name="l00211"></a>00211 
<a name="l00212"></a>00212    <span class="keywordtype">void</span> <a class="code" href="class_open_n_n_1_1_gradient_descent.html#a1a12c07c1db1420bb59f58c3a17fea4">set_minimum_performance_increase</a>(<span class="keyword">const</span> <span class="keywordtype">double</span>&amp;);
<a name="l00213"></a>00213    <span class="keywordtype">void</span> <a class="code" href="class_open_n_n_1_1_gradient_descent.html#8e10381a376476d92e3c96a56a7cf257">set_performance_goal</a>(<span class="keyword">const</span> <span class="keywordtype">double</span>&amp;);
<a name="l00214"></a>00214    <span class="keywordtype">void</span> <a class="code" href="class_open_n_n_1_1_gradient_descent.html#1ad68485a9faa5a39c134b4177551c48">set_gradient_norm_goal</a>(<span class="keyword">const</span> <span class="keywordtype">double</span>&amp;);
<a name="l00215"></a>00215    <span class="keywordtype">void</span> <a class="code" href="class_open_n_n_1_1_gradient_descent.html#de9212832bd5d3a23f751d830f153e8a">set_maximum_generalization_evaluation_decreases</a>(<span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span>&amp;);
<a name="l00216"></a>00216 
<a name="l00217"></a>00217    <span class="keywordtype">void</span> <a class="code" href="class_open_n_n_1_1_gradient_descent.html#f66661bb709e3b68c748a4307e8bee45">set_maximum_epochs_number</a>(<span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span>&amp;);
<a name="l00218"></a>00218    <span class="keywordtype">void</span> <a class="code" href="class_open_n_n_1_1_gradient_descent.html#79b6c48c3f392baeaabff840d22cb5b3">set_maximum_time</a>(<span class="keyword">const</span> <span class="keywordtype">double</span>&amp;);
<a name="l00219"></a>00219 
<a name="l00220"></a>00220    <span class="comment">// Reserve training history</span>
<a name="l00221"></a>00221 
<a name="l00222"></a>00222    <span class="keywordtype">void</span> <a class="code" href="class_open_n_n_1_1_gradient_descent.html#3d828a36bf0df6069f04d5c7ac2eeb51">set_reserve_parameters_history</a>(<span class="keyword">const</span> <span class="keywordtype">bool</span>&amp;);
<a name="l00223"></a>00223    <span class="keywordtype">void</span> <a class="code" href="class_open_n_n_1_1_gradient_descent.html#daf7e1540cc81138bd541bee36269464">set_reserve_parameters_norm_history</a>(<span class="keyword">const</span> <span class="keywordtype">bool</span>&amp;);
<a name="l00224"></a>00224 
<a name="l00225"></a>00225    <span class="keywordtype">void</span> <a class="code" href="class_open_n_n_1_1_gradient_descent.html#aa21d82bbe0fd3bb31295e97da9593c9">set_reserve_evaluation_history</a>(<span class="keyword">const</span> <span class="keywordtype">bool</span>&amp;);
<a name="l00226"></a>00226    <span class="keywordtype">void</span> <a class="code" href="class_open_n_n_1_1_gradient_descent.html#8ec7e29c6611ca1d0e3d03d543d62ce7">set_reserve_gradient_history</a>(<span class="keyword">const</span> <span class="keywordtype">bool</span>&amp;);
<a name="l00227"></a>00227    <span class="keywordtype">void</span> <a class="code" href="class_open_n_n_1_1_gradient_descent.html#c35bd72977a353a1edbc01178c1965e1">set_reserve_gradient_norm_history</a>(<span class="keyword">const</span> <span class="keywordtype">bool</span>&amp;);
<a name="l00228"></a>00228    <span class="keywordtype">void</span> <a class="code" href="class_open_n_n_1_1_gradient_descent.html#05e2aedc5889583d5cfcdd3e69ea24ce">set_reserve_generalization_evaluation_history</a>(<span class="keyword">const</span> <span class="keywordtype">bool</span>&amp;);
<a name="l00229"></a>00229 
<a name="l00230"></a>00230    <span class="keywordtype">void</span> <a class="code" href="class_open_n_n_1_1_gradient_descent.html#9c2553d655440601e779a3d093de593c">set_reserve_training_direction_history</a>(<span class="keyword">const</span> <span class="keywordtype">bool</span>&amp;);
<a name="l00231"></a>00231    <span class="keywordtype">void</span> <a class="code" href="class_open_n_n_1_1_gradient_descent.html#7adc9d5149d9599aa3df9d254974d503">set_reserve_training_rate_history</a>(<span class="keyword">const</span> <span class="keywordtype">bool</span>&amp;);
<a name="l00232"></a>00232    <span class="keywordtype">void</span> <a class="code" href="class_open_n_n_1_1_gradient_descent.html#8e98003d637460b1a6f57cc5063b77d8">set_reserve_elapsed_time_history</a>(<span class="keyword">const</span> <span class="keywordtype">bool</span>&amp;);
<a name="l00233"></a>00233 
<a name="l00234"></a>00234    <span class="comment">// Utilities</span>
<a name="l00235"></a>00235 
<a name="l00236"></a>00236    <span class="keywordtype">void</span> <a class="code" href="class_open_n_n_1_1_gradient_descent.html#a296ed469c45fd0db6a301f120c3b257">set_display_period</a>(<span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span>&amp;);
<a name="l00237"></a>00237 
<a name="l00238"></a>00238    <span class="comment">// Training methods</span>
<a name="l00239"></a>00239 
<a name="l00240"></a>00240    <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt;double&gt;</a> <a class="code" href="class_open_n_n_1_1_gradient_descent.html#c77548469088ea0f6256a531aff79cd1" title="This method returns the gradient descent training direction, which is the negative...">calculate_training_direction</a>(<span class="keyword">const</span> <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt;double&gt;</a>&amp;) <span class="keyword">const</span>;
<a name="l00241"></a>00241 
<a name="l00242"></a>00242    <a class="code" href="struct_open_n_n_1_1_gradient_descent_1_1_gradient_descent_results.html">GradientDescentResults</a>* <a class="code" href="class_open_n_n_1_1_gradient_descent.html#35748714df5dcc4f03c642084b5d16cb">perform_training</a>(<span class="keywordtype">void</span>);
<a name="l00243"></a>00243 
<a name="l00244"></a>00244    std::string <a class="code" href="class_open_n_n_1_1_gradient_descent.html#9feb1b4939513b37febe25ed0adbba2f" title="This method writes a string with the type of training algoritm.">write_training_algorithm_type</a>(<span class="keywordtype">void</span>) <span class="keyword">const</span>;
<a name="l00245"></a>00245 
<a name="l00246"></a>00246    <span class="comment">// Serialization methods</span>
<a name="l00247"></a>00247 
<a name="l00248"></a>00248    TiXmlElement* <a class="code" href="class_open_n_n_1_1_gradient_descent.html#2d790ddb6884db0ec6d0a7fe7ebd6768">to_XML</a>(<span class="keywordtype">void</span>) <span class="keyword">const</span>;
<a name="l00249"></a>00249    <span class="keywordtype">void</span> <a class="code" href="class_open_n_n_1_1_gradient_descent.html#ee5b6a70c80e41df05f583193ec52045">from_XML</a>(TiXmlElement*);
<a name="l00250"></a>00250 
<a name="l00251"></a>00251 <span class="keyword">private</span>:
<a name="l00252"></a>00252 
<a name="l00253"></a>00253    <span class="comment">// TRAINING OPERATORS</span>
<a name="l00254"></a>00254 
<a name="l00256"></a>00256 
<a name="l00257"></a>00257    <a class="code" href="class_open_n_n_1_1_training_rate_algorithm.html">TrainingRateAlgorithm</a> training_rate_algorithm;
<a name="l00258"></a>00258 
<a name="l00259"></a>00259    <span class="comment">// TRAINING PARAMETERS</span>
<a name="l00260"></a>00260 
<a name="l00262"></a>00262 
<a name="l00263"></a>00263    <span class="keywordtype">double</span> warning_parameters_norm;
<a name="l00264"></a>00264 
<a name="l00266"></a>00266 
<a name="l00267"></a>00267    <span class="keywordtype">double</span> warning_gradient_norm;   
<a name="l00268"></a>00268 
<a name="l00270"></a>00270 
<a name="l00271"></a>00271    <span class="keywordtype">double</span> warning_training_rate;
<a name="l00272"></a>00272 
<a name="l00274"></a>00274    
<a name="l00275"></a>00275    <span class="keywordtype">double</span> error_parameters_norm;
<a name="l00276"></a>00276 
<a name="l00278"></a>00278 
<a name="l00279"></a>00279    <span class="keywordtype">double</span> error_gradient_norm;
<a name="l00280"></a>00280 
<a name="l00282"></a>00282 
<a name="l00283"></a>00283    <span class="keywordtype">double</span> error_training_rate;
<a name="l00284"></a>00284 
<a name="l00285"></a>00285 
<a name="l00286"></a>00286    <span class="comment">// STOPPING CRITERIA</span>
<a name="l00287"></a>00287 
<a name="l00289"></a>00289 
<a name="l00290"></a>00290    <span class="keywordtype">double</span> minimum_parameters_increment_norm;
<a name="l00291"></a>00291 
<a name="l00293"></a>00293 
<a name="l00294"></a>00294    <span class="keywordtype">double</span> minimum_performance_increase;
<a name="l00295"></a>00295 
<a name="l00297"></a>00297 
<a name="l00298"></a>00298    <span class="keywordtype">double</span> performance_goal;
<a name="l00299"></a>00299 
<a name="l00301"></a>00301 
<a name="l00302"></a>00302    <span class="keywordtype">double</span> gradient_norm_goal;
<a name="l00303"></a>00303 
<a name="l00304"></a>00304    <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> maximum_generalization_evaluation_decreases;
<a name="l00305"></a>00305 
<a name="l00307"></a>00307 
<a name="l00308"></a>00308    <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> maximum_epochs_number;
<a name="l00309"></a>00309 
<a name="l00311"></a>00311 
<a name="l00312"></a>00312    <span class="keywordtype">double</span> maximum_time;
<a name="l00313"></a>00313 
<a name="l00314"></a>00314    <span class="comment">// TRAINING HISTORY</span>
<a name="l00315"></a>00315 
<a name="l00317"></a>00317 
<a name="l00318"></a>00318    <span class="keywordtype">bool</span> reserve_parameters_history;
<a name="l00319"></a>00319 
<a name="l00321"></a>00321 
<a name="l00322"></a>00322    <span class="keywordtype">bool</span> reserve_parameters_norm_history;
<a name="l00323"></a>00323 
<a name="l00325"></a>00325 
<a name="l00326"></a>00326    <span class="keywordtype">bool</span> reserve_evaluation_history;
<a name="l00327"></a>00327 
<a name="l00329"></a>00329 
<a name="l00330"></a>00330    <span class="keywordtype">bool</span> reserve_gradient_history;
<a name="l00331"></a>00331 
<a name="l00333"></a>00333 
<a name="l00334"></a>00334    <span class="keywordtype">bool</span> reserve_gradient_norm_history;
<a name="l00335"></a>00335 
<a name="l00337"></a>00337    
<a name="l00338"></a>00338    <span class="keywordtype">bool</span> reserve_training_direction_history;
<a name="l00339"></a>00339 
<a name="l00341"></a>00341 
<a name="l00342"></a>00342    <span class="keywordtype">bool</span> reserve_training_rate_history;
<a name="l00343"></a>00343 
<a name="l00345"></a>00345 
<a name="l00346"></a>00346    <span class="keywordtype">bool</span> reserve_elapsed_time_history;
<a name="l00347"></a>00347 
<a name="l00349"></a>00349 
<a name="l00350"></a>00350    <span class="keywordtype">bool</span> reserve_generalization_evaluation_history;
<a name="l00351"></a>00351 
<a name="l00353"></a>00353 
<a name="l00354"></a>00354    <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> display_period;
<a name="l00355"></a>00355 
<a name="l00356"></a>00356 };
<a name="l00357"></a>00357 
<a name="l00358"></a>00358 }
<a name="l00359"></a>00359 
<a name="l00360"></a>00360 <span class="preprocessor">#endif</span>
</pre></div></div>
<hr size="1"><address style="text-align: right;"><small>Generated on Sun Aug 26 11:58:10 2012 for OpenNN by&nbsp;
<a href="http://www.doxygen.org/index.html">
<img src="doxygen.png" alt="doxygen" align="middle" border="0"></a> 1.5.9 </small></address>
</body>
</html>
