<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.3.1"/>
<title>OpenNN: OpenNN::ConjugateGradient Class Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/javascript">
  $(document).ready(function() { searchBox.OnSelectItem(0); });
</script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectlogo"><img alt="Logo" src="opennn_icon_512x512.png"/></td>
  <td style="padding-left: 0.5em;">
   <div id="projectname">OpenNN
   &#160;<span id="projectnumber">1.0</span>
   </div>
   <div id="projectbrief">Open Neural Networks Library</div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.3.1 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
  <div id="navrow1" class="tabs">
    <ul class="tablist">
      <li><a href="index.html"><span>Main&#160;Page</span></a></li>
      <li><a href="pages.html"><span>Related&#160;Pages</span></a></li>
      <li class="current"><a href="annotated.html"><span>Classes</span></a></li>
      <li><a href="files.html"><span>Files</span></a></li>
      <li>
        <div id="MSearchBox" class="MSearchBoxInactive">
        <span class="left">
          <img id="MSearchSelect" src="search/mag_sel.png"
               onmouseover="return searchBox.OnSearchSelectShow()"
               onmouseout="return searchBox.OnSearchSelectHide()"
               alt=""/>
          <input type="text" id="MSearchField" value="Search" accesskey="S"
               onfocus="searchBox.OnSearchFieldFocus(true)" 
               onblur="searchBox.OnSearchFieldFocus(false)" 
               onkeyup="searchBox.OnSearchFieldChange(event)"/>
          </span><span class="right">
            <a id="MSearchClose" href="javascript:searchBox.CloseResultsWindow()"><img id="MSearchCloseImg" border="0" src="search/close.png" alt=""/></a>
          </span>
        </div>
      </li>
    </ul>
  </div>
  <div id="navrow2" class="tabs2">
    <ul class="tablist">
      <li><a href="annotated.html"><span>Class&#160;List</span></a></li>
      <li><a href="classes.html"><span>Class&#160;Index</span></a></li>
      <li><a href="hierarchy.html"><span>Class&#160;Hierarchy</span></a></li>
      <li><a href="functions.html"><span>Class&#160;Members</span></a></li>
    </ul>
  </div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
<a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(0)"><span class="SelectionMark">&#160;</span>All</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(1)"><span class="SelectionMark">&#160;</span>Classes</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(2)"><span class="SelectionMark">&#160;</span>Functions</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(3)"><span class="SelectionMark">&#160;</span>Variables</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(4)"><span class="SelectionMark">&#160;</span>Enumerations</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(5)"><span class="SelectionMark">&#160;</span>Pages</a></div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><b>OpenNN</b></li><li class="navelem"><a class="el" href="class_open_n_n_1_1_conjugate_gradient.html">ConjugateGradient</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="summary">
<a href="#nested-classes">Classes</a> &#124;
<a href="#pub-types">Public Types</a> &#124;
<a href="#pub-methods">Public Member Functions</a> &#124;
<a href="#pri-attribs">Private Attributes</a> &#124;
<a href="class_open_n_n_1_1_conjugate_gradient-members.html">List of all members</a>  </div>
  <div class="headertitle">
<div class="title">OpenNN::ConjugateGradient Class Reference</div>  </div>
</div><!--header-->
<div class="contents">

<p><code>#include &lt;<a class="el" href="conjugate__gradient_8h_source.html">conjugate_gradient.h</a>&gt;</code></p>
<div class="dynheader">
Inheritance diagram for OpenNN::ConjugateGradient:</div>
<div class="dyncontent">
 <div class="center">
  <img src="class_open_n_n_1_1_conjugate_gradient.png" usemap="#OpenNN::ConjugateGradient_map" alt=""/>
  <map id="OpenNN::ConjugateGradient_map" name="OpenNN::ConjugateGradient_map">
<area href="class_open_n_n_1_1_training_algorithm.html" alt="OpenNN::TrainingAlgorithm" shape="rect" coords="0,0,172,24"/>
</map>
 </div></div>
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="nested-classes"></a>
Classes</h2></td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="struct_open_n_n_1_1_conjugate_gradient_1_1_conjugate_gradient_results.html">ConjugateGradientResults</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="pub-types"></a>
Public Types</h2></td></tr>
<tr class="memitem:a6945bdfb0798a692bc45158307a05423"><td class="memItemLeft" align="right" valign="top">enum &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_conjugate_gradient.html#a6945bdfb0798a692bc45158307a05423">TrainingDirectionMethod</a> { <b>PR</b>, 
<b>FR</b>
 }</td></tr>
<tr class="separator:a6945bdfb0798a692bc45158307a05423"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="pub-methods"></a>
Public Member Functions</h2></td></tr>
<tr class="memitem:a1a583e3f482717a40656a18a0f9071ea"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_conjugate_gradient.html#a1a583e3f482717a40656a18a0f9071ea">ConjugateGradient</a> (void)</td></tr>
<tr class="separator:a1a583e3f482717a40656a18a0f9071ea"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:acb492edd9546dd27a67de1b91d80906b"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_conjugate_gradient.html#acb492edd9546dd27a67de1b91d80906b">ConjugateGradient</a> (<a class="el" href="class_open_n_n_1_1_performance_functional.html">PerformanceFunctional</a> *)</td></tr>
<tr class="separator:acb492edd9546dd27a67de1b91d80906b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a616137897c2c50ca3e2d7996edb9b493"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_conjugate_gradient.html#a616137897c2c50ca3e2d7996edb9b493">ConjugateGradient</a> (const tinyxml2::XMLDocument &amp;)</td></tr>
<tr class="separator:a616137897c2c50ca3e2d7996edb9b493"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af2be8db22fb41b35959c4713450e47de"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="af2be8db22fb41b35959c4713450e47de"></a>
virtual&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_conjugate_gradient.html#af2be8db22fb41b35959c4713450e47de">~ConjugateGradient</a> (void)</td></tr>
<tr class="separator:af2be8db22fb41b35959c4713450e47de"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a28c02d60f1cb366d2678b563dd69fa94"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a28c02d60f1cb366d2678b563dd69fa94"></a>
const <a class="el" href="class_open_n_n_1_1_training_rate_algorithm.html">TrainingRateAlgorithm</a> &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_conjugate_gradient.html#a28c02d60f1cb366d2678b563dd69fa94">get_training_rate_algorithm</a> (void) const </td></tr>
<tr class="separator:a28c02d60f1cb366d2678b563dd69fa94"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab85062c33da1b9065b81ac946198a5c9"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ab85062c33da1b9065b81ac946198a5c9"></a>
<a class="el" href="class_open_n_n_1_1_training_rate_algorithm.html">TrainingRateAlgorithm</a> *&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_conjugate_gradient.html#ab85062c33da1b9065b81ac946198a5c9">get_training_rate_algorithm_pointer</a> (void)</td></tr>
<tr class="separator:ab85062c33da1b9065b81ac946198a5c9"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a43e996a2ada93a8383616f937d256fca"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a43e996a2ada93a8383616f937d256fca"></a>
const <a class="el" href="class_open_n_n_1_1_conjugate_gradient.html#a6945bdfb0798a692bc45158307a05423">TrainingDirectionMethod</a> &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_conjugate_gradient.html#a43e996a2ada93a8383616f937d256fca">get_training_direction_method</a> (void) const </td></tr>
<tr class="separator:a43e996a2ada93a8383616f937d256fca"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a020bd6b55cfcedf04647818eb388b292"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a020bd6b55cfcedf04647818eb388b292"></a>
std::string&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_conjugate_gradient.html#a020bd6b55cfcedf04647818eb388b292">write_training_direction_method</a> (void) const </td></tr>
<tr class="separator:a020bd6b55cfcedf04647818eb388b292"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5e8a2b67c6a42a1b14fa97e2b69175f9"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a5e8a2b67c6a42a1b14fa97e2b69175f9"></a>
const double &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_conjugate_gradient.html#a5e8a2b67c6a42a1b14fa97e2b69175f9">get_warning_parameters_norm</a> (void) const </td></tr>
<tr class="separator:a5e8a2b67c6a42a1b14fa97e2b69175f9"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad81ca9794bb6f12cb779429e722ec80b"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ad81ca9794bb6f12cb779429e722ec80b"></a>
const double &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_conjugate_gradient.html#ad81ca9794bb6f12cb779429e722ec80b">get_warning_gradient_norm</a> (void) const </td></tr>
<tr class="separator:ad81ca9794bb6f12cb779429e722ec80b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a38eb80588a92a1b33b5d55f23619a92e"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a38eb80588a92a1b33b5d55f23619a92e"></a>
const double &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_conjugate_gradient.html#a38eb80588a92a1b33b5d55f23619a92e">get_warning_training_rate</a> (void) const </td></tr>
<tr class="separator:a38eb80588a92a1b33b5d55f23619a92e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2d4b35306a6a32e8db701c4fbf279ab8"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a2d4b35306a6a32e8db701c4fbf279ab8"></a>
const double &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_conjugate_gradient.html#a2d4b35306a6a32e8db701c4fbf279ab8">get_error_parameters_norm</a> (void) const </td></tr>
<tr class="separator:a2d4b35306a6a32e8db701c4fbf279ab8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1ca39aa64b5dc6587e8cd58899b28871"><td class="memItemLeft" align="right" valign="top">const double &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_conjugate_gradient.html#a1ca39aa64b5dc6587e8cd58899b28871">get_error_gradient_norm</a> (void) const </td></tr>
<tr class="separator:a1ca39aa64b5dc6587e8cd58899b28871"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a823a4cd208d9d23e78c367b5d40dc973"><td class="memItemLeft" align="right" valign="top">const double &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_conjugate_gradient.html#a823a4cd208d9d23e78c367b5d40dc973">get_error_training_rate</a> (void) const </td></tr>
<tr class="separator:a823a4cd208d9d23e78c367b5d40dc973"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac51ecb02105e6c6eee62a03bfa4de9b5"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ac51ecb02105e6c6eee62a03bfa4de9b5"></a>
const double &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_conjugate_gradient.html#ac51ecb02105e6c6eee62a03bfa4de9b5">get_minimum_parameters_increment_norm</a> (void) const </td></tr>
<tr class="separator:ac51ecb02105e6c6eee62a03bfa4de9b5"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a438904120da1acb53573676ced73fb3e"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a438904120da1acb53573676ced73fb3e"></a>
const double &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_conjugate_gradient.html#a438904120da1acb53573676ced73fb3e">get_minimum_performance_increase</a> (void) const </td></tr>
<tr class="separator:a438904120da1acb53573676ced73fb3e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a952c454e35e25bd7c425b80bb33e3837"><td class="memItemLeft" align="right" valign="top">const double &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_conjugate_gradient.html#a952c454e35e25bd7c425b80bb33e3837">get_performance_goal</a> (void) const </td></tr>
<tr class="separator:a952c454e35e25bd7c425b80bb33e3837"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a612431b46e60ca3033d1a760c8c29e8f"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a612431b46e60ca3033d1a760c8c29e8f"></a>
const unsigned &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_conjugate_gradient.html#a612431b46e60ca3033d1a760c8c29e8f">get_maximum_generalization_performance_decreases</a> (void) const </td></tr>
<tr class="separator:a612431b46e60ca3033d1a760c8c29e8f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a94c848cc3c12c07e246ae16d7a648a35"><td class="memItemLeft" align="right" valign="top">const double &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_conjugate_gradient.html#a94c848cc3c12c07e246ae16d7a648a35">get_gradient_norm_goal</a> (void) const </td></tr>
<tr class="separator:a94c848cc3c12c07e246ae16d7a648a35"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9cb0b706426648eac5a328459a14c2ad"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a9cb0b706426648eac5a328459a14c2ad"></a>
const unsigned &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_conjugate_gradient.html#a9cb0b706426648eac5a328459a14c2ad">get_maximum_iterations_number</a> (void) const </td></tr>
<tr class="separator:a9cb0b706426648eac5a328459a14c2ad"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac5624cf775eb3edd705202f2ee984812"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ac5624cf775eb3edd705202f2ee984812"></a>
const double &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_conjugate_gradient.html#ac5624cf775eb3edd705202f2ee984812">get_maximum_time</a> (void) const </td></tr>
<tr class="separator:ac5624cf775eb3edd705202f2ee984812"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a32db840eb56ef1a5b63d05b72bfc548d"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a32db840eb56ef1a5b63d05b72bfc548d"></a>
const bool &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_conjugate_gradient.html#a32db840eb56ef1a5b63d05b72bfc548d">get_reserve_parameters_history</a> (void) const </td></tr>
<tr class="separator:a32db840eb56ef1a5b63d05b72bfc548d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3dcbdaa338cdce965a679c335559596e"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a3dcbdaa338cdce965a679c335559596e"></a>
const bool &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_conjugate_gradient.html#a3dcbdaa338cdce965a679c335559596e">get_reserve_parameters_norm_history</a> (void) const </td></tr>
<tr class="separator:a3dcbdaa338cdce965a679c335559596e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:afc0182451d5116c78593c16474e7ce70"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="afc0182451d5116c78593c16474e7ce70"></a>
const bool &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_conjugate_gradient.html#afc0182451d5116c78593c16474e7ce70">get_reserve_performance_history</a> (void) const </td></tr>
<tr class="separator:afc0182451d5116c78593c16474e7ce70"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9c4c8931ae9312ab1c235f9438ae2e56"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a9c4c8931ae9312ab1c235f9438ae2e56"></a>
const bool &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_conjugate_gradient.html#a9c4c8931ae9312ab1c235f9438ae2e56">get_reserve_generalization_performance_history</a> (void) const </td></tr>
<tr class="separator:a9c4c8931ae9312ab1c235f9438ae2e56"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6e4409d688dea5659d53353046bcbdb0"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a6e4409d688dea5659d53353046bcbdb0"></a>
const bool &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_conjugate_gradient.html#a6e4409d688dea5659d53353046bcbdb0">get_reserve_gradient_history</a> (void) const </td></tr>
<tr class="separator:a6e4409d688dea5659d53353046bcbdb0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3b5923caafc58407ebc36e6cbb7cc12d"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a3b5923caafc58407ebc36e6cbb7cc12d"></a>
const bool &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_conjugate_gradient.html#a3b5923caafc58407ebc36e6cbb7cc12d">get_reserve_gradient_norm_history</a> (void) const </td></tr>
<tr class="separator:a3b5923caafc58407ebc36e6cbb7cc12d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5e688cf2d60a8619910b3477c69cd15a"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a5e688cf2d60a8619910b3477c69cd15a"></a>
const bool &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_conjugate_gradient.html#a5e688cf2d60a8619910b3477c69cd15a">get_reserve_training_direction_history</a> (void) const </td></tr>
<tr class="separator:a5e688cf2d60a8619910b3477c69cd15a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab8d074f8bbd8a98c6314cf2e557aedc8"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ab8d074f8bbd8a98c6314cf2e557aedc8"></a>
const bool &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_conjugate_gradient.html#ab8d074f8bbd8a98c6314cf2e557aedc8">get_reserve_training_rate_history</a> (void) const </td></tr>
<tr class="separator:ab8d074f8bbd8a98c6314cf2e557aedc8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7aa7d75996822715371d62a40f056223"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a7aa7d75996822715371d62a40f056223"></a>
const bool &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_conjugate_gradient.html#a7aa7d75996822715371d62a40f056223">get_reserve_elapsed_time_history</a> (void) const </td></tr>
<tr class="separator:a7aa7d75996822715371d62a40f056223"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0003b64d6d2146df20184e862b4dc81a"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a0003b64d6d2146df20184e862b4dc81a"></a>
const unsigned &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_conjugate_gradient.html#a0003b64d6d2146df20184e862b4dc81a">get_display_period</a> (void) const </td></tr>
<tr class="separator:a0003b64d6d2146df20184e862b4dc81a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7098a0ce93b35aed9c735d9e8fdf87b5"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_conjugate_gradient.html#a7098a0ce93b35aed9c735d9e8fdf87b5">set_default</a> (void)</td></tr>
<tr class="separator:a7098a0ce93b35aed9c735d9e8fdf87b5"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a80ce9dd7855dde50fc83ee152a67b6aa"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_conjugate_gradient.html#a80ce9dd7855dde50fc83ee152a67b6aa">set_performance_functional_pointer</a> (<a class="el" href="class_open_n_n_1_1_performance_functional.html">PerformanceFunctional</a> *)</td></tr>
<tr class="separator:a80ce9dd7855dde50fc83ee152a67b6aa"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6ae0ce9c10e2462993eee59883e490ba"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_conjugate_gradient.html#a6ae0ce9c10e2462993eee59883e490ba">set_training_direction_method</a> (const <a class="el" href="class_open_n_n_1_1_conjugate_gradient.html#a6945bdfb0798a692bc45158307a05423">TrainingDirectionMethod</a> &amp;)</td></tr>
<tr class="separator:a6ae0ce9c10e2462993eee59883e490ba"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aee58db9e1adf83e2e1ab8bbba3a58ee1"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_conjugate_gradient.html#aee58db9e1adf83e2e1ab8bbba3a58ee1">set_training_direction_method</a> (const std::string &amp;)</td></tr>
<tr class="separator:aee58db9e1adf83e2e1ab8bbba3a58ee1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4b1a110fd305f1986af4cb58c528ac63"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_conjugate_gradient.html#a4b1a110fd305f1986af4cb58c528ac63">set_warning_parameters_norm</a> (const double &amp;)</td></tr>
<tr class="separator:a4b1a110fd305f1986af4cb58c528ac63"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab9d2365e8c662083d1edd946d521f7bf"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_conjugate_gradient.html#ab9d2365e8c662083d1edd946d521f7bf">set_warning_gradient_norm</a> (const double &amp;)</td></tr>
<tr class="separator:ab9d2365e8c662083d1edd946d521f7bf"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:abbae77c17da7d542b4e3c4251e57cb06"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_conjugate_gradient.html#abbae77c17da7d542b4e3c4251e57cb06">set_warning_training_rate</a> (const double &amp;)</td></tr>
<tr class="separator:abbae77c17da7d542b4e3c4251e57cb06"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac213f5dae6f2236e288462abb794a956"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_conjugate_gradient.html#ac213f5dae6f2236e288462abb794a956">set_error_parameters_norm</a> (const double &amp;)</td></tr>
<tr class="separator:ac213f5dae6f2236e288462abb794a956"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aac8d36d1372f47c9cf03a3b73c1df440"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_conjugate_gradient.html#aac8d36d1372f47c9cf03a3b73c1df440">set_error_gradient_norm</a> (const double &amp;)</td></tr>
<tr class="separator:aac8d36d1372f47c9cf03a3b73c1df440"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a165eaf088bb453f5a8ffc231d61d3d5f"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_conjugate_gradient.html#a165eaf088bb453f5a8ffc231d61d3d5f">set_error_training_rate</a> (const double &amp;)</td></tr>
<tr class="separator:a165eaf088bb453f5a8ffc231d61d3d5f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:abcf2b6f18bb3ea67c66b8f274e05c170"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_conjugate_gradient.html#abcf2b6f18bb3ea67c66b8f274e05c170">set_minimum_parameters_increment_norm</a> (const double &amp;)</td></tr>
<tr class="separator:abcf2b6f18bb3ea67c66b8f274e05c170"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1e5f16b50b764b468183186422703313"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_conjugate_gradient.html#a1e5f16b50b764b468183186422703313">set_performance_goal</a> (const double &amp;)</td></tr>
<tr class="separator:a1e5f16b50b764b468183186422703313"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:abfc1ed807a9f18532c879a82180aebd6"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_conjugate_gradient.html#abfc1ed807a9f18532c879a82180aebd6">set_minimum_performance_increase</a> (const double &amp;)</td></tr>
<tr class="separator:abfc1ed807a9f18532c879a82180aebd6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a45212ffee225f5e2a2cf8fe197c7a9dc"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_conjugate_gradient.html#a45212ffee225f5e2a2cf8fe197c7a9dc">set_maximum_generalization_performance_decreases</a> (const unsigned &amp;)</td></tr>
<tr class="separator:a45212ffee225f5e2a2cf8fe197c7a9dc"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a06331ca7f99debc62d1afadf26bff850"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_conjugate_gradient.html#a06331ca7f99debc62d1afadf26bff850">set_gradient_norm_goal</a> (const double &amp;)</td></tr>
<tr class="separator:a06331ca7f99debc62d1afadf26bff850"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af81f633c98d9056c71c24f1f3138466f"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_conjugate_gradient.html#af81f633c98d9056c71c24f1f3138466f">set_maximum_iterations_number</a> (const unsigned &amp;)</td></tr>
<tr class="separator:af81f633c98d9056c71c24f1f3138466f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7227ff99b52a9fa1a3a5905c6cc66b76"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_conjugate_gradient.html#a7227ff99b52a9fa1a3a5905c6cc66b76">set_maximum_time</a> (const double &amp;)</td></tr>
<tr class="separator:a7227ff99b52a9fa1a3a5905c6cc66b76"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9de9b218ff51f2393ea38006019f7ffa"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_conjugate_gradient.html#a9de9b218ff51f2393ea38006019f7ffa">set_reserve_parameters_history</a> (const bool &amp;)</td></tr>
<tr class="separator:a9de9b218ff51f2393ea38006019f7ffa"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a274786cd036399313295dff4a097130c"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_conjugate_gradient.html#a274786cd036399313295dff4a097130c">set_reserve_parameters_norm_history</a> (const bool &amp;)</td></tr>
<tr class="separator:a274786cd036399313295dff4a097130c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab227db5113a4c162df05a2d91f88690e"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_conjugate_gradient.html#ab227db5113a4c162df05a2d91f88690e">set_reserve_performance_history</a> (const bool &amp;)</td></tr>
<tr class="separator:ab227db5113a4c162df05a2d91f88690e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8bfd0378628b1a93f3deaab67f6389eb"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_conjugate_gradient.html#a8bfd0378628b1a93f3deaab67f6389eb">set_reserve_generalization_performance_history</a> (const bool &amp;)</td></tr>
<tr class="separator:a8bfd0378628b1a93f3deaab67f6389eb"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:afaef3aac943440a248a9f2e9851eb9c0"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_conjugate_gradient.html#afaef3aac943440a248a9f2e9851eb9c0">set_reserve_gradient_history</a> (const bool &amp;)</td></tr>
<tr class="separator:afaef3aac943440a248a9f2e9851eb9c0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0c59f4b561c506844b01718945db2ea8"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_conjugate_gradient.html#a0c59f4b561c506844b01718945db2ea8">set_reserve_gradient_norm_history</a> (const bool &amp;)</td></tr>
<tr class="separator:a0c59f4b561c506844b01718945db2ea8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a379aa30482f6ce0a1ad2071a4e6f6b61"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_conjugate_gradient.html#a379aa30482f6ce0a1ad2071a4e6f6b61">set_reserve_training_direction_history</a> (const bool &amp;)</td></tr>
<tr class="separator:a379aa30482f6ce0a1ad2071a4e6f6b61"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae46832a168326e64d3e19ef769335771"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_conjugate_gradient.html#ae46832a168326e64d3e19ef769335771">set_reserve_training_rate_history</a> (const bool &amp;)</td></tr>
<tr class="separator:ae46832a168326e64d3e19ef769335771"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a98b68a0401e023dc61692d4b7377a4ac"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_conjugate_gradient.html#a98b68a0401e023dc61692d4b7377a4ac">set_reserve_elapsed_time_history</a> (const bool &amp;)</td></tr>
<tr class="separator:a98b68a0401e023dc61692d4b7377a4ac"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5b21e8e16b09531d93384dd9339c02f5"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_conjugate_gradient.html#a5b21e8e16b09531d93384dd9339c02f5">set_reserve_all_training_history</a> (const bool &amp;)</td></tr>
<tr class="separator:a5b21e8e16b09531d93384dd9339c02f5"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a75533e5f865e1293f339d79a8ffd612c"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_conjugate_gradient.html#a75533e5f865e1293f339d79a8ffd612c">set_display_period</a> (const unsigned &amp;)</td></tr>
<tr class="separator:a75533e5f865e1293f339d79a8ffd612c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af73bcb65142c7608cca02496f6bc484b"><td class="memItemLeft" align="right" valign="top">double&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_conjugate_gradient.html#af73bcb65142c7608cca02496f6bc484b">calculate_PR_parameter</a> (const <a class="el" href="class_open_n_n_1_1_vector.html">Vector</a>&lt; double &gt; &amp;, const <a class="el" href="class_open_n_n_1_1_vector.html">Vector</a>&lt; double &gt; &amp;) const </td></tr>
<tr class="separator:af73bcb65142c7608cca02496f6bc484b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aeef9bc0433ecff10db98d87945b553ae"><td class="memItemLeft" align="right" valign="top">double&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_conjugate_gradient.html#aeef9bc0433ecff10db98d87945b553ae">calculate_FR_parameter</a> (const <a class="el" href="class_open_n_n_1_1_vector.html">Vector</a>&lt; double &gt; &amp;, const <a class="el" href="class_open_n_n_1_1_vector.html">Vector</a>&lt; double &gt; &amp;) const </td></tr>
<tr class="separator:aeef9bc0433ecff10db98d87945b553ae"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a349d877b87f39e34f2041ca12578493f"><td class="memItemLeft" align="right" valign="top"><a class="el" href="class_open_n_n_1_1_vector.html">Vector</a>&lt; double &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_conjugate_gradient.html#a349d877b87f39e34f2041ca12578493f">calculate_PR_training_direction</a> (const <a class="el" href="class_open_n_n_1_1_vector.html">Vector</a>&lt; double &gt; &amp;, const <a class="el" href="class_open_n_n_1_1_vector.html">Vector</a>&lt; double &gt; &amp;, const <a class="el" href="class_open_n_n_1_1_vector.html">Vector</a>&lt; double &gt; &amp;) const </td></tr>
<tr class="separator:a349d877b87f39e34f2041ca12578493f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aeb3e308b272d1bffa46c96cbb1160be7"><td class="memItemLeft" align="right" valign="top"><a class="el" href="class_open_n_n_1_1_vector.html">Vector</a>&lt; double &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_conjugate_gradient.html#aeb3e308b272d1bffa46c96cbb1160be7">calculate_FR_training_direction</a> (const <a class="el" href="class_open_n_n_1_1_vector.html">Vector</a>&lt; double &gt; &amp;, const <a class="el" href="class_open_n_n_1_1_vector.html">Vector</a>&lt; double &gt; &amp;, const <a class="el" href="class_open_n_n_1_1_vector.html">Vector</a>&lt; double &gt; &amp;) const </td></tr>
<tr class="separator:aeb3e308b272d1bffa46c96cbb1160be7"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a42e7f404e32cceabb10a25d2b66f6ca4"><td class="memItemLeft" align="right" valign="top"><a class="el" href="class_open_n_n_1_1_vector.html">Vector</a>&lt; double &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_conjugate_gradient.html#a42e7f404e32cceabb10a25d2b66f6ca4">calculate_gradient_descent_training_direction</a> (const <a class="el" href="class_open_n_n_1_1_vector.html">Vector</a>&lt; double &gt; &amp;) const </td></tr>
<tr class="separator:a42e7f404e32cceabb10a25d2b66f6ca4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a24e0e461557d5f855c97dbeedf43d0cb"><td class="memItemLeft" align="right" valign="top"><a class="el" href="class_open_n_n_1_1_vector.html">Vector</a>&lt; double &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_conjugate_gradient.html#a24e0e461557d5f855c97dbeedf43d0cb">calculate_training_direction</a> (const <a class="el" href="class_open_n_n_1_1_vector.html">Vector</a>&lt; double &gt; &amp;, const <a class="el" href="class_open_n_n_1_1_vector.html">Vector</a>&lt; double &gt; &amp;, const <a class="el" href="class_open_n_n_1_1_vector.html">Vector</a>&lt; double &gt; &amp;) const </td></tr>
<tr class="separator:a24e0e461557d5f855c97dbeedf43d0cb"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a21c8810233ae2c5da6f6e5b923759d4f"><td class="memItemLeft" align="right" valign="top"><a class="el" href="struct_open_n_n_1_1_conjugate_gradient_1_1_conjugate_gradient_results.html">ConjugateGradientResults</a> *&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_conjugate_gradient.html#a21c8810233ae2c5da6f6e5b923759d4f">perform_training</a> (void)</td></tr>
<tr class="separator:a21c8810233ae2c5da6f6e5b923759d4f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ada7b8d4a49f4e401f94a08a287d5359e"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ada7b8d4a49f4e401f94a08a287d5359e"></a>
std::string&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_conjugate_gradient.html#ada7b8d4a49f4e401f94a08a287d5359e">write_training_algorithm_type</a> (void) const </td></tr>
<tr class="separator:ada7b8d4a49f4e401f94a08a287d5359e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a77f7f09e45d38f021c38a12ff116d36b"><td class="memItemLeft" align="right" valign="top"><a class="el" href="class_open_n_n_1_1_matrix.html">Matrix</a>&lt; std::string &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_conjugate_gradient.html#a77f7f09e45d38f021c38a12ff116d36b">to_string_matrix</a> (void) const </td></tr>
<tr class="separator:a77f7f09e45d38f021c38a12ff116d36b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a304ecc955e539bfec80538143d1ed2ee"><td class="memItemLeft" align="right" valign="top">tinyxml2::XMLDocument *&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_conjugate_gradient.html#a304ecc955e539bfec80538143d1ed2ee">to_XML</a> (void) const </td></tr>
<tr class="separator:a304ecc955e539bfec80538143d1ed2ee"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0cab144708679e94648116139c3543a1"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_conjugate_gradient.html#a0cab144708679e94648116139c3543a1">from_XML</a> (const tinyxml2::XMLDocument &amp;)</td></tr>
<tr class="separator:a0cab144708679e94648116139c3543a1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="inherit_header pub_methods_class_open_n_n_1_1_training_algorithm"><td colspan="2" onclick="javascript:toggleInherit('pub_methods_class_open_n_n_1_1_training_algorithm')"><img src="closed.png" alt="-"/>&#160;Public Member Functions inherited from <a class="el" href="class_open_n_n_1_1_training_algorithm.html">OpenNN::TrainingAlgorithm</a></td></tr>
<tr class="memitem:ad282802485d33f89e1c59eeef54444da inherit pub_methods_class_open_n_n_1_1_training_algorithm"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_training_algorithm.html#ad282802485d33f89e1c59eeef54444da">TrainingAlgorithm</a> (void)</td></tr>
<tr class="separator:ad282802485d33f89e1c59eeef54444da inherit pub_methods_class_open_n_n_1_1_training_algorithm"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab69eb3d525dab60fd69fb00ba421f36d inherit pub_methods_class_open_n_n_1_1_training_algorithm"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_training_algorithm.html#ab69eb3d525dab60fd69fb00ba421f36d">TrainingAlgorithm</a> (<a class="el" href="class_open_n_n_1_1_performance_functional.html">PerformanceFunctional</a> *)</td></tr>
<tr class="separator:ab69eb3d525dab60fd69fb00ba421f36d inherit pub_methods_class_open_n_n_1_1_training_algorithm"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8dfcef44772c57f9df88da95b9d35c54 inherit pub_methods_class_open_n_n_1_1_training_algorithm"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_training_algorithm.html#a8dfcef44772c57f9df88da95b9d35c54">TrainingAlgorithm</a> (const tinyxml2::XMLDocument &amp;)</td></tr>
<tr class="separator:a8dfcef44772c57f9df88da95b9d35c54 inherit pub_methods_class_open_n_n_1_1_training_algorithm"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac5742dcab114dd8806f2e4a3959bfb9b inherit pub_methods_class_open_n_n_1_1_training_algorithm"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ac5742dcab114dd8806f2e4a3959bfb9b"></a>
virtual&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_training_algorithm.html#ac5742dcab114dd8806f2e4a3959bfb9b">~TrainingAlgorithm</a> (void)</td></tr>
<tr class="separator:ac5742dcab114dd8806f2e4a3959bfb9b inherit pub_methods_class_open_n_n_1_1_training_algorithm"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1d8b68ae8ed824dc5e229ae9b492a460 inherit pub_methods_class_open_n_n_1_1_training_algorithm"><td class="memItemLeft" align="right" valign="top">virtual <a class="el" href="class_open_n_n_1_1_training_algorithm.html">TrainingAlgorithm</a> &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_training_algorithm.html#a1d8b68ae8ed824dc5e229ae9b492a460">operator=</a> (const <a class="el" href="class_open_n_n_1_1_training_algorithm.html">TrainingAlgorithm</a> &amp;)</td></tr>
<tr class="separator:a1d8b68ae8ed824dc5e229ae9b492a460 inherit pub_methods_class_open_n_n_1_1_training_algorithm"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa360a500379e8ff1d47fecbac96114fd inherit pub_methods_class_open_n_n_1_1_training_algorithm"><td class="memItemLeft" align="right" valign="top">virtual bool&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_training_algorithm.html#aa360a500379e8ff1d47fecbac96114fd">operator==</a> (const <a class="el" href="class_open_n_n_1_1_training_algorithm.html">TrainingAlgorithm</a> &amp;) const </td></tr>
<tr class="separator:aa360a500379e8ff1d47fecbac96114fd inherit pub_methods_class_open_n_n_1_1_training_algorithm"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a74a0a591997aef59500d6f227b33bff8 inherit pub_methods_class_open_n_n_1_1_training_algorithm"><td class="memItemLeft" align="right" valign="top"><a class="el" href="class_open_n_n_1_1_performance_functional.html">PerformanceFunctional</a> *&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_training_algorithm.html#a74a0a591997aef59500d6f227b33bff8">get_performance_functional_pointer</a> (void) const </td></tr>
<tr class="separator:a74a0a591997aef59500d6f227b33bff8 inherit pub_methods_class_open_n_n_1_1_training_algorithm"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a446b4bbf285cf06381e8ef22cbb386b8 inherit pub_methods_class_open_n_n_1_1_training_algorithm"><td class="memItemLeft" align="right" valign="top">bool&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_training_algorithm.html#a446b4bbf285cf06381e8ef22cbb386b8">has_performance_functional</a> (void) const </td></tr>
<tr class="separator:a446b4bbf285cf06381e8ef22cbb386b8 inherit pub_methods_class_open_n_n_1_1_training_algorithm"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1e12f5434cca6045ec7f32ed6354fae2 inherit pub_methods_class_open_n_n_1_1_training_algorithm"><td class="memItemLeft" align="right" valign="top">const bool &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_training_algorithm.html#a1e12f5434cca6045ec7f32ed6354fae2">get_display</a> (void) const </td></tr>
<tr class="separator:a1e12f5434cca6045ec7f32ed6354fae2 inherit pub_methods_class_open_n_n_1_1_training_algorithm"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4da24ff7d918b6e71eafbd6b5ebb0db3 inherit pub_methods_class_open_n_n_1_1_training_algorithm"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_training_algorithm.html#a4da24ff7d918b6e71eafbd6b5ebb0db3">set</a> (void)</td></tr>
<tr class="separator:a4da24ff7d918b6e71eafbd6b5ebb0db3 inherit pub_methods_class_open_n_n_1_1_training_algorithm"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1d81f9756854bc09a7992eba398f8994 inherit pub_methods_class_open_n_n_1_1_training_algorithm"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_training_algorithm.html#a1d81f9756854bc09a7992eba398f8994">set</a> (<a class="el" href="class_open_n_n_1_1_performance_functional.html">PerformanceFunctional</a> *)</td></tr>
<tr class="separator:a1d81f9756854bc09a7992eba398f8994 inherit pub_methods_class_open_n_n_1_1_training_algorithm"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8c9546bea276fe018a2e4269a28d0665 inherit pub_methods_class_open_n_n_1_1_training_algorithm"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_training_algorithm.html#a8c9546bea276fe018a2e4269a28d0665">set_display</a> (const bool &amp;)</td></tr>
<tr class="separator:a8c9546bea276fe018a2e4269a28d0665 inherit pub_methods_class_open_n_n_1_1_training_algorithm"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7bb1b776eaf2742280096376389bd37e inherit pub_methods_class_open_n_n_1_1_training_algorithm"><td class="memItemLeft" align="right" valign="top">virtual void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_training_algorithm.html#a7bb1b776eaf2742280096376389bd37e">check</a> (void) const </td></tr>
<tr class="separator:a7bb1b776eaf2742280096376389bd37e inherit pub_methods_class_open_n_n_1_1_training_algorithm"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5caf204457d2e1898c9e6782c11a6dc8 inherit pub_methods_class_open_n_n_1_1_training_algorithm"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a5caf204457d2e1898c9e6782c11a6dc8"></a>
virtual std::string&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_training_algorithm.html#a5caf204457d2e1898c9e6782c11a6dc8">to_string</a> (void) const </td></tr>
<tr class="separator:a5caf204457d2e1898c9e6782c11a6dc8 inherit pub_methods_class_open_n_n_1_1_training_algorithm"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:abfa18d80ad62902246b235f16744d6fd inherit pub_methods_class_open_n_n_1_1_training_algorithm"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="abfa18d80ad62902246b235f16744d6fd"></a>
void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_training_algorithm.html#abfa18d80ad62902246b235f16744d6fd">print</a> (void) const </td></tr>
<tr class="separator:abfa18d80ad62902246b235f16744d6fd inherit pub_methods_class_open_n_n_1_1_training_algorithm"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0523f936827472aff3303b35a42edcc4 inherit pub_methods_class_open_n_n_1_1_training_algorithm"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_training_algorithm.html#a0523f936827472aff3303b35a42edcc4">save</a> (const std::string &amp;) const </td></tr>
<tr class="separator:a0523f936827472aff3303b35a42edcc4 inherit pub_methods_class_open_n_n_1_1_training_algorithm"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a93e2fbe67a1edcfb8441b6f063b17e94 inherit pub_methods_class_open_n_n_1_1_training_algorithm"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_training_algorithm.html#a93e2fbe67a1edcfb8441b6f063b17e94">load</a> (const std::string &amp;)</td></tr>
<tr class="separator:a93e2fbe67a1edcfb8441b6f063b17e94 inherit pub_methods_class_open_n_n_1_1_training_algorithm"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a493aa79360d2d0405025de416b2a92ff inherit pub_methods_class_open_n_n_1_1_training_algorithm"><td class="memItemLeft" align="right" valign="top">virtual void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_training_algorithm.html#a493aa79360d2d0405025de416b2a92ff">initialize_random</a> (void)</td></tr>
<tr class="separator:a493aa79360d2d0405025de416b2a92ff inherit pub_methods_class_open_n_n_1_1_training_algorithm"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="pri-attribs"></a>
Private Attributes</h2></td></tr>
<tr class="memitem:a81ad2c4941ca65f3452bde12400773a0"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a81ad2c4941ca65f3452bde12400773a0"></a>
<a class="el" href="class_open_n_n_1_1_conjugate_gradient.html#a6945bdfb0798a692bc45158307a05423">TrainingDirectionMethod</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_conjugate_gradient.html#a81ad2c4941ca65f3452bde12400773a0">training_direction_method</a></td></tr>
<tr class="separator:a81ad2c4941ca65f3452bde12400773a0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab985b1032afdadbffc814fff645baeca"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ab985b1032afdadbffc814fff645baeca"></a>
<a class="el" href="class_open_n_n_1_1_training_rate_algorithm.html">TrainingRateAlgorithm</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_conjugate_gradient.html#ab985b1032afdadbffc814fff645baeca">training_rate_algorithm</a></td></tr>
<tr class="separator:ab985b1032afdadbffc814fff645baeca"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a659b0214a02330fa77388b1df4530569"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a659b0214a02330fa77388b1df4530569"></a>
double&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_conjugate_gradient.html#a659b0214a02330fa77388b1df4530569">warning_parameters_norm</a></td></tr>
<tr class="separator:a659b0214a02330fa77388b1df4530569"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a96676b769eef8b9c35a6637ca0a63e75"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a96676b769eef8b9c35a6637ca0a63e75"></a>
double&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_conjugate_gradient.html#a96676b769eef8b9c35a6637ca0a63e75">warning_gradient_norm</a></td></tr>
<tr class="separator:a96676b769eef8b9c35a6637ca0a63e75"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aece38a88e96d275da1ed4ddef2715fef"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aece38a88e96d275da1ed4ddef2715fef"></a>
double&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_conjugate_gradient.html#aece38a88e96d275da1ed4ddef2715fef">warning_training_rate</a></td></tr>
<tr class="separator:aece38a88e96d275da1ed4ddef2715fef"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2f44734c4b9f2f45ca578d5a6c789882"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a2f44734c4b9f2f45ca578d5a6c789882"></a>
double&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_conjugate_gradient.html#a2f44734c4b9f2f45ca578d5a6c789882">error_parameters_norm</a></td></tr>
<tr class="separator:a2f44734c4b9f2f45ca578d5a6c789882"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:afc3bcb4f351c218100585c5299dbffc2"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="afc3bcb4f351c218100585c5299dbffc2"></a>
double&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_conjugate_gradient.html#afc3bcb4f351c218100585c5299dbffc2">error_gradient_norm</a></td></tr>
<tr class="separator:afc3bcb4f351c218100585c5299dbffc2"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a19b8fdd15c928916d55aaf13497761d8"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a19b8fdd15c928916d55aaf13497761d8"></a>
double&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_conjugate_gradient.html#a19b8fdd15c928916d55aaf13497761d8">error_training_rate</a></td></tr>
<tr class="separator:a19b8fdd15c928916d55aaf13497761d8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac386e0987a7bd97cfe0e2d8aa1454eb7"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ac386e0987a7bd97cfe0e2d8aa1454eb7"></a>
double&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_conjugate_gradient.html#ac386e0987a7bd97cfe0e2d8aa1454eb7">minimum_parameters_increment_norm</a></td></tr>
<tr class="separator:ac386e0987a7bd97cfe0e2d8aa1454eb7"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a39b3a91bf6dc48e66fb391a81fd59f2d"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a39b3a91bf6dc48e66fb391a81fd59f2d"></a>
double&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_conjugate_gradient.html#a39b3a91bf6dc48e66fb391a81fd59f2d">minimum_performance_increase</a></td></tr>
<tr class="separator:a39b3a91bf6dc48e66fb391a81fd59f2d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aab3b9495c0dcf2c8e034d977b82d4b0f"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aab3b9495c0dcf2c8e034d977b82d4b0f"></a>
double&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_conjugate_gradient.html#aab3b9495c0dcf2c8e034d977b82d4b0f">performance_goal</a></td></tr>
<tr class="separator:aab3b9495c0dcf2c8e034d977b82d4b0f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa56d3952992f63b284f411336d651277"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aa56d3952992f63b284f411336d651277"></a>
double&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_conjugate_gradient.html#aa56d3952992f63b284f411336d651277">gradient_norm_goal</a></td></tr>
<tr class="separator:aa56d3952992f63b284f411336d651277"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:adb9f750b428f492aea406838dbe77fb0"><td class="memItemLeft" align="right" valign="top">unsigned&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_conjugate_gradient.html#adb9f750b428f492aea406838dbe77fb0">maximum_generalization_performance_decreases</a></td></tr>
<tr class="separator:adb9f750b428f492aea406838dbe77fb0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3a64c1c47a5909c202bac62f2cf0ba72"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a3a64c1c47a5909c202bac62f2cf0ba72"></a>
unsigned&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_conjugate_gradient.html#a3a64c1c47a5909c202bac62f2cf0ba72">maximum_iterations_number</a></td></tr>
<tr class="separator:a3a64c1c47a5909c202bac62f2cf0ba72"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:afe69da2fa7f81f437324b0d31147412c"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="afe69da2fa7f81f437324b0d31147412c"></a>
double&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_conjugate_gradient.html#afe69da2fa7f81f437324b0d31147412c">maximum_time</a></td></tr>
<tr class="separator:afe69da2fa7f81f437324b0d31147412c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2b9e11bc85ab962b0d414f91f2815c9f"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a2b9e11bc85ab962b0d414f91f2815c9f"></a>
bool&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_conjugate_gradient.html#a2b9e11bc85ab962b0d414f91f2815c9f">reserve_parameters_history</a></td></tr>
<tr class="separator:a2b9e11bc85ab962b0d414f91f2815c9f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac2099b4622a55533f2e5c14bb673601b"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ac2099b4622a55533f2e5c14bb673601b"></a>
bool&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_conjugate_gradient.html#ac2099b4622a55533f2e5c14bb673601b">reserve_parameters_norm_history</a></td></tr>
<tr class="separator:ac2099b4622a55533f2e5c14bb673601b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a15b9491c0b08616da5bcf0370dc71527"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a15b9491c0b08616da5bcf0370dc71527"></a>
bool&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_conjugate_gradient.html#a15b9491c0b08616da5bcf0370dc71527">reserve_performance_history</a></td></tr>
<tr class="separator:a15b9491c0b08616da5bcf0370dc71527"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aaa176757d9ef24686275cc407747aa7b"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aaa176757d9ef24686275cc407747aa7b"></a>
bool&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_conjugate_gradient.html#aaa176757d9ef24686275cc407747aa7b">reserve_gradient_history</a></td></tr>
<tr class="separator:aaa176757d9ef24686275cc407747aa7b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aec871dd53d58186bee65f2763ab460a8"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aec871dd53d58186bee65f2763ab460a8"></a>
bool&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_conjugate_gradient.html#aec871dd53d58186bee65f2763ab460a8">reserve_gradient_norm_history</a></td></tr>
<tr class="separator:aec871dd53d58186bee65f2763ab460a8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6cb00b3df2b295bfa9358adfdebd5dc0"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a6cb00b3df2b295bfa9358adfdebd5dc0"></a>
bool&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_conjugate_gradient.html#a6cb00b3df2b295bfa9358adfdebd5dc0">reserve_training_direction_history</a></td></tr>
<tr class="separator:a6cb00b3df2b295bfa9358adfdebd5dc0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a056d45285f3542d5f999242e33888843"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a056d45285f3542d5f999242e33888843"></a>
bool&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_conjugate_gradient.html#a056d45285f3542d5f999242e33888843">reserve_training_rate_history</a></td></tr>
<tr class="separator:a056d45285f3542d5f999242e33888843"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:abdbc963804958b39477b7ace420ef3a6"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="abdbc963804958b39477b7ace420ef3a6"></a>
bool&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_conjugate_gradient.html#abdbc963804958b39477b7ace420ef3a6">reserve_elapsed_time_history</a></td></tr>
<tr class="separator:abdbc963804958b39477b7ace420ef3a6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ade49000d8c1da371e8f62bd28b613efd"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ade49000d8c1da371e8f62bd28b613efd"></a>
bool&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_conjugate_gradient.html#ade49000d8c1da371e8f62bd28b613efd">reserve_generalization_performance_history</a></td></tr>
<tr class="separator:ade49000d8c1da371e8f62bd28b613efd"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6cce2fcc4f362fa7732fdf68c5165c6a"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a6cce2fcc4f362fa7732fdf68c5165c6a"></a>
unsigned&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_conjugate_gradient.html#a6cce2fcc4f362fa7732fdf68c5165c6a">display_period</a></td></tr>
<tr class="separator:a6cce2fcc4f362fa7732fdf68c5165c6a"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="inherited"></a>
Additional Inherited Members</h2></td></tr>
<tr class="inherit_header pro_attribs_class_open_n_n_1_1_training_algorithm"><td colspan="2" onclick="javascript:toggleInherit('pro_attribs_class_open_n_n_1_1_training_algorithm')"><img src="closed.png" alt="-"/>&#160;Protected Attributes inherited from <a class="el" href="class_open_n_n_1_1_training_algorithm.html">OpenNN::TrainingAlgorithm</a></td></tr>
<tr class="memitem:a90ba564d00e69786d58ed94672e6e8f4 inherit pro_attribs_class_open_n_n_1_1_training_algorithm"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a90ba564d00e69786d58ed94672e6e8f4"></a>
<a class="el" href="class_open_n_n_1_1_performance_functional.html">PerformanceFunctional</a> *&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_training_algorithm.html#a90ba564d00e69786d58ed94672e6e8f4">performance_functional_pointer</a></td></tr>
<tr class="separator:a90ba564d00e69786d58ed94672e6e8f4 inherit pro_attribs_class_open_n_n_1_1_training_algorithm"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a13bf46cc2670a9852b9336b66b7897f3 inherit pro_attribs_class_open_n_n_1_1_training_algorithm"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a13bf46cc2670a9852b9336b66b7897f3"></a>
bool&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_training_algorithm.html#a13bf46cc2670a9852b9336b66b7897f3">display</a></td></tr>
<tr class="separator:a13bf46cc2670a9852b9336b66b7897f3 inherit pro_attribs_class_open_n_n_1_1_training_algorithm"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<div class="textblock"><p>This concrete class represents a conjugate gradient training algorithm for a performance functional of a neural network. </p>
</div><h2 class="groupheader">Constructor &amp; Destructor Documentation</h2>
<a class="anchor" id="a1a583e3f482717a40656a18a0f9071ea"></a>
<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">OpenNN::ConjugateGradient::ConjugateGradient </td>
          <td>(</td>
          <td class="paramtype">void&#160;</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">explicit</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<p>Default constructor. It creates a conjugate gradient training algorithm object not associated to any performance functional object. It also initializes the class members to their default values. </p>

</div>
</div>
<a class="anchor" id="acb492edd9546dd27a67de1b91d80906b"></a>
<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">OpenNN::ConjugateGradient::ConjugateGradient </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="class_open_n_n_1_1_performance_functional.html">PerformanceFunctional</a> *&#160;</td>
          <td class="paramname"><em>new_performance_functional_pointer</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">explicit</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<p>General constructor. It creates a conjugate gradient training algorithm associated to a performance functional object. It also initializes the rest of class members to their default values. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">new_performance_functional_pointer</td><td>Pointer to a performance functional object. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a class="anchor" id="a616137897c2c50ca3e2d7996edb9b493"></a>
<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">OpenNN::ConjugateGradient::ConjugateGradient </td>
          <td>(</td>
          <td class="paramtype">const tinyxml2::XMLDocument &amp;&#160;</td>
          <td class="paramname"><em>conjugate_gradient_document</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">explicit</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<p>XML constructor. It creates a conjugate gradient training algorithm not associated to any performance functional object. It also loads the class members from a XML document. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">conjugate_gradient_document</td><td>TinyXML document with the members of a conjugate gradient object. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<h2 class="groupheader">Member Function Documentation</h2>
<a class="anchor" id="aeef9bc0433ecff10db98d87945b553ae"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">double OpenNN::ConjugateGradient::calculate_FR_parameter </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="class_open_n_n_1_1_vector.html">Vector</a>&lt; double &gt; &amp;&#160;</td>
          <td class="paramname"><em>old_gradient</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="class_open_n_n_1_1_vector.html">Vector</a>&lt; double &gt; &amp;&#160;</td>
          <td class="paramname"><em>gradient</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td> const</td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Returns the Fletcher-Reeves parameter used to calculate the training direction.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">old_gradient</td><td>Previous objective function gradient. </td></tr>
    <tr><td class="paramname">gradient,:</td><td>Current objective function gradient. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a class="anchor" id="aeb3e308b272d1bffa46c96cbb1160be7"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="class_open_n_n_1_1_vector.html">Vector</a>&lt; double &gt; OpenNN::ConjugateGradient::calculate_FR_training_direction </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="class_open_n_n_1_1_vector.html">Vector</a>&lt; double &gt; &amp;&#160;</td>
          <td class="paramname"><em>old_gradient</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="class_open_n_n_1_1_vector.html">Vector</a>&lt; double &gt; &amp;&#160;</td>
          <td class="paramname"><em>gradient</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="class_open_n_n_1_1_vector.html">Vector</a>&lt; double &gt; &amp;&#160;</td>
          <td class="paramname"><em>old_training_direction</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td> const</td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Returns the training direction using the Fletcher-Reeves update. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">old_gradient</td><td>Previous objective function gradient. </td></tr>
    <tr><td class="paramname">gradient</td><td>Current objective function gradient. </td></tr>
    <tr><td class="paramname">old_training_direction</td><td>Previous training direction vector. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a class="anchor" id="a42e7f404e32cceabb10a25d2b66f6ca4"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="class_open_n_n_1_1_vector.html">Vector</a>&lt; double &gt; OpenNN::ConjugateGradient::calculate_gradient_descent_training_direction </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="class_open_n_n_1_1_vector.html">Vector</a>&lt; double &gt; &amp;&#160;</td>
          <td class="paramname"><em>gradient</em></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Returns the gradient descent training direction, which is the negative of the normalized gradient. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">gradient</td><td>Gradient vector. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a class="anchor" id="af73bcb65142c7608cca02496f6bc484b"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">double OpenNN::ConjugateGradient::calculate_PR_parameter </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="class_open_n_n_1_1_vector.html">Vector</a>&lt; double &gt; &amp;&#160;</td>
          <td class="paramname"><em>old_gradient</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="class_open_n_n_1_1_vector.html">Vector</a>&lt; double &gt; &amp;&#160;</td>
          <td class="paramname"><em>gradient</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td> const</td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Returns the Polak-Ribiere parameter used to calculate the training direction. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">old_gradient</td><td>Previous objective function gradient. </td></tr>
    <tr><td class="paramname">gradient</td><td>Current objective function gradient. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a class="anchor" id="a349d877b87f39e34f2041ca12578493f"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="class_open_n_n_1_1_vector.html">Vector</a>&lt; double &gt; OpenNN::ConjugateGradient::calculate_PR_training_direction </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="class_open_n_n_1_1_vector.html">Vector</a>&lt; double &gt; &amp;&#160;</td>
          <td class="paramname"><em>old_gradient</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="class_open_n_n_1_1_vector.html">Vector</a>&lt; double &gt; &amp;&#160;</td>
          <td class="paramname"><em>gradient</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="class_open_n_n_1_1_vector.html">Vector</a>&lt; double &gt; &amp;&#160;</td>
          <td class="paramname"><em>old_training_direction</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td> const</td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Returns the training direction using the Polak-Ribiere update. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">old_gradient</td><td>Previous objective function gradient. </td></tr>
    <tr><td class="paramname">gradient</td><td>Current objective function gradient. </td></tr>
    <tr><td class="paramname">old_training_direction</td><td>Previous training direction vector. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a class="anchor" id="a24e0e461557d5f855c97dbeedf43d0cb"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="class_open_n_n_1_1_vector.html">Vector</a>&lt; double &gt; OpenNN::ConjugateGradient::calculate_training_direction </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="class_open_n_n_1_1_vector.html">Vector</a>&lt; double &gt; &amp;&#160;</td>
          <td class="paramname"><em>old_gradient</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="class_open_n_n_1_1_vector.html">Vector</a>&lt; double &gt; &amp;&#160;</td>
          <td class="paramname"><em>gradient</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="class_open_n_n_1_1_vector.html">Vector</a>&lt; double &gt; &amp;&#160;</td>
          <td class="paramname"><em>old_training_direction</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td> const</td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Returns the conjugate gradient training direction, which has been previously normalized. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">old_gradient</td><td>Gradient vector in the previous iteration. </td></tr>
    <tr><td class="paramname">gradient</td><td>Current gradient vector. </td></tr>
    <tr><td class="paramname">old_training_direction</td><td>Training direction in the previous iteration. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a class="anchor" id="a0cab144708679e94648116139c3543a1"></a>
<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void OpenNN::ConjugateGradient::from_XML </td>
          <td>(</td>
          <td class="paramtype">const tinyxml2::XMLDocument &amp;&#160;</td>
          <td class="paramname"><em>document</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<p>Deserializes the conjugate gradient object from a XML document of the TinyXML library. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">document</td><td>TinyXML document containing the member data. </td></tr>
  </table>
  </dd>
</dl>

<p>Reimplemented from <a class="el" href="class_open_n_n_1_1_training_algorithm.html#ac2c7597edd71a2dd8e103c68c629ccce">OpenNN::TrainingAlgorithm</a>.</p>

</div>
</div>
<a class="anchor" id="a1ca39aa64b5dc6587e8cd58899b28871"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">const double &amp; OpenNN::ConjugateGradient::get_error_gradient_norm </td>
          <td>(</td>
          <td class="paramtype">void&#160;</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Returns the value for the norm of the gradient vector at wich an error message is written to the screen and the program exits. </p>

</div>
</div>
<a class="anchor" id="a823a4cd208d9d23e78c367b5d40dc973"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">const double &amp; OpenNN::ConjugateGradient::get_error_training_rate </td>
          <td>(</td>
          <td class="paramtype">void&#160;</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Returns the training rate value at wich the line minimization algorithm is assumed to fail when bracketing a minimum. </p>

</div>
</div>
<a class="anchor" id="a94c848cc3c12c07e246ae16d7a648a35"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">const double &amp; OpenNN::ConjugateGradient::get_gradient_norm_goal </td>
          <td>(</td>
          <td class="paramtype">void&#160;</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Returns the goal value for the norm of the objective function gradient. This is used as a stopping criterion when training a multilayer perceptron </p>

</div>
</div>
<a class="anchor" id="a952c454e35e25bd7c425b80bb33e3837"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">const double &amp; OpenNN::ConjugateGradient::get_performance_goal </td>
          <td>(</td>
          <td class="paramtype">void&#160;</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Returns the goal value for the performance. This is used as a stopping criterion when training a multilayer perceptron </p>

</div>
</div>
<a class="anchor" id="a21c8810233ae2c5da6f6e5b923759d4f"></a>
<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="struct_open_n_n_1_1_conjugate_gradient_1_1_conjugate_gradient_results.html">ConjugateGradient::ConjugateGradientResults</a> * OpenNN::ConjugateGradient::perform_training </td>
          <td>(</td>
          <td class="paramtype">void&#160;</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<p>Trains a neural network with an associated performance functional according to the conjugate gradient algorithm. Training occurs according to the training operators, training parameters and stopping criteria. </p>

<p>Implements <a class="el" href="class_open_n_n_1_1_training_algorithm.html#a3ed4426c63e74939ae52730e3505cfdf">OpenNN::TrainingAlgorithm</a>.</p>

</div>
</div>
<a class="anchor" id="a7098a0ce93b35aed9c735d9e8fdf87b5"></a>
<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void OpenNN::ConjugateGradient::set_default </td>
          <td>(</td>
          <td class="paramtype">void&#160;</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<p>Sets the default values into a conjugate gradient object. Training operators: </p>
<ul>
<li>
Training direction method = Polak-Ribiere; </li>
<li>
Training rate method = Brent; </li>
</ul>
<p>Training parameters: </p>
<ul>
<li>
First training rate: 1.0. </li>
<li>
Bracketing factor: 2.0. </li>
<li>
Training rate tolerance: 1.0e-3. </li>
</ul>
<p>Stopping criteria: </p>
<ul>
<li>
Performance goal: -1.0e99. </li>
<li>
Gradient norm goal: 0.0. </li>
<li>
Maximum training time: 1.0e6. </li>
<li>
Maximum number of iterations: 100. </li>
</ul>
<p>User stuff: </p>
<ul>
<li>
Warning training rate: 1.0e6. </li>
<li>
Error training rate: 1.0e12. </li>
<li>
Display: true. </li>
<li>
Display period: 25. </li>
</ul>
<p>Reserve: </p>
<ul>
<li>
Reserve training direction history: false. </li>
<li>
Reserve training direction norm history: false. </li>
<li>
Reserve training rate history: false. </li>
</ul>

<p>Reimplemented from <a class="el" href="class_open_n_n_1_1_training_algorithm.html#a856d53c16da6bf5726da0f8403a13349">OpenNN::TrainingAlgorithm</a>.</p>

</div>
</div>
<a class="anchor" id="a75533e5f865e1293f339d79a8ffd612c"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void OpenNN::ConjugateGradient::set_display_period </td>
          <td>(</td>
          <td class="paramtype">const unsigned &amp;&#160;</td>
          <td class="paramname"><em>new_display_period</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Sets a new number of iterations between the training showing progress. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">new_display_period</td><td>Number of iterations between the training showing progress. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a class="anchor" id="aac8d36d1372f47c9cf03a3b73c1df440"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void OpenNN::ConjugateGradient::set_error_gradient_norm </td>
          <td>(</td>
          <td class="paramtype">const double &amp;&#160;</td>
          <td class="paramname"><em>new_error_gradient_norm</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Sets a new value for the gradient vector norm at which an error message is written to the screen and the program exits. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">new_error_gradient_norm</td><td>Error norm of gradient vector value. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a class="anchor" id="ac213f5dae6f2236e288462abb794a956"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void OpenNN::ConjugateGradient::set_error_parameters_norm </td>
          <td>(</td>
          <td class="paramtype">const double &amp;&#160;</td>
          <td class="paramname"><em>new_error_parameters_norm</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Sets a new value for the parameters vector norm at which an error message is written to the screen and the program exits. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">new_error_parameters_norm</td><td>Error norm of parameters vector value. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a class="anchor" id="a165eaf088bb453f5a8ffc231d61d3d5f"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void OpenNN::ConjugateGradient::set_error_training_rate </td>
          <td>(</td>
          <td class="paramtype">const double &amp;&#160;</td>
          <td class="paramname"><em>new_error_training_rate</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Sets a new training rate value at wich a the line minimization algorithm is assumed to fail when bracketing a minimum. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">new_error_training_rate</td><td>Error training rate value. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a class="anchor" id="a06331ca7f99debc62d1afadf26bff850"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void OpenNN::ConjugateGradient::set_gradient_norm_goal </td>
          <td>(</td>
          <td class="paramtype">const double &amp;&#160;</td>
          <td class="paramname"><em>new_gradient_norm_goal</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Sets a new the goal value for the norm of the objective function gradient. This is used as a stopping criterion when training a multilayer perceptron </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">new_gradient_norm_goal</td><td>Goal value for the norm of the objective function gradient. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a class="anchor" id="a45212ffee225f5e2a2cf8fe197c7a9dc"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void OpenNN::ConjugateGradient::set_maximum_generalization_performance_decreases </td>
          <td>(</td>
          <td class="paramtype">const unsigned &amp;&#160;</td>
          <td class="paramname"><em>new_maximum_generalization_performance_decreases</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Sets a new maximum number of generalization failures. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">new_maximum_generalization_performance_decreases</td><td>Maximum number of iterations in which the generalization evalutation decreases. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a class="anchor" id="af81f633c98d9056c71c24f1f3138466f"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void OpenNN::ConjugateGradient::set_maximum_iterations_number </td>
          <td>(</td>
          <td class="paramtype">const unsigned &amp;&#160;</td>
          <td class="paramname"><em>new_maximum_iterations_number</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Sets a maximum number of iterations for training. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">new_maximum_iterations_number</td><td>Maximum number of iterations for training. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a class="anchor" id="a7227ff99b52a9fa1a3a5905c6cc66b76"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void OpenNN::ConjugateGradient::set_maximum_time </td>
          <td>(</td>
          <td class="paramtype">const double &amp;&#160;</td>
          <td class="paramname"><em>new_maximum_time</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Sets a new maximum training time. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">new_maximum_time</td><td>Maximum training time. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a class="anchor" id="abcf2b6f18bb3ea67c66b8f274e05c170"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void OpenNN::ConjugateGradient::set_minimum_parameters_increment_norm </td>
          <td>(</td>
          <td class="paramtype">const double &amp;&#160;</td>
          <td class="paramname"><em>new_minimum_parameters_increment_norm</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Sets a new value for the minimum parameters increment norm stopping criterion. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">new_minimum_parameters_increment_norm</td><td>Value of norm of parameters increment norm used to stop training. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a class="anchor" id="abfc1ed807a9f18532c879a82180aebd6"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void OpenNN::ConjugateGradient::set_minimum_performance_increase </td>
          <td>(</td>
          <td class="paramtype">const double &amp;&#160;</td>
          <td class="paramname"><em>new_minimum_performance_increase</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Sets a new minimum performance improvement during training. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">new_minimum_performance_increase</td><td>Minimum improvement in the performance between two iterations. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a class="anchor" id="a80ce9dd7855dde50fc83ee152a67b6aa"></a>
<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void OpenNN::ConjugateGradient::set_performance_functional_pointer </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="class_open_n_n_1_1_performance_functional.html">PerformanceFunctional</a> *&#160;</td>
          <td class="paramname"><em>new_performance_functional_pointer</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<p>Sets a pointer to a performance functional object to be associated to the conjugate gradient object. It also sets that performance functional to the training rate algorithm. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">new_performance_functional_pointer</td><td>Pointer to a performance functional object. </td></tr>
  </table>
  </dd>
</dl>

<p>Reimplemented from <a class="el" href="class_open_n_n_1_1_training_algorithm.html#a071b431c38ba3998865d7269eab4b25d">OpenNN::TrainingAlgorithm</a>.</p>

</div>
</div>
<a class="anchor" id="a1e5f16b50b764b468183186422703313"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void OpenNN::ConjugateGradient::set_performance_goal </td>
          <td>(</td>
          <td class="paramtype">const double &amp;&#160;</td>
          <td class="paramname"><em>new_performance_goal</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Sets a new goal value for the performance. This is used as a stopping criterion when training a multilayer perceptron </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">new_performance_goal</td><td>Goal value for the performance. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a class="anchor" id="a5b21e8e16b09531d93384dd9339c02f5"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void OpenNN::ConjugateGradient::set_reserve_all_training_history </td>
          <td>(</td>
          <td class="paramtype">const bool &amp;&#160;</td>
          <td class="paramname"><em>new_reserve_all_training_history</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Makes the training history of all variables to reseved or not in memory when training. </p>
<ul>
<li>
Parameters. </li>
<li>
Parameters norm. </li>
<li>
performance. </li>
<li>
Gradient. </li>
<li>
Gradient norm. </li>
<li>
Generalization performance. </li>
<li>
Training direction. </li>
<li>
Training direction norm. </li>
<li>
Training rate. </li>
</ul>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">new_reserve_all_training_history</td><td>True if all training history variables are to be reserved, false otherwise. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a class="anchor" id="a98b68a0401e023dc61692d4b7377a4ac"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void OpenNN::ConjugateGradient::set_reserve_elapsed_time_history </td>
          <td>(</td>
          <td class="paramtype">const bool &amp;&#160;</td>
          <td class="paramname"><em>new_reserve_elapsed_time_history</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Makes the elapsed time over the iterations to be reseved or not in memory. This is a vector. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">new_reserve_elapsed_time_history</td><td>True if the elapsed time history vector is to be reserved, false otherwise. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a class="anchor" id="a8bfd0378628b1a93f3deaab67f6389eb"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void OpenNN::ConjugateGradient::set_reserve_generalization_performance_history </td>
          <td>(</td>
          <td class="paramtype">const bool &amp;&#160;</td>
          <td class="paramname"><em>new_reserve_generalization_performance_history</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Makes the Generalization performance history to be reserved or not in memory. This is a vector. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">new_reserve_generalization_performance_history</td><td>True if the Generalization performance history is to be reserved, false otherwise. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a class="anchor" id="afaef3aac943440a248a9f2e9851eb9c0"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void OpenNN::ConjugateGradient::set_reserve_gradient_history </td>
          <td>(</td>
          <td class="paramtype">const bool &amp;&#160;</td>
          <td class="paramname"><em>new_reserve_gradient_history</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Makes the gradient history vector of vectors to be reseved or not in memory. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">new_reserve_gradient_history</td><td>True if the gradient history matrix is to be reserved, false otherwise. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a class="anchor" id="a0c59f4b561c506844b01718945db2ea8"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void OpenNN::ConjugateGradient::set_reserve_gradient_norm_history </td>
          <td>(</td>
          <td class="paramtype">const bool &amp;&#160;</td>
          <td class="paramname"><em>new_reserve_gradient_norm_history</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Makes the gradient norm history vector to be reseved or not in memory. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">new_reserve_gradient_norm_history</td><td>True if the gradient norm history matrix is to be reserved, false otherwise. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a class="anchor" id="a9de9b218ff51f2393ea38006019f7ffa"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void OpenNN::ConjugateGradient::set_reserve_parameters_history </td>
          <td>(</td>
          <td class="paramtype">const bool &amp;&#160;</td>
          <td class="paramname"><em>new_reserve_parameters_history</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Makes the parameters history vector of vectors to be reseved or not in memory. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">new_reserve_parameters_history</td><td>True if the parameters history vector of vectors is to be reserved, false otherwise. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a class="anchor" id="a274786cd036399313295dff4a097130c"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void OpenNN::ConjugateGradient::set_reserve_parameters_norm_history </td>
          <td>(</td>
          <td class="paramtype">const bool &amp;&#160;</td>
          <td class="paramname"><em>new_reserve_parameters_norm_history</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Makes the parameters norm history vector to be reseved or not in memory. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">new_reserve_parameters_norm_history</td><td>True if the parameters norm history vector is to be reserved, false otherwise. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a class="anchor" id="ab227db5113a4c162df05a2d91f88690e"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void OpenNN::ConjugateGradient::set_reserve_performance_history </td>
          <td>(</td>
          <td class="paramtype">const bool &amp;&#160;</td>
          <td class="paramname"><em>new_reserve_performance_history</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Makes the performance history vector to be reseved or not in memory. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">new_reserve_performance_history</td><td>True if the performance history vector is to be reserved, false otherwise. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a class="anchor" id="a379aa30482f6ce0a1ad2071a4e6f6b61"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void OpenNN::ConjugateGradient::set_reserve_training_direction_history </td>
          <td>(</td>
          <td class="paramtype">const bool &amp;&#160;</td>
          <td class="paramname"><em>new_reserve_training_direction_history</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Makes the training direction history vector of vectors to be reseved or not in memory. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">new_reserve_training_direction_history</td><td>True if the training direction history matrix is to be reserved, false otherwise. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a class="anchor" id="ae46832a168326e64d3e19ef769335771"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void OpenNN::ConjugateGradient::set_reserve_training_rate_history </td>
          <td>(</td>
          <td class="paramtype">const bool &amp;&#160;</td>
          <td class="paramname"><em>new_reserve_training_rate_history</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Makes the training rate history vector to be reseved or not in memory. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">new_reserve_training_rate_history</td><td>True if the training rate history vector is to be reserved, false otherwise. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a class="anchor" id="a6ae0ce9c10e2462993eee59883e490ba"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void OpenNN::ConjugateGradient::set_training_direction_method </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="class_open_n_n_1_1_conjugate_gradient.html#a6945bdfb0798a692bc45158307a05423">TrainingDirectionMethod</a> &amp;&#160;</td>
          <td class="paramname"><em>new_training_direction_method</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Sets a new training direction method to be used for training. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">new_training_direction_method</td><td>Conjugate gradient training direction method. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a class="anchor" id="aee58db9e1adf83e2e1ab8bbba3a58ee1"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void OpenNN::ConjugateGradient::set_training_direction_method </td>
          <td>(</td>
          <td class="paramtype">const std::string &amp;&#160;</td>
          <td class="paramname"><em>new_training_direction_method_name</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Sets a new conjugate gradient training direction from a string representation. Possible values are: </p>
<ul>
<li>
"PR" </li>
<li>
"FR" </li>
</ul>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">new_training_direction_method_name</td><td>String with the name of the training direction method. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a class="anchor" id="ab9d2365e8c662083d1edd946d521f7bf"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void OpenNN::ConjugateGradient::set_warning_gradient_norm </td>
          <td>(</td>
          <td class="paramtype">const double &amp;&#160;</td>
          <td class="paramname"><em>new_warning_gradient_norm</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Sets a new value for the gradient vector norm at which a warning message is written to the screen. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">new_warning_gradient_norm</td><td>Warning norm of gradient vector value. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a class="anchor" id="a4b1a110fd305f1986af4cb58c528ac63"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void OpenNN::ConjugateGradient::set_warning_parameters_norm </td>
          <td>(</td>
          <td class="paramtype">const double &amp;&#160;</td>
          <td class="paramname"><em>new_warning_parameters_norm</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Sets a new value for the parameters vector norm at which a warning message is written to the screen. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">new_warning_parameters_norm</td><td>Warning norm of parameters vector value. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a class="anchor" id="abbae77c17da7d542b4e3c4251e57cb06"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void OpenNN::ConjugateGradient::set_warning_training_rate </td>
          <td>(</td>
          <td class="paramtype">const double &amp;&#160;</td>
          <td class="paramname"><em>new_warning_training_rate</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Sets a new training rate value at wich a warning message is written to the screen during line minimization. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">new_warning_training_rate</td><td>Warning training rate value. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a class="anchor" id="a77f7f09e45d38f021c38a12ff116d36b"></a>
<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="class_open_n_n_1_1_matrix.html">Matrix</a>&lt; std::string &gt; OpenNN::ConjugateGradient::to_string_matrix </td>
          <td>(</td>
          <td class="paramtype">void&#160;</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<p>Returns a default (empty) string matrix containing the members of the training algorithm object. </p>

<p>Reimplemented from <a class="el" href="class_open_n_n_1_1_training_algorithm.html#a41385b1044a60771b27bfa0d9818e0c6">OpenNN::TrainingAlgorithm</a>.</p>

</div>
</div>
<a class="anchor" id="a304ecc955e539bfec80538143d1ed2ee"></a>
<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">tinyxml2::XMLDocument * OpenNN::ConjugateGradient::to_XML </td>
          <td>(</td>
          <td class="paramtype">void&#160;</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<p>Serializes the conjugate gradient object into a XML document of the TinyXML library. See the OpenNN manual for more information about the format of this element. </p>

<p>Reimplemented from <a class="el" href="class_open_n_n_1_1_training_algorithm.html#a2f2d5d9d1d9bc7fb6bae6df90ba5df1c">OpenNN::TrainingAlgorithm</a>.</p>

</div>
</div>
<h2 class="groupheader">Member Data Documentation</h2>
<a class="anchor" id="adb9f750b428f492aea406838dbe77fb0"></a>
<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">unsigned OpenNN::ConjugateGradient::maximum_generalization_performance_decreases</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">private</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<p>Maximum number of iterations at which the generalization performance decreases. This is an early stopping method for improving generalization. </p>

</div>
</div>
<hr/>The documentation for this class was generated from the following files:<ul>
<li>C:/neural-designer/trunk/source/opennn/source/<a class="el" href="conjugate__gradient_8h_source.html">conjugate_gradient.h</a></li>
<li>C:/neural-designer/trunk/source/opennn/source/conjugate_gradient.cpp</li>
</ul>
</div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated on Tue Dec 31 2013 12:16:26 for OpenNN by &#160;<a href="http://www.doxygen.org/index.html">
<img class="footer" src="doxygen.png" alt="doxygen"/>
</a> 1.8.3.1
</small></address>
</body>
</html>
