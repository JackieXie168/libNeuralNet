<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html><head><meta http-equiv="Content-Type" content="text/html;charset=UTF-8">
<title>OpenNN: OpenNN::ConjugateGradient Class Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css">
<link href="doxygen.css" rel="stylesheet" type="text/css">
</head><body>
<!-- Generated by Doxygen 1.5.9 -->
<div class="navigation" id="top">
  <div class="tabs">
    <ul>
      <li><a href="index.html"><span>Main&nbsp;Page</span></a></li>
      <li><a href="pages.html"><span>Related&nbsp;Pages</span></a></li>
      <li class="current"><a href="annotated.html"><span>Classes</span></a></li>
      <li><a href="files.html"><span>Files</span></a></li>
    </ul>
  </div>
  <div class="tabs">
    <ul>
      <li><a href="annotated.html"><span>Class&nbsp;List</span></a></li>
      <li><a href="hierarchy.html"><span>Class&nbsp;Hierarchy</span></a></li>
      <li><a href="functions.html"><span>Class&nbsp;Members</span></a></li>
    </ul>
  </div>
  <div class="navpath"><b>OpenNN</b>::<a class="el" href="class_open_n_n_1_1_conjugate_gradient.html">ConjugateGradient</a>
  </div>
</div>
<div class="contents">
<h1>OpenNN::ConjugateGradient Class Reference</h1><!-- doxytag: class="OpenNN::ConjugateGradient" --><!-- doxytag: inherits="OpenNN::TrainingAlgorithm" --><code>#include &lt;<a class="el" href="conjugate__gradient_8h_source.html">conjugate_gradient.h</a>&gt;</code>
<p>
<div class="dynheader">
Inheritance diagram for OpenNN::ConjugateGradient:</div>
<div class="dynsection">

<p><center><img src="class_open_n_n_1_1_conjugate_gradient.png" usemap="#OpenNN::ConjugateGradient_map" border="0" alt=""></center>
<map name="OpenNN::ConjugateGradient_map">
<area href="class_open_n_n_1_1_training_algorithm.html" alt="OpenNN::TrainingAlgorithm" shape="rect" coords="0,0,172,24">
</map>
</div>

<p>
<a href="class_open_n_n_1_1_conjugate_gradient-members.html">List of all members.</a><table border="0" cellpadding="0" cellspacing="0">
<tr><td></td></tr>
<tr><td colspan="2"><br><h2>Classes</h2></td></tr>
<tr><td class="memItemLeft" nowrap align="right" valign="top">struct &nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="struct_open_n_n_1_1_conjugate_gradient_1_1_conjugate_gradient_results.html">ConjugateGradientResults</a></td></tr>

<tr><td colspan="2"><br><h2>Public Types</h2></td></tr>
<tr><td class="memItemLeft" nowrap align="right" valign="top">enum &nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_conjugate_gradient.html#6945bdfb0798a692bc45158307a05423">TrainingDirectionMethod</a> { <b>PR</b>, 
<b>FR</b>
 }</td></tr>

<tr><td colspan="2"><br><h2>Public Member Functions</h2></td></tr>
<tr><td class="memItemLeft" nowrap align="right" valign="top">&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_conjugate_gradient.html#1a583e3f482717a40656a18a0f9071ea">ConjugateGradient</a> (void)</td></tr>

<tr><td class="memItemLeft" nowrap align="right" valign="top">&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_conjugate_gradient.html#cb492edd9546dd27a67de1b91d80906b">ConjugateGradient</a> (<a class="el" href="class_open_n_n_1_1_performance_functional.html">PerformanceFunctional</a> *)</td></tr>

<tr><td class="memItemLeft" nowrap align="right" valign="top">&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_conjugate_gradient.html#017be76bfb8f94567c64c1e6e4869ea7">ConjugateGradient</a> (TiXmlElement *)</td></tr>

<tr><td class="memItemLeft" nowrap align="right" valign="top">virtual&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_conjugate_gradient.html#f2be8db22fb41b35959c4713450e47de">~ConjugateGradient</a> (void)</td></tr>

<tr><td class="memItemLeft" nowrap align="right" valign="top">const <a class="el" href="class_open_n_n_1_1_training_rate_algorithm.html">TrainingRateAlgorithm</a> &amp;&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_conjugate_gradient.html#28c02d60f1cb366d2678b563dd69fa94">get_training_rate_algorithm</a> (void) const </td></tr>

<tr><td class="memItemLeft" nowrap align="right" valign="top"><a class="el" href="class_open_n_n_1_1_training_rate_algorithm.html">TrainingRateAlgorithm</a> *&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_conjugate_gradient.html#b85062c33da1b9065b81ac946198a5c9">get_training_rate_algorithm_pointer</a> (void)</td></tr>

<tr><td class="memItemLeft" nowrap align="right" valign="top">const <a class="el" href="class_open_n_n_1_1_conjugate_gradient.html#6945bdfb0798a692bc45158307a05423">TrainingDirectionMethod</a> &amp;&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_conjugate_gradient.html#43e996a2ada93a8383616f937d256fca">get_training_direction_method</a> (void) const </td></tr>

<tr><td class="memItemLeft" nowrap align="right" valign="top">std::string&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_conjugate_gradient.html#020bd6b55cfcedf04647818eb388b292">write_training_direction_method</a> (void) const </td></tr>

<tr><td class="memItemLeft" nowrap align="right" valign="top">const double &amp;&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_conjugate_gradient.html#5e8a2b67c6a42a1b14fa97e2b69175f9">get_warning_parameters_norm</a> (void) const </td></tr>

<tr><td class="memItemLeft" nowrap align="right" valign="top">const double &amp;&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_conjugate_gradient.html#d81ca9794bb6f12cb779429e722ec80b">get_warning_gradient_norm</a> (void) const </td></tr>

<tr><td class="memItemLeft" nowrap align="right" valign="top">const double &amp;&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_conjugate_gradient.html#38eb80588a92a1b33b5d55f23619a92e">get_warning_training_rate</a> (void) const </td></tr>

<tr><td class="memItemLeft" nowrap align="right" valign="top">const double &amp;&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_conjugate_gradient.html#2d4b35306a6a32e8db701c4fbf279ab8">get_error_parameters_norm</a> (void) const </td></tr>

<tr><td class="memItemLeft" nowrap align="right" valign="top">const double &amp;&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_conjugate_gradient.html#1ca39aa64b5dc6587e8cd58899b28871">get_error_gradient_norm</a> (void) const </td></tr>

<tr><td class="memItemLeft" nowrap align="right" valign="top">const double &amp;&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_conjugate_gradient.html#823a4cd208d9d23e78c367b5d40dc973">get_error_training_rate</a> (void) const </td></tr>

<tr><td class="memItemLeft" nowrap align="right" valign="top">const double &amp;&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_conjugate_gradient.html#c51ecb02105e6c6eee62a03bfa4de9b5">get_minimum_parameters_increment_norm</a> (void) const </td></tr>

<tr><td class="memItemLeft" nowrap align="right" valign="top">const double &amp;&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_conjugate_gradient.html#438904120da1acb53573676ced73fb3e">get_minimum_performance_increase</a> (void) const </td></tr>

<tr><td class="memItemLeft" nowrap align="right" valign="top">const double &amp;&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_conjugate_gradient.html#952c454e35e25bd7c425b80bb33e3837">get_performance_goal</a> (void) const </td></tr>

<tr><td class="memItemLeft" nowrap align="right" valign="top">const unsigned int &amp;&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_conjugate_gradient.html#194897049aeb0163bf0f558ce566a980">get_maximum_generalization_evaluation_decreases</a> (void) const </td></tr>

<tr><td class="memItemLeft" nowrap align="right" valign="top">const double &amp;&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_conjugate_gradient.html#94c848cc3c12c07e246ae16d7a648a35">get_gradient_norm_goal</a> (void) const </td></tr>

<tr><td class="memItemLeft" nowrap align="right" valign="top">const unsigned int &amp;&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_conjugate_gradient.html#9d4a5f1af0823b85434a3da875aa2ad8">get_maximum_epochs_number</a> (void) const </td></tr>

<tr><td class="memItemLeft" nowrap align="right" valign="top">const double &amp;&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_conjugate_gradient.html#c5624cf775eb3edd705202f2ee984812">get_maximum_time</a> (void) const </td></tr>

<tr><td class="memItemLeft" nowrap align="right" valign="top">const bool &amp;&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_conjugate_gradient.html#32db840eb56ef1a5b63d05b72bfc548d">get_reserve_parameters_history</a> (void) const </td></tr>

<tr><td class="memItemLeft" nowrap align="right" valign="top">const bool &amp;&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_conjugate_gradient.html#3dcbdaa338cdce965a679c335559596e">get_reserve_parameters_norm_history</a> (void) const </td></tr>

<tr><td class="memItemLeft" nowrap align="right" valign="top">const bool &amp;&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_conjugate_gradient.html#3c679d7258867ddb0c2444d1ace3e97f">get_reserve_evaluation_history</a> (void) const </td></tr>

<tr><td class="memItemLeft" nowrap align="right" valign="top">const bool &amp;&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_conjugate_gradient.html#98ef4a1f946631cf02659db7b32cd6ef">get_reserve_generalization_evaluation_history</a> (void) const </td></tr>

<tr><td class="memItemLeft" nowrap align="right" valign="top">const bool &amp;&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_conjugate_gradient.html#6e4409d688dea5659d53353046bcbdb0">get_reserve_gradient_history</a> (void) const </td></tr>

<tr><td class="memItemLeft" nowrap align="right" valign="top">const bool &amp;&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_conjugate_gradient.html#3b5923caafc58407ebc36e6cbb7cc12d">get_reserve_gradient_norm_history</a> (void) const </td></tr>

<tr><td class="memItemLeft" nowrap align="right" valign="top">const bool &amp;&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_conjugate_gradient.html#5e688cf2d60a8619910b3477c69cd15a">get_reserve_training_direction_history</a> (void) const </td></tr>

<tr><td class="memItemLeft" nowrap align="right" valign="top">const bool &amp;&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_conjugate_gradient.html#b8d074f8bbd8a98c6314cf2e557aedc8">get_reserve_training_rate_history</a> (void) const </td></tr>

<tr><td class="memItemLeft" nowrap align="right" valign="top">const bool &amp;&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_conjugate_gradient.html#7aa7d75996822715371d62a40f056223">get_reserve_elapsed_time_history</a> (void) const </td></tr>

<tr><td class="memItemLeft" nowrap align="right" valign="top">const unsigned int &amp;&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_conjugate_gradient.html#877bd03a5d267e8d648c9ad1f5c941c8">get_display_period</a> (void) const </td></tr>

<tr><td class="memItemLeft" nowrap align="right" valign="top">void&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_conjugate_gradient.html#7098a0ce93b35aed9c735d9e8fdf87b5">set_default</a> (void)</td></tr>

<tr><td class="memItemLeft" nowrap align="right" valign="top">void&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_conjugate_gradient.html#6ae0ce9c10e2462993eee59883e490ba">set_training_direction_method</a> (const <a class="el" href="class_open_n_n_1_1_conjugate_gradient.html#6945bdfb0798a692bc45158307a05423">TrainingDirectionMethod</a> &amp;)</td></tr>

<tr><td class="memItemLeft" nowrap align="right" valign="top">void&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_conjugate_gradient.html#ee58db9e1adf83e2e1ab8bbba3a58ee1">set_training_direction_method</a> (const std::string &amp;)</td></tr>

<tr><td class="memItemLeft" nowrap align="right" valign="top">void&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_conjugate_gradient.html#4b1a110fd305f1986af4cb58c528ac63">set_warning_parameters_norm</a> (const double &amp;)</td></tr>

<tr><td class="memItemLeft" nowrap align="right" valign="top">void&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_conjugate_gradient.html#b9d2365e8c662083d1edd946d521f7bf">set_warning_gradient_norm</a> (const double &amp;)</td></tr>

<tr><td class="memItemLeft" nowrap align="right" valign="top">void&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_conjugate_gradient.html#bbae77c17da7d542b4e3c4251e57cb06">set_warning_training_rate</a> (const double &amp;)</td></tr>

<tr><td class="memItemLeft" nowrap align="right" valign="top">void&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_conjugate_gradient.html#c213f5dae6f2236e288462abb794a956">set_error_parameters_norm</a> (const double &amp;)</td></tr>

<tr><td class="memItemLeft" nowrap align="right" valign="top">void&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_conjugate_gradient.html#ac8d36d1372f47c9cf03a3b73c1df440">set_error_gradient_norm</a> (const double &amp;)</td></tr>

<tr><td class="memItemLeft" nowrap align="right" valign="top">void&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_conjugate_gradient.html#165eaf088bb453f5a8ffc231d61d3d5f">set_error_training_rate</a> (const double &amp;)</td></tr>

<tr><td class="memItemLeft" nowrap align="right" valign="top">void&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_conjugate_gradient.html#bcf2b6f18bb3ea67c66b8f274e05c170">set_minimum_parameters_increment_norm</a> (const double &amp;)</td></tr>

<tr><td class="memItemLeft" nowrap align="right" valign="top">void&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_conjugate_gradient.html#1e5f16b50b764b468183186422703313">set_performance_goal</a> (const double &amp;)</td></tr>

<tr><td class="memItemLeft" nowrap align="right" valign="top">void&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_conjugate_gradient.html#bfc1ed807a9f18532c879a82180aebd6">set_minimum_performance_increase</a> (const double &amp;)</td></tr>

<tr><td class="memItemLeft" nowrap align="right" valign="top">void&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_conjugate_gradient.html#ac4f86ed5087ff33770e3a92b3df4fdb">set_maximum_generalization_evaluation_decreases</a> (const unsigned int &amp;)</td></tr>

<tr><td class="memItemLeft" nowrap align="right" valign="top">void&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_conjugate_gradient.html#06331ca7f99debc62d1afadf26bff850">set_gradient_norm_goal</a> (const double &amp;)</td></tr>

<tr><td class="memItemLeft" nowrap align="right" valign="top">void&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_conjugate_gradient.html#aebcfb56d10a7846d587db6d66caea63">set_maximum_epochs_number</a> (const unsigned int &amp;)</td></tr>

<tr><td class="memItemLeft" nowrap align="right" valign="top">void&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_conjugate_gradient.html#7227ff99b52a9fa1a3a5905c6cc66b76">set_maximum_time</a> (const double &amp;)</td></tr>

<tr><td class="memItemLeft" nowrap align="right" valign="top">void&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_conjugate_gradient.html#9de9b218ff51f2393ea38006019f7ffa">set_reserve_parameters_history</a> (const bool &amp;)</td></tr>

<tr><td class="memItemLeft" nowrap align="right" valign="top">void&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_conjugate_gradient.html#274786cd036399313295dff4a097130c">set_reserve_parameters_norm_history</a> (const bool &amp;)</td></tr>

<tr><td class="memItemLeft" nowrap align="right" valign="top">void&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_conjugate_gradient.html#eb7604ee6718eeda10dbff12695ca215">set_reserve_evaluation_history</a> (const bool &amp;)</td></tr>

<tr><td class="memItemLeft" nowrap align="right" valign="top">void&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_conjugate_gradient.html#97eaf29840f91536f1a55878bc077882">set_reserve_generalization_evaluation_history</a> (const bool &amp;)</td></tr>

<tr><td class="memItemLeft" nowrap align="right" valign="top">void&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_conjugate_gradient.html#faef3aac943440a248a9f2e9851eb9c0">set_reserve_gradient_history</a> (const bool &amp;)</td></tr>

<tr><td class="memItemLeft" nowrap align="right" valign="top">void&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_conjugate_gradient.html#0c59f4b561c506844b01718945db2ea8">set_reserve_gradient_norm_history</a> (const bool &amp;)</td></tr>

<tr><td class="memItemLeft" nowrap align="right" valign="top">void&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_conjugate_gradient.html#379aa30482f6ce0a1ad2071a4e6f6b61">set_reserve_training_direction_history</a> (const bool &amp;)</td></tr>

<tr><td class="memItemLeft" nowrap align="right" valign="top">void&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_conjugate_gradient.html#e46832a168326e64d3e19ef769335771">set_reserve_training_rate_history</a> (const bool &amp;)</td></tr>

<tr><td class="memItemLeft" nowrap align="right" valign="top">void&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_conjugate_gradient.html#98b68a0401e023dc61692d4b7377a4ac">set_reserve_elapsed_time_history</a> (const bool &amp;)</td></tr>

<tr><td class="memItemLeft" nowrap align="right" valign="top">void&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_conjugate_gradient.html#5b21e8e16b09531d93384dd9339c02f5">set_reserve_all_training_history</a> (const bool &amp;)</td></tr>

<tr><td class="memItemLeft" nowrap align="right" valign="top">void&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_conjugate_gradient.html#a38aa187051cc3605a507a35d36b63be">set_display_period</a> (const unsigned int &amp;)</td></tr>

<tr><td class="memItemLeft" nowrap align="right" valign="top">double&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_conjugate_gradient.html#f73bcb65142c7608cca02496f6bc484b">calculate_PR_parameter</a> (const <a class="el" href="class_open_n_n_1_1_vector.html">Vector</a>&lt; double &gt; &amp;, const <a class="el" href="class_open_n_n_1_1_vector.html">Vector</a>&lt; double &gt; &amp;) const </td></tr>

<tr><td class="memItemLeft" nowrap align="right" valign="top">double&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_conjugate_gradient.html#eef9bc0433ecff10db98d87945b553ae">calculate_FR_parameter</a> (const <a class="el" href="class_open_n_n_1_1_vector.html">Vector</a>&lt; double &gt; &amp;, const <a class="el" href="class_open_n_n_1_1_vector.html">Vector</a>&lt; double &gt; &amp;) const </td></tr>

<tr><td class="memItemLeft" nowrap align="right" valign="top"><a class="el" href="class_open_n_n_1_1_vector.html">Vector</a>&lt; double &gt;&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_conjugate_gradient.html#349d877b87f39e34f2041ca12578493f">calculate_PR_training_direction</a> (const <a class="el" href="class_open_n_n_1_1_vector.html">Vector</a>&lt; double &gt; &amp;, const <a class="el" href="class_open_n_n_1_1_vector.html">Vector</a>&lt; double &gt; &amp;, const <a class="el" href="class_open_n_n_1_1_vector.html">Vector</a>&lt; double &gt; &amp;) const </td></tr>

<tr><td class="memItemLeft" nowrap align="right" valign="top"><a class="el" href="class_open_n_n_1_1_vector.html">Vector</a>&lt; double &gt;&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_conjugate_gradient.html#eb3e308b272d1bffa46c96cbb1160be7">calculate_FR_training_direction</a> (const <a class="el" href="class_open_n_n_1_1_vector.html">Vector</a>&lt; double &gt; &amp;, const <a class="el" href="class_open_n_n_1_1_vector.html">Vector</a>&lt; double &gt; &amp;, const <a class="el" href="class_open_n_n_1_1_vector.html">Vector</a>&lt; double &gt; &amp;) const </td></tr>

<tr><td class="memItemLeft" nowrap align="right" valign="top"><a class="el" href="class_open_n_n_1_1_vector.html">Vector</a>&lt; double &gt;&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_conjugate_gradient.html#24e0e461557d5f855c97dbeedf43d0cb">calculate_training_direction</a> (const <a class="el" href="class_open_n_n_1_1_vector.html">Vector</a>&lt; double &gt; &amp;, const <a class="el" href="class_open_n_n_1_1_vector.html">Vector</a>&lt; double &gt; &amp;, const <a class="el" href="class_open_n_n_1_1_vector.html">Vector</a>&lt; double &gt; &amp;) const </td></tr>

<tr><td class="memItemLeft" nowrap align="right" valign="top"><a class="el" href="class_open_n_n_1_1_vector.html">Vector</a>&lt; double &gt;&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_conjugate_gradient.html#42e7f404e32cceabb10a25d2b66f6ca4">calculate_gradient_descent_training_direction</a> (const <a class="el" href="class_open_n_n_1_1_vector.html">Vector</a>&lt; double &gt; &amp;) const </td></tr>

<tr><td class="memItemLeft" nowrap align="right" valign="top"><a class="el" href="struct_open_n_n_1_1_conjugate_gradient_1_1_conjugate_gradient_results.html">ConjugateGradientResults</a> *&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_conjugate_gradient.html#21c8810233ae2c5da6f6e5b923759d4f">perform_training</a> (void)</td></tr>

<tr><td class="memItemLeft" nowrap align="right" valign="top">std::string&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_conjugate_gradient.html#da7b8d4a49f4e401f94a08a287d5359e">write_training_algorithm_type</a> (void) const </td></tr>

<tr><td class="memItemLeft" nowrap align="right" valign="top">TiXmlElement *&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_conjugate_gradient.html#6c49f6f5185b73909d10decaed887b2a">to_XML</a> (void) const </td></tr>

<tr><td class="memItemLeft" nowrap align="right" valign="top">void&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_open_n_n_1_1_conjugate_gradient.html#0a4d9795e258a93cf261b996eb785018">from_XML</a> (TiXmlElement *)</td></tr>

</table>
<hr><a name="_details"></a><h2>Detailed Description</h2>
This concrete class represents a conjugate gradient training algorithm for a performance functional of a neural network. 
<p>Definition at line <a class="el" href="conjugate__gradient_8h_source.html#l00035">35</a> of file <a class="el" href="conjugate__gradient_8h_source.html">conjugate_gradient.h</a>.</p>
<hr><h2>Member Enumeration Documentation</h2>
<a class="anchor" name="6945bdfb0798a692bc45158307a05423"></a><!-- doxytag: member="OpenNN::ConjugateGradient::TrainingDirectionMethod" ref="6945bdfb0798a692bc45158307a05423" args="" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">enum <a class="el" href="class_open_n_n_1_1_conjugate_gradient.html#6945bdfb0798a692bc45158307a05423">OpenNN::ConjugateGradient::TrainingDirectionMethod</a>          </td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
Enumeration of the available training operators for obtaining the training direction. 
<p>

<p>Definition at line <a class="el" href="conjugate__gradient_8h_source.html#l00044">44</a> of file <a class="el" href="conjugate__gradient_8h_source.html">conjugate_gradient.h</a>.</p>

</div>
</div><p>
<hr><h2>Constructor &amp; Destructor Documentation</h2>
<a class="anchor" name="1a583e3f482717a40656a18a0f9071ea"></a><!-- doxytag: member="OpenNN::ConjugateGradient::ConjugateGradient" ref="1a583e3f482717a40656a18a0f9071ea" args="(void)" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">OpenNN::ConjugateGradient::ConjugateGradient           </td>
          <td>(</td>
          <td class="paramtype">void&nbsp;</td>
          <td class="paramname">          </td>
          <td>&nbsp;)&nbsp;</td>
          <td><code> [explicit]</code></td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
Default constructor. It creates a conjugate gradient training algorithm object not associated to any performance functional object. It also initializes the class members to their default values. 
<p>Definition at line <a class="el" href="conjugate__gradient_8cpp_source.html#l00046">46</a> of file <a class="el" href="conjugate__gradient_8cpp_source.html">conjugate_gradient.cpp</a>.</p>

</div>
</div><p>
<a class="anchor" name="cb492edd9546dd27a67de1b91d80906b"></a><!-- doxytag: member="OpenNN::ConjugateGradient::ConjugateGradient" ref="cb492edd9546dd27a67de1b91d80906b" args="(PerformanceFunctional *)" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">OpenNN::ConjugateGradient::ConjugateGradient           </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="class_open_n_n_1_1_performance_functional.html">PerformanceFunctional</a> *&nbsp;</td>
          <td class="paramname"> <em>new_performance_functional_pointer</em>          </td>
          <td>&nbsp;)&nbsp;</td>
          <td><code> [explicit]</code></td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
General constructor. It creates a conjugate gradient training algorithm associated to a performance functional object. It also initializes the rest of class members to their default values. <dl compact><dt><b>Parameters:</b></dt><dd>
  <table border="0" cellspacing="2" cellpadding="0">
    <tr><td valign="top"></td><td valign="top"><em>new_performance_functional_pointer</em>&nbsp;</td><td>Pointer to a performance functional object. </td></tr>
  </table>
</dl>

<p>Definition at line <a class="el" href="conjugate__gradient_8cpp_source.html#l00059">59</a> of file <a class="el" href="conjugate__gradient_8cpp_source.html">conjugate_gradient.cpp</a>.</p>

</div>
</div><p>
<a class="anchor" name="017be76bfb8f94567c64c1e6e4869ea7"></a><!-- doxytag: member="OpenNN::ConjugateGradient::ConjugateGradient" ref="017be76bfb8f94567c64c1e6e4869ea7" args="(TiXmlElement *)" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">OpenNN::ConjugateGradient::ConjugateGradient           </td>
          <td>(</td>
          <td class="paramtype">TiXmlElement *&nbsp;</td>
          <td class="paramname"> <em>conjugate_gradient_element</em>          </td>
          <td>&nbsp;)&nbsp;</td>
          <td><code> [explicit]</code></td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
XML constructor. It creates a conjugate gradient training algorithm not associated to any performance functional object. It also loads the class members from a XML element. <dl compact><dt><b>Parameters:</b></dt><dd>
  <table border="0" cellspacing="2" cellpadding="0">
    <tr><td valign="top"></td><td valign="top"><em>conjugate_gradient_element</em>&nbsp;</td><td>Tiny XML element with the members of a conjugate gradient object. </td></tr>
  </table>
</dl>

<p>Definition at line <a class="el" href="conjugate__gradient_8cpp_source.html#l00075">75</a> of file <a class="el" href="conjugate__gradient_8cpp_source.html">conjugate_gradient.cpp</a>.</p>

</div>
</div><p>
<a class="anchor" name="f2be8db22fb41b35959c4713450e47de"></a><!-- doxytag: member="OpenNN::ConjugateGradient::~ConjugateGradient" ref="f2be8db22fb41b35959c4713450e47de" args="(void)" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">OpenNN::ConjugateGradient::~ConjugateGradient           </td>
          <td>(</td>
          <td class="paramtype">void&nbsp;</td>
          <td class="paramname">          </td>
          <td>&nbsp;)&nbsp;</td>
          <td><code> [virtual]</code></td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
Destructor. 
<p>

<p>Definition at line <a class="el" href="conjugate__gradient_8cpp_source.html#l00088">88</a> of file <a class="el" href="conjugate__gradient_8cpp_source.html">conjugate_gradient.cpp</a>.</p>

</div>
</div><p>
<hr><h2>Member Function Documentation</h2>
<a class="anchor" name="28c02d60f1cb366d2678b563dd69fa94"></a><!-- doxytag: member="OpenNN::ConjugateGradient::get_training_rate_algorithm" ref="28c02d60f1cb366d2678b563dd69fa94" args="(void) const " -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">const <a class="el" href="class_open_n_n_1_1_training_rate_algorithm.html">TrainingRateAlgorithm</a> &amp; OpenNN::ConjugateGradient::get_training_rate_algorithm           </td>
          <td>(</td>
          <td class="paramtype">void&nbsp;</td>
          <td class="paramname">          </td>
          <td>&nbsp;)&nbsp;</td>
          <td> const</td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
This method returns a constant reference to the training rate algorithm object inside the conjugate gradient method object. 
<p>

<p>Definition at line <a class="el" href="conjugate__gradient_8cpp_source.html#l00099">99</a> of file <a class="el" href="conjugate__gradient_8cpp_source.html">conjugate_gradient.cpp</a>.</p>

</div>
</div><p>
<a class="anchor" name="b85062c33da1b9065b81ac946198a5c9"></a><!-- doxytag: member="OpenNN::ConjugateGradient::get_training_rate_algorithm_pointer" ref="b85062c33da1b9065b81ac946198a5c9" args="(void)" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="class_open_n_n_1_1_training_rate_algorithm.html">TrainingRateAlgorithm</a> * OpenNN::ConjugateGradient::get_training_rate_algorithm_pointer           </td>
          <td>(</td>
          <td class="paramtype">void&nbsp;</td>
          <td class="paramname">          </td>
          <td>&nbsp;)&nbsp;</td>
          <td></td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
This method returns a pointer to the training rate algorithm object inside the conjugate gradient method object. 
<p>

<p>Definition at line <a class="el" href="conjugate__gradient_8cpp_source.html#l00109">109</a> of file <a class="el" href="conjugate__gradient_8cpp_source.html">conjugate_gradient.cpp</a>.</p>

</div>
</div><p>
<a class="anchor" name="43e996a2ada93a8383616f937d256fca"></a><!-- doxytag: member="OpenNN::ConjugateGradient::get_training_direction_method" ref="43e996a2ada93a8383616f937d256fca" args="(void) const " -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">const <a class="el" href="class_open_n_n_1_1_conjugate_gradient.html#6945bdfb0798a692bc45158307a05423">ConjugateGradient::TrainingDirectionMethod</a> &amp; OpenNN::ConjugateGradient::get_training_direction_method           </td>
          <td>(</td>
          <td class="paramtype">void&nbsp;</td>
          <td class="paramname">          </td>
          <td>&nbsp;)&nbsp;</td>
          <td> const</td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
This method returns the conjugate gradient training direction method used for training. 
<p>

<p>Definition at line <a class="el" href="conjugate__gradient_8cpp_source.html#l00119">119</a> of file <a class="el" href="conjugate__gradient_8cpp_source.html">conjugate_gradient.cpp</a>.</p>

</div>
</div><p>
<a class="anchor" name="020bd6b55cfcedf04647818eb388b292"></a><!-- doxytag: member="OpenNN::ConjugateGradient::write_training_direction_method" ref="020bd6b55cfcedf04647818eb388b292" args="(void) const " -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">std::string OpenNN::ConjugateGradient::write_training_direction_method           </td>
          <td>(</td>
          <td class="paramtype">void&nbsp;</td>
          <td class="paramname">          </td>
          <td>&nbsp;)&nbsp;</td>
          <td> const</td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
This method returns a string with the name of the training direction. 
<p>

<p>Definition at line <a class="el" href="conjugate__gradient_8cpp_source.html#l00129">129</a> of file <a class="el" href="conjugate__gradient_8cpp_source.html">conjugate_gradient.cpp</a>.</p>

</div>
</div><p>
<a class="anchor" name="5e8a2b67c6a42a1b14fa97e2b69175f9"></a><!-- doxytag: member="OpenNN::ConjugateGradient::get_warning_parameters_norm" ref="5e8a2b67c6a42a1b14fa97e2b69175f9" args="(void) const " -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">const double &amp; OpenNN::ConjugateGradient::get_warning_parameters_norm           </td>
          <td>(</td>
          <td class="paramtype">void&nbsp;</td>
          <td class="paramname">          </td>
          <td>&nbsp;)&nbsp;</td>
          <td> const</td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
This method returns the minimum value for the norm of the parameters vector at wich a warning message is written to the screen. 
<p>

<p>Definition at line <a class="el" href="conjugate__gradient_8cpp_source.html#l00164">164</a> of file <a class="el" href="conjugate__gradient_8cpp_source.html">conjugate_gradient.cpp</a>.</p>

</div>
</div><p>
<a class="anchor" name="d81ca9794bb6f12cb779429e722ec80b"></a><!-- doxytag: member="OpenNN::ConjugateGradient::get_warning_gradient_norm" ref="d81ca9794bb6f12cb779429e722ec80b" args="(void) const " -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">const double &amp; OpenNN::ConjugateGradient::get_warning_gradient_norm           </td>
          <td>(</td>
          <td class="paramtype">void&nbsp;</td>
          <td class="paramname">          </td>
          <td>&nbsp;)&nbsp;</td>
          <td> const</td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
This method returns the minimum value for the norm of the gradient vector at wich a warning message is written to the screen. 
<p>

<p>Definition at line <a class="el" href="conjugate__gradient_8cpp_source.html#l00174">174</a> of file <a class="el" href="conjugate__gradient_8cpp_source.html">conjugate_gradient.cpp</a>.</p>

</div>
</div><p>
<a class="anchor" name="38eb80588a92a1b33b5d55f23619a92e"></a><!-- doxytag: member="OpenNN::ConjugateGradient::get_warning_training_rate" ref="38eb80588a92a1b33b5d55f23619a92e" args="(void) const " -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">const double &amp; OpenNN::ConjugateGradient::get_warning_training_rate           </td>
          <td>(</td>
          <td class="paramtype">void&nbsp;</td>
          <td class="paramname">          </td>
          <td>&nbsp;)&nbsp;</td>
          <td> const</td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
This method returns the training rate value at wich a warning message is written to the screen during line minimization. 
<p>

<p>Definition at line <a class="el" href="conjugate__gradient_8cpp_source.html#l00184">184</a> of file <a class="el" href="conjugate__gradient_8cpp_source.html">conjugate_gradient.cpp</a>.</p>

</div>
</div><p>
<a class="anchor" name="2d4b35306a6a32e8db701c4fbf279ab8"></a><!-- doxytag: member="OpenNN::ConjugateGradient::get_error_parameters_norm" ref="2d4b35306a6a32e8db701c4fbf279ab8" args="(void) const " -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">const double &amp; OpenNN::ConjugateGradient::get_error_parameters_norm           </td>
          <td>(</td>
          <td class="paramtype">void&nbsp;</td>
          <td class="paramname">          </td>
          <td>&nbsp;)&nbsp;</td>
          <td> const</td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
This method returns the value for the norm of the parameters vector at wich an error message is written to the screen and the program exits. 
<p>

<p>Definition at line <a class="el" href="conjugate__gradient_8cpp_source.html#l00194">194</a> of file <a class="el" href="conjugate__gradient_8cpp_source.html">conjugate_gradient.cpp</a>.</p>

</div>
</div><p>
<a class="anchor" name="1ca39aa64b5dc6587e8cd58899b28871"></a><!-- doxytag: member="OpenNN::ConjugateGradient::get_error_gradient_norm" ref="1ca39aa64b5dc6587e8cd58899b28871" args="(void) const " -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">const double &amp; OpenNN::ConjugateGradient::get_error_gradient_norm           </td>
          <td>(</td>
          <td class="paramtype">void&nbsp;</td>
          <td class="paramname">          </td>
          <td>&nbsp;)&nbsp;</td>
          <td> const</td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
This method returns the value for the norm of the gradient vector at wich an error message is written to the screen and the program exits. 
<p>Definition at line <a class="el" href="conjugate__gradient_8cpp_source.html#l00205">205</a> of file <a class="el" href="conjugate__gradient_8cpp_source.html">conjugate_gradient.cpp</a>.</p>

</div>
</div><p>
<a class="anchor" name="823a4cd208d9d23e78c367b5d40dc973"></a><!-- doxytag: member="OpenNN::ConjugateGradient::get_error_training_rate" ref="823a4cd208d9d23e78c367b5d40dc973" args="(void) const " -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">const double &amp; OpenNN::ConjugateGradient::get_error_training_rate           </td>
          <td>(</td>
          <td class="paramtype">void&nbsp;</td>
          <td class="paramname">          </td>
          <td>&nbsp;)&nbsp;</td>
          <td> const</td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
This method returns the training rate value at wich the line minimization algorithm is assumed to fail when bracketing a minimum. 
<p>Definition at line <a class="el" href="conjugate__gradient_8cpp_source.html#l00216">216</a> of file <a class="el" href="conjugate__gradient_8cpp_source.html">conjugate_gradient.cpp</a>.</p>

</div>
</div><p>
<a class="anchor" name="c51ecb02105e6c6eee62a03bfa4de9b5"></a><!-- doxytag: member="OpenNN::ConjugateGradient::get_minimum_parameters_increment_norm" ref="c51ecb02105e6c6eee62a03bfa4de9b5" args="(void) const " -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">const double &amp; OpenNN::ConjugateGradient::get_minimum_parameters_increment_norm           </td>
          <td>(</td>
          <td class="paramtype">void&nbsp;</td>
          <td class="paramname">          </td>
          <td>&nbsp;)&nbsp;</td>
          <td> const</td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
This method returns the minimum norm of the parameter increment vector used as a stopping criteria when training. 
<p>

<p>Definition at line <a class="el" href="conjugate__gradient_8cpp_source.html#l00226">226</a> of file <a class="el" href="conjugate__gradient_8cpp_source.html">conjugate_gradient.cpp</a>.</p>

</div>
</div><p>
<a class="anchor" name="438904120da1acb53573676ced73fb3e"></a><!-- doxytag: member="OpenNN::ConjugateGradient::get_minimum_performance_increase" ref="438904120da1acb53573676ced73fb3e" args="(void) const " -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">const double &amp; OpenNN::ConjugateGradient::get_minimum_performance_increase           </td>
          <td>(</td>
          <td class="paramtype">void&nbsp;</td>
          <td class="paramname">          </td>
          <td>&nbsp;)&nbsp;</td>
          <td> const</td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
This method returns the minimum performance improvement during training. 
<p>

<p>Definition at line <a class="el" href="conjugate__gradient_8cpp_source.html#l00236">236</a> of file <a class="el" href="conjugate__gradient_8cpp_source.html">conjugate_gradient.cpp</a>.</p>

</div>
</div><p>
<a class="anchor" name="952c454e35e25bd7c425b80bb33e3837"></a><!-- doxytag: member="OpenNN::ConjugateGradient::get_performance_goal" ref="952c454e35e25bd7c425b80bb33e3837" args="(void) const " -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">const double &amp; OpenNN::ConjugateGradient::get_performance_goal           </td>
          <td>(</td>
          <td class="paramtype">void&nbsp;</td>
          <td class="paramname">          </td>
          <td>&nbsp;)&nbsp;</td>
          <td> const</td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
This method returns the goal value for the performance. This is used as a stopping criterium when training a multilayer perceptron 
<p>Definition at line <a class="el" href="conjugate__gradient_8cpp_source.html#l00247">247</a> of file <a class="el" href="conjugate__gradient_8cpp_source.html">conjugate_gradient.cpp</a>.</p>

</div>
</div><p>
<a class="anchor" name="194897049aeb0163bf0f558ce566a980"></a><!-- doxytag: member="OpenNN::ConjugateGradient::get_maximum_generalization_evaluation_decreases" ref="194897049aeb0163bf0f558ce566a980" args="(void) const " -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">const unsigned int &amp; OpenNN::ConjugateGradient::get_maximum_generalization_evaluation_decreases           </td>
          <td>(</td>
          <td class="paramtype">void&nbsp;</td>
          <td class="paramname">          </td>
          <td>&nbsp;)&nbsp;</td>
          <td> const</td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
This method returns the maximum number of generalization failures during the training process. 
<p>

<p>Definition at line <a class="el" href="conjugate__gradient_8cpp_source.html#l00268">268</a> of file <a class="el" href="conjugate__gradient_8cpp_source.html">conjugate_gradient.cpp</a>.</p>

</div>
</div><p>
<a class="anchor" name="94c848cc3c12c07e246ae16d7a648a35"></a><!-- doxytag: member="OpenNN::ConjugateGradient::get_gradient_norm_goal" ref="94c848cc3c12c07e246ae16d7a648a35" args="(void) const " -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">const double &amp; OpenNN::ConjugateGradient::get_gradient_norm_goal           </td>
          <td>(</td>
          <td class="paramtype">void&nbsp;</td>
          <td class="paramname">          </td>
          <td>&nbsp;)&nbsp;</td>
          <td> const</td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
This method returns the goal value for the norm of the objective function gradient. This is used as a stopping criterium when training a multilayer perceptron 
<p>Definition at line <a class="el" href="conjugate__gradient_8cpp_source.html#l00258">258</a> of file <a class="el" href="conjugate__gradient_8cpp_source.html">conjugate_gradient.cpp</a>.</p>

</div>
</div><p>
<a class="anchor" name="9d4a5f1af0823b85434a3da875aa2ad8"></a><!-- doxytag: member="OpenNN::ConjugateGradient::get_maximum_epochs_number" ref="9d4a5f1af0823b85434a3da875aa2ad8" args="(void) const " -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">const unsigned int &amp; OpenNN::ConjugateGradient::get_maximum_epochs_number           </td>
          <td>(</td>
          <td class="paramtype">void&nbsp;</td>
          <td class="paramname">          </td>
          <td>&nbsp;)&nbsp;</td>
          <td> const</td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
This method returns the maximum number of epochs for training. 
<p>

<p>Definition at line <a class="el" href="conjugate__gradient_8cpp_source.html#l00278">278</a> of file <a class="el" href="conjugate__gradient_8cpp_source.html">conjugate_gradient.cpp</a>.</p>

</div>
</div><p>
<a class="anchor" name="c5624cf775eb3edd705202f2ee984812"></a><!-- doxytag: member="OpenNN::ConjugateGradient::get_maximum_time" ref="c5624cf775eb3edd705202f2ee984812" args="(void) const " -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">const double &amp; OpenNN::ConjugateGradient::get_maximum_time           </td>
          <td>(</td>
          <td class="paramtype">void&nbsp;</td>
          <td class="paramname">          </td>
          <td>&nbsp;)&nbsp;</td>
          <td> const</td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
This method returns the maximum training time. 
<p>

<p>Definition at line <a class="el" href="conjugate__gradient_8cpp_source.html#l00288">288</a> of file <a class="el" href="conjugate__gradient_8cpp_source.html">conjugate_gradient.cpp</a>.</p>

</div>
</div><p>
<a class="anchor" name="32db840eb56ef1a5b63d05b72bfc548d"></a><!-- doxytag: member="OpenNN::ConjugateGradient::get_reserve_parameters_history" ref="32db840eb56ef1a5b63d05b72bfc548d" args="(void) const " -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">const bool &amp; OpenNN::ConjugateGradient::get_reserve_parameters_history           </td>
          <td>(</td>
          <td class="paramtype">void&nbsp;</td>
          <td class="paramname">          </td>
          <td>&nbsp;)&nbsp;</td>
          <td> const</td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
This method returns true if the parameters history matrix is to be reserved, and false otherwise. 
<p>

<p>Definition at line <a class="el" href="conjugate__gradient_8cpp_source.html#l00298">298</a> of file <a class="el" href="conjugate__gradient_8cpp_source.html">conjugate_gradient.cpp</a>.</p>

</div>
</div><p>
<a class="anchor" name="3dcbdaa338cdce965a679c335559596e"></a><!-- doxytag: member="OpenNN::ConjugateGradient::get_reserve_parameters_norm_history" ref="3dcbdaa338cdce965a679c335559596e" args="(void) const " -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">const bool &amp; OpenNN::ConjugateGradient::get_reserve_parameters_norm_history           </td>
          <td>(</td>
          <td class="paramtype">void&nbsp;</td>
          <td class="paramname">          </td>
          <td>&nbsp;)&nbsp;</td>
          <td> const</td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
This method returns true if the parameters norm history vector is to be reserved, and false otherwise. 
<p>

<p>Definition at line <a class="el" href="conjugate__gradient_8cpp_source.html#l00308">308</a> of file <a class="el" href="conjugate__gradient_8cpp_source.html">conjugate_gradient.cpp</a>.</p>

</div>
</div><p>
<a class="anchor" name="3c679d7258867ddb0c2444d1ace3e97f"></a><!-- doxytag: member="OpenNN::ConjugateGradient::get_reserve_evaluation_history" ref="3c679d7258867ddb0c2444d1ace3e97f" args="(void) const " -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">const bool &amp; OpenNN::ConjugateGradient::get_reserve_evaluation_history           </td>
          <td>(</td>
          <td class="paramtype">void&nbsp;</td>
          <td class="paramname">          </td>
          <td>&nbsp;)&nbsp;</td>
          <td> const</td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
This method returns true if the evaluation history vector is to be reserved, and false otherwise. 
<p>

<p>Definition at line <a class="el" href="conjugate__gradient_8cpp_source.html#l00318">318</a> of file <a class="el" href="conjugate__gradient_8cpp_source.html">conjugate_gradient.cpp</a>.</p>

</div>
</div><p>
<a class="anchor" name="98ef4a1f946631cf02659db7b32cd6ef"></a><!-- doxytag: member="OpenNN::ConjugateGradient::get_reserve_generalization_evaluation_history" ref="98ef4a1f946631cf02659db7b32cd6ef" args="(void) const " -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">const bool &amp; OpenNN::ConjugateGradient::get_reserve_generalization_evaluation_history           </td>
          <td>(</td>
          <td class="paramtype">void&nbsp;</td>
          <td class="paramname">          </td>
          <td>&nbsp;)&nbsp;</td>
          <td> const</td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
This method returns true if the Generalization evaluation history vector is to be reserved, and false otherwise. 
<p>

<p>Definition at line <a class="el" href="conjugate__gradient_8cpp_source.html#l00379">379</a> of file <a class="el" href="conjugate__gradient_8cpp_source.html">conjugate_gradient.cpp</a>.</p>

</div>
</div><p>
<a class="anchor" name="6e4409d688dea5659d53353046bcbdb0"></a><!-- doxytag: member="OpenNN::ConjugateGradient::get_reserve_gradient_history" ref="6e4409d688dea5659d53353046bcbdb0" args="(void) const " -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">const bool &amp; OpenNN::ConjugateGradient::get_reserve_gradient_history           </td>
          <td>(</td>
          <td class="paramtype">void&nbsp;</td>
          <td class="paramname">          </td>
          <td>&nbsp;)&nbsp;</td>
          <td> const</td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
This method returns true if the gradient history vector of vectors is to be reserved, and false otherwise. 
<p>

<p>Definition at line <a class="el" href="conjugate__gradient_8cpp_source.html#l00328">328</a> of file <a class="el" href="conjugate__gradient_8cpp_source.html">conjugate_gradient.cpp</a>.</p>

</div>
</div><p>
<a class="anchor" name="3b5923caafc58407ebc36e6cbb7cc12d"></a><!-- doxytag: member="OpenNN::ConjugateGradient::get_reserve_gradient_norm_history" ref="3b5923caafc58407ebc36e6cbb7cc12d" args="(void) const " -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">const bool &amp; OpenNN::ConjugateGradient::get_reserve_gradient_norm_history           </td>
          <td>(</td>
          <td class="paramtype">void&nbsp;</td>
          <td class="paramname">          </td>
          <td>&nbsp;)&nbsp;</td>
          <td> const</td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
This method returns true if the gradient norm history vector is to be reserved, and false otherwise. 
<p>

<p>Definition at line <a class="el" href="conjugate__gradient_8cpp_source.html#l00338">338</a> of file <a class="el" href="conjugate__gradient_8cpp_source.html">conjugate_gradient.cpp</a>.</p>

</div>
</div><p>
<a class="anchor" name="5e688cf2d60a8619910b3477c69cd15a"></a><!-- doxytag: member="OpenNN::ConjugateGradient::get_reserve_training_direction_history" ref="5e688cf2d60a8619910b3477c69cd15a" args="(void) const " -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">const bool &amp; OpenNN::ConjugateGradient::get_reserve_training_direction_history           </td>
          <td>(</td>
          <td class="paramtype">void&nbsp;</td>
          <td class="paramname">          </td>
          <td>&nbsp;)&nbsp;</td>
          <td> const</td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
This method returns true if the training direction history matrix is to be reserved, and false otherwise. 
<p>

<p>Definition at line <a class="el" href="conjugate__gradient_8cpp_source.html#l00349">349</a> of file <a class="el" href="conjugate__gradient_8cpp_source.html">conjugate_gradient.cpp</a>.</p>

</div>
</div><p>
<a class="anchor" name="b8d074f8bbd8a98c6314cf2e557aedc8"></a><!-- doxytag: member="OpenNN::ConjugateGradient::get_reserve_training_rate_history" ref="b8d074f8bbd8a98c6314cf2e557aedc8" args="(void) const " -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">const bool &amp; OpenNN::ConjugateGradient::get_reserve_training_rate_history           </td>
          <td>(</td>
          <td class="paramtype">void&nbsp;</td>
          <td class="paramname">          </td>
          <td>&nbsp;)&nbsp;</td>
          <td> const</td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
This method returns true if the training rate history vector is to be reserved, and false otherwise. 
<p>

<p>Definition at line <a class="el" href="conjugate__gradient_8cpp_source.html#l00359">359</a> of file <a class="el" href="conjugate__gradient_8cpp_source.html">conjugate_gradient.cpp</a>.</p>

</div>
</div><p>
<a class="anchor" name="7aa7d75996822715371d62a40f056223"></a><!-- doxytag: member="OpenNN::ConjugateGradient::get_reserve_elapsed_time_history" ref="7aa7d75996822715371d62a40f056223" args="(void) const " -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">const bool &amp; OpenNN::ConjugateGradient::get_reserve_elapsed_time_history           </td>
          <td>(</td>
          <td class="paramtype">void&nbsp;</td>
          <td class="paramname">          </td>
          <td>&nbsp;)&nbsp;</td>
          <td> const</td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
This method returns true if the elapsed time history vector is to be reserved, and false otherwise. 
<p>

<p>Definition at line <a class="el" href="conjugate__gradient_8cpp_source.html#l00369">369</a> of file <a class="el" href="conjugate__gradient_8cpp_source.html">conjugate_gradient.cpp</a>.</p>

</div>
</div><p>
<a class="anchor" name="877bd03a5d267e8d648c9ad1f5c941c8"></a><!-- doxytag: member="OpenNN::ConjugateGradient::get_display_period" ref="877bd03a5d267e8d648c9ad1f5c941c8" args="(void) const " -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">const unsigned int &amp; OpenNN::ConjugateGradient::get_display_period           </td>
          <td>(</td>
          <td class="paramtype">void&nbsp;</td>
          <td class="paramname">          </td>
          <td>&nbsp;)&nbsp;</td>
          <td> const</td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
This method returns the number of epochs between the training showing progress. 
<p>

<p>Definition at line <a class="el" href="conjugate__gradient_8cpp_source.html#l00389">389</a> of file <a class="el" href="conjugate__gradient_8cpp_source.html">conjugate_gradient.cpp</a>.</p>

</div>
</div><p>
<a class="anchor" name="7098a0ce93b35aed9c735d9e8fdf87b5"></a><!-- doxytag: member="OpenNN::ConjugateGradient::set_default" ref="7098a0ce93b35aed9c735d9e8fdf87b5" args="(void)" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void OpenNN::ConjugateGradient::set_default           </td>
          <td>(</td>
          <td class="paramtype">void&nbsp;</td>
          <td class="paramname">          </td>
          <td>&nbsp;)&nbsp;</td>
          <td><code> [virtual]</code></td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
This method sets the default values into a conjugate gradient object. Training operators: <ul>
<li>
Training direction method = Polak-Ribiere; </li>
<li>
Training rate method = Brent; </li>
</ul>
Training parameters: <ul>
<li>
First training rate: 1.0. </li>
<li>
Bracketing factor: 2.0. </li>
<li>
Training rate tolerance: 1.0e-3. </li>
</ul>
Stopping criteria: <ul>
<li>
Performance goal: -1.0e99. </li>
<li>
Gradient norm goal: 0.0. </li>
<li>
Maximum training time: 1.0e6. </li>
<li>
Maximum number of epochs: 100. </li>
</ul>
User stuff: <ul>
<li>
Warning training rate: 1.0e6. </li>
<li>
Error training rate: 1.0e12. </li>
<li>
Display: true. </li>
<li>
Display period: 25. </li>
</ul>
Reserve: <ul>
<li>
Reserve training direction history: false. </li>
<li>
Reserve training direction norm history: false. </li>
<li>
Reserve training rate history: false. </li>
</ul>

<p>Reimplemented from <a class="el" href="class_open_n_n_1_1_training_algorithm.html#856d53c16da6bf5726da0f8403a13349">OpenNN::TrainingAlgorithm</a>.</p>

<p>Definition at line <a class="el" href="conjugate__gradient_8cpp_source.html#l00520">520</a> of file <a class="el" href="conjugate__gradient_8cpp_source.html">conjugate_gradient.cpp</a>.</p>

</div>
</div><p>
<a class="anchor" name="6ae0ce9c10e2462993eee59883e490ba"></a><!-- doxytag: member="OpenNN::ConjugateGradient::set_training_direction_method" ref="6ae0ce9c10e2462993eee59883e490ba" args="(const TrainingDirectionMethod &amp;)" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void OpenNN::ConjugateGradient::set_training_direction_method           </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="class_open_n_n_1_1_conjugate_gradient.html#6945bdfb0798a692bc45158307a05423">TrainingDirectionMethod</a> &amp;&nbsp;</td>
          <td class="paramname"> <em>new_training_direction_method</em>          </td>
          <td>&nbsp;)&nbsp;</td>
          <td></td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
This method sets a new training direction method to be used for training.<p>
<dl compact><dt><b>Parameters:</b></dt><dd>
  <table border="0" cellspacing="2" cellpadding="0">
    <tr><td valign="top"></td><td valign="top"><em>new_training_direction_method</em>&nbsp;</td><td>Conjugate gradient training direction method. </td></tr>
  </table>
</dl>

<p>Definition at line <a class="el" href="conjugate__gradient_8cpp_source.html#l00403">403</a> of file <a class="el" href="conjugate__gradient_8cpp_source.html">conjugate_gradient.cpp</a>.</p>

</div>
</div><p>
<a class="anchor" name="ee58db9e1adf83e2e1ab8bbba3a58ee1"></a><!-- doxytag: member="OpenNN::ConjugateGradient::set_training_direction_method" ref="ee58db9e1adf83e2e1ab8bbba3a58ee1" args="(const std::string &amp;)" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void OpenNN::ConjugateGradient::set_training_direction_method           </td>
          <td>(</td>
          <td class="paramtype">const std::string &amp;&nbsp;</td>
          <td class="paramname"> <em>new_training_direction_method_name</em>          </td>
          <td>&nbsp;)&nbsp;</td>
          <td></td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
This method sets a new conjugate gradient training direction from a string representation. Possible values are: <ul>
<li>
"PR" </li>
<li>
"FR" </li>
</ul>
<dl compact><dt><b>Parameters:</b></dt><dd>
  <table border="0" cellspacing="2" cellpadding="0">
    <tr><td valign="top"></td><td valign="top"><em>new_training_direction_method_name</em>&nbsp;</td><td>String with the name of the training direction method. </td></tr>
  </table>
</dl>

<p>Definition at line <a class="el" href="conjugate__gradient_8cpp_source.html#l00419">419</a> of file <a class="el" href="conjugate__gradient_8cpp_source.html">conjugate_gradient.cpp</a>.</p>

</div>
</div><p>
<a class="anchor" name="4b1a110fd305f1986af4cb58c528ac63"></a><!-- doxytag: member="OpenNN::ConjugateGradient::set_warning_parameters_norm" ref="4b1a110fd305f1986af4cb58c528ac63" args="(const double &amp;)" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void OpenNN::ConjugateGradient::set_warning_parameters_norm           </td>
          <td>(</td>
          <td class="paramtype">const double &amp;&nbsp;</td>
          <td class="paramname"> <em>new_warning_parameters_norm</em>          </td>
          <td>&nbsp;)&nbsp;</td>
          <td></td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
This method sets a new value for the parameters vector norm at which a warning message is written to the screen. <dl compact><dt><b>Parameters:</b></dt><dd>
  <table border="0" cellspacing="2" cellpadding="0">
    <tr><td valign="top"></td><td valign="top"><em>new_warning_parameters_norm</em>&nbsp;</td><td>Warning norm of parameters vector value. </td></tr>
  </table>
</dl>

<p>Definition at line <a class="el" href="conjugate__gradient_8cpp_source.html#l00574">574</a> of file <a class="el" href="conjugate__gradient_8cpp_source.html">conjugate_gradient.cpp</a>.</p>

</div>
</div><p>
<a class="anchor" name="b9d2365e8c662083d1edd946d521f7bf"></a><!-- doxytag: member="OpenNN::ConjugateGradient::set_warning_gradient_norm" ref="b9d2365e8c662083d1edd946d521f7bf" args="(const double &amp;)" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void OpenNN::ConjugateGradient::set_warning_gradient_norm           </td>
          <td>(</td>
          <td class="paramtype">const double &amp;&nbsp;</td>
          <td class="paramname"> <em>new_warning_gradient_norm</em>          </td>
          <td>&nbsp;)&nbsp;</td>
          <td></td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
This method sets a new value for the gradient vector norm at which a warning message is written to the screen. <dl compact><dt><b>Parameters:</b></dt><dd>
  <table border="0" cellspacing="2" cellpadding="0">
    <tr><td valign="top"></td><td valign="top"><em>new_warning_gradient_norm</em>&nbsp;</td><td>Warning norm of gradient vector value. </td></tr>
  </table>
</dl>

<p>Definition at line <a class="el" href="conjugate__gradient_8cpp_source.html#l00605">605</a> of file <a class="el" href="conjugate__gradient_8cpp_source.html">conjugate_gradient.cpp</a>.</p>

</div>
</div><p>
<a class="anchor" name="bbae77c17da7d542b4e3c4251e57cb06"></a><!-- doxytag: member="OpenNN::ConjugateGradient::set_warning_training_rate" ref="bbae77c17da7d542b4e3c4251e57cb06" args="(const double &amp;)" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void OpenNN::ConjugateGradient::set_warning_training_rate           </td>
          <td>(</td>
          <td class="paramtype">const double &amp;&nbsp;</td>
          <td class="paramname"> <em>new_warning_training_rate</em>          </td>
          <td>&nbsp;)&nbsp;</td>
          <td></td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
This method sets a new training rate value at wich a warning message is written to the screen during line minimization. <dl compact><dt><b>Parameters:</b></dt><dd>
  <table border="0" cellspacing="2" cellpadding="0">
    <tr><td valign="top"></td><td valign="top"><em>new_warning_training_rate</em>&nbsp;</td><td>Warning training rate value. </td></tr>
  </table>
</dl>

<p>Definition at line <a class="el" href="conjugate__gradient_8cpp_source.html#l00636">636</a> of file <a class="el" href="conjugate__gradient_8cpp_source.html">conjugate_gradient.cpp</a>.</p>

</div>
</div><p>
<a class="anchor" name="c213f5dae6f2236e288462abb794a956"></a><!-- doxytag: member="OpenNN::ConjugateGradient::set_error_parameters_norm" ref="c213f5dae6f2236e288462abb794a956" args="(const double &amp;)" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void OpenNN::ConjugateGradient::set_error_parameters_norm           </td>
          <td>(</td>
          <td class="paramtype">const double &amp;&nbsp;</td>
          <td class="paramname"> <em>new_error_parameters_norm</em>          </td>
          <td>&nbsp;)&nbsp;</td>
          <td></td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
This method sets a new value for the parameters vector norm at which an error message is written to the screen and the program exits. <dl compact><dt><b>Parameters:</b></dt><dd>
  <table border="0" cellspacing="2" cellpadding="0">
    <tr><td valign="top"></td><td valign="top"><em>new_error_parameters_norm</em>&nbsp;</td><td>Error norm of parameters vector value. </td></tr>
  </table>
</dl>

<p>Definition at line <a class="el" href="conjugate__gradient_8cpp_source.html#l00665">665</a> of file <a class="el" href="conjugate__gradient_8cpp_source.html">conjugate_gradient.cpp</a>.</p>

</div>
</div><p>
<a class="anchor" name="ac8d36d1372f47c9cf03a3b73c1df440"></a><!-- doxytag: member="OpenNN::ConjugateGradient::set_error_gradient_norm" ref="ac8d36d1372f47c9cf03a3b73c1df440" args="(const double &amp;)" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void OpenNN::ConjugateGradient::set_error_gradient_norm           </td>
          <td>(</td>
          <td class="paramtype">const double &amp;&nbsp;</td>
          <td class="paramname"> <em>new_error_gradient_norm</em>          </td>
          <td>&nbsp;)&nbsp;</td>
          <td></td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
This method sets a new value for the gradient vector norm at which an error message is written to the screen and the program exits. <dl compact><dt><b>Parameters:</b></dt><dd>
  <table border="0" cellspacing="2" cellpadding="0">
    <tr><td valign="top"></td><td valign="top"><em>new_error_gradient_norm</em>&nbsp;</td><td>Error norm of gradient vector value. </td></tr>
  </table>
</dl>

<p>Definition at line <a class="el" href="conjugate__gradient_8cpp_source.html#l00696">696</a> of file <a class="el" href="conjugate__gradient_8cpp_source.html">conjugate_gradient.cpp</a>.</p>

</div>
</div><p>
<a class="anchor" name="165eaf088bb453f5a8ffc231d61d3d5f"></a><!-- doxytag: member="OpenNN::ConjugateGradient::set_error_training_rate" ref="165eaf088bb453f5a8ffc231d61d3d5f" args="(const double &amp;)" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void OpenNN::ConjugateGradient::set_error_training_rate           </td>
          <td>(</td>
          <td class="paramtype">const double &amp;&nbsp;</td>
          <td class="paramname"> <em>new_error_training_rate</em>          </td>
          <td>&nbsp;)&nbsp;</td>
          <td></td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
This method sets a new training rate value at wich a the line minimization algorithm is assumed to fail when bracketing a minimum. <dl compact><dt><b>Parameters:</b></dt><dd>
  <table border="0" cellspacing="2" cellpadding="0">
    <tr><td valign="top"></td><td valign="top"><em>new_error_training_rate</em>&nbsp;</td><td>Error training rate value. </td></tr>
  </table>
</dl>

<p>Definition at line <a class="el" href="conjugate__gradient_8cpp_source.html#l00727">727</a> of file <a class="el" href="conjugate__gradient_8cpp_source.html">conjugate_gradient.cpp</a>.</p>

</div>
</div><p>
<a class="anchor" name="bcf2b6f18bb3ea67c66b8f274e05c170"></a><!-- doxytag: member="OpenNN::ConjugateGradient::set_minimum_parameters_increment_norm" ref="bcf2b6f18bb3ea67c66b8f274e05c170" args="(const double &amp;)" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void OpenNN::ConjugateGradient::set_minimum_parameters_increment_norm           </td>
          <td>(</td>
          <td class="paramtype">const double &amp;&nbsp;</td>
          <td class="paramname"> <em>new_minimum_parameters_increment_norm</em>          </td>
          <td>&nbsp;)&nbsp;</td>
          <td></td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
This method sets a new value for the minimum parameters increment norm stopping criterium. <dl compact><dt><b>Parameters:</b></dt><dd>
  <table border="0" cellspacing="2" cellpadding="0">
    <tr><td valign="top"></td><td valign="top"><em>new_minimum_parameters_increment_norm</em>&nbsp;</td><td>Value of norm of parameters increment norm used to stop training. </td></tr>
  </table>
</dl>

<p>Definition at line <a class="el" href="conjugate__gradient_8cpp_source.html#l00757">757</a> of file <a class="el" href="conjugate__gradient_8cpp_source.html">conjugate_gradient.cpp</a>.</p>

</div>
</div><p>
<a class="anchor" name="1e5f16b50b764b468183186422703313"></a><!-- doxytag: member="OpenNN::ConjugateGradient::set_performance_goal" ref="1e5f16b50b764b468183186422703313" args="(const double &amp;)" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void OpenNN::ConjugateGradient::set_performance_goal           </td>
          <td>(</td>
          <td class="paramtype">const double &amp;&nbsp;</td>
          <td class="paramname"> <em>new_performance_goal</em>          </td>
          <td>&nbsp;)&nbsp;</td>
          <td></td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
This method sets a new goal value for the performance. This is used as a stopping criterium when training a multilayer perceptron <dl compact><dt><b>Parameters:</b></dt><dd>
  <table border="0" cellspacing="2" cellpadding="0">
    <tr><td valign="top"></td><td valign="top"><em>new_performance_goal</em>&nbsp;</td><td>Goal value for the performance. </td></tr>
  </table>
</dl>

<p>Definition at line <a class="el" href="conjugate__gradient_8cpp_source.html#l00818">818</a> of file <a class="el" href="conjugate__gradient_8cpp_source.html">conjugate_gradient.cpp</a>.</p>

</div>
</div><p>
<a class="anchor" name="bfc1ed807a9f18532c879a82180aebd6"></a><!-- doxytag: member="OpenNN::ConjugateGradient::set_minimum_performance_increase" ref="bfc1ed807a9f18532c879a82180aebd6" args="(const double &amp;)" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void OpenNN::ConjugateGradient::set_minimum_performance_increase           </td>
          <td>(</td>
          <td class="paramtype">const double &amp;&nbsp;</td>
          <td class="paramname"> <em>new_minimum_performance_increase</em>          </td>
          <td>&nbsp;)&nbsp;</td>
          <td></td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
This method sets a new minimum performance improvement during training. <dl compact><dt><b>Parameters:</b></dt><dd>
  <table border="0" cellspacing="2" cellpadding="0">
    <tr><td valign="top"></td><td valign="top"><em>new_minimum_performance_increase</em>&nbsp;</td><td>Minimum improvement in the performance between two epochs. </td></tr>
  </table>
</dl>

<p>Definition at line <a class="el" href="conjugate__gradient_8cpp_source.html#l00787">787</a> of file <a class="el" href="conjugate__gradient_8cpp_source.html">conjugate_gradient.cpp</a>.</p>

</div>
</div><p>
<a class="anchor" name="ac4f86ed5087ff33770e3a92b3df4fdb"></a><!-- doxytag: member="OpenNN::ConjugateGradient::set_maximum_generalization_evaluation_decreases" ref="ac4f86ed5087ff33770e3a92b3df4fdb" args="(const unsigned int &amp;)" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void OpenNN::ConjugateGradient::set_maximum_generalization_evaluation_decreases           </td>
          <td>(</td>
          <td class="paramtype">const unsigned int &amp;&nbsp;</td>
          <td class="paramname"> <em>new_maximum_generalization_evaluation_decreases</em>          </td>
          <td>&nbsp;)&nbsp;</td>
          <td></td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
This method sets a new maximum number of generalization failures. <dl compact><dt><b>Parameters:</b></dt><dd>
  <table border="0" cellspacing="2" cellpadding="0">
    <tr><td valign="top"></td><td valign="top"><em>new_maximum_generalization_evaluation_decreases</em>&nbsp;</td><td>Maximum number of epochs in which the generalization evalutation decreases. </td></tr>
  </table>
</dl>

<p>Definition at line <a class="el" href="conjugate__gradient_8cpp_source.html#l00860">860</a> of file <a class="el" href="conjugate__gradient_8cpp_source.html">conjugate_gradient.cpp</a>.</p>

</div>
</div><p>
<a class="anchor" name="06331ca7f99debc62d1afadf26bff850"></a><!-- doxytag: member="OpenNN::ConjugateGradient::set_gradient_norm_goal" ref="06331ca7f99debc62d1afadf26bff850" args="(const double &amp;)" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void OpenNN::ConjugateGradient::set_gradient_norm_goal           </td>
          <td>(</td>
          <td class="paramtype">const double &amp;&nbsp;</td>
          <td class="paramname"> <em>new_gradient_norm_goal</em>          </td>
          <td>&nbsp;)&nbsp;</td>
          <td></td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
This method sets a new the goal value for the norm of the objective function gradient. This is used as a stopping criterium when training a multilayer perceptron <dl compact><dt><b>Parameters:</b></dt><dd>
  <table border="0" cellspacing="2" cellpadding="0">
    <tr><td valign="top"></td><td valign="top"><em>new_gradient_norm_goal</em>&nbsp;</td><td>Goal value for the norm of the objective function gradient. </td></tr>
  </table>
</dl>

<p>Definition at line <a class="el" href="conjugate__gradient_8cpp_source.html#l00830">830</a> of file <a class="el" href="conjugate__gradient_8cpp_source.html">conjugate_gradient.cpp</a>.</p>

</div>
</div><p>
<a class="anchor" name="aebcfb56d10a7846d587db6d66caea63"></a><!-- doxytag: member="OpenNN::ConjugateGradient::set_maximum_epochs_number" ref="aebcfb56d10a7846d587db6d66caea63" args="(const unsigned int &amp;)" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void OpenNN::ConjugateGradient::set_maximum_epochs_number           </td>
          <td>(</td>
          <td class="paramtype">const unsigned int &amp;&nbsp;</td>
          <td class="paramname"> <em>new_maximum_epochs_number</em>          </td>
          <td>&nbsp;)&nbsp;</td>
          <td></td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
This method sets a maximum number of epochs for training. <dl compact><dt><b>Parameters:</b></dt><dd>
  <table border="0" cellspacing="2" cellpadding="0">
    <tr><td valign="top"></td><td valign="top"><em>new_maximum_epochs_number</em>&nbsp;</td><td>Maximum number of epochs for training. </td></tr>
  </table>
</dl>

<p>Definition at line <a class="el" href="conjugate__gradient_8cpp_source.html#l00890">890</a> of file <a class="el" href="conjugate__gradient_8cpp_source.html">conjugate_gradient.cpp</a>.</p>

</div>
</div><p>
<a class="anchor" name="7227ff99b52a9fa1a3a5905c6cc66b76"></a><!-- doxytag: member="OpenNN::ConjugateGradient::set_maximum_time" ref="7227ff99b52a9fa1a3a5905c6cc66b76" args="(const double &amp;)" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void OpenNN::ConjugateGradient::set_maximum_time           </td>
          <td>(</td>
          <td class="paramtype">const double &amp;&nbsp;</td>
          <td class="paramname"> <em>new_maximum_time</em>          </td>
          <td>&nbsp;)&nbsp;</td>
          <td></td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
This method sets a new maximum training time. <dl compact><dt><b>Parameters:</b></dt><dd>
  <table border="0" cellspacing="2" cellpadding="0">
    <tr><td valign="top"></td><td valign="top"><em>new_maximum_time</em>&nbsp;</td><td>Maximum training time. </td></tr>
  </table>
</dl>

<p>Definition at line <a class="el" href="conjugate__gradient_8cpp_source.html#l00920">920</a> of file <a class="el" href="conjugate__gradient_8cpp_source.html">conjugate_gradient.cpp</a>.</p>

</div>
</div><p>
<a class="anchor" name="9de9b218ff51f2393ea38006019f7ffa"></a><!-- doxytag: member="OpenNN::ConjugateGradient::set_reserve_parameters_history" ref="9de9b218ff51f2393ea38006019f7ffa" args="(const bool &amp;)" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void OpenNN::ConjugateGradient::set_reserve_parameters_history           </td>
          <td>(</td>
          <td class="paramtype">const bool &amp;&nbsp;</td>
          <td class="paramname"> <em>new_reserve_parameters_history</em>          </td>
          <td>&nbsp;)&nbsp;</td>
          <td></td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
This method makes the parameters history vector of vectors to be reseved or not in memory. <dl compact><dt><b>Parameters:</b></dt><dd>
  <table border="0" cellspacing="2" cellpadding="0">
    <tr><td valign="top"></td><td valign="top"><em>new_reserve_parameters_history</em>&nbsp;</td><td>True if the parameters history vector of vectors is to be reserved, false otherwise. </td></tr>
  </table>
</dl>

<p>Definition at line <a class="el" href="conjugate__gradient_8cpp_source.html#l00950">950</a> of file <a class="el" href="conjugate__gradient_8cpp_source.html">conjugate_gradient.cpp</a>.</p>

</div>
</div><p>
<a class="anchor" name="274786cd036399313295dff4a097130c"></a><!-- doxytag: member="OpenNN::ConjugateGradient::set_reserve_parameters_norm_history" ref="274786cd036399313295dff4a097130c" args="(const bool &amp;)" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void OpenNN::ConjugateGradient::set_reserve_parameters_norm_history           </td>
          <td>(</td>
          <td class="paramtype">const bool &amp;&nbsp;</td>
          <td class="paramname"> <em>new_reserve_parameters_norm_history</em>          </td>
          <td>&nbsp;)&nbsp;</td>
          <td></td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
This method makes the parameters norm history vector to be reseved or not in memory. <dl compact><dt><b>Parameters:</b></dt><dd>
  <table border="0" cellspacing="2" cellpadding="0">
    <tr><td valign="top"></td><td valign="top"><em>new_reserve_parameters_norm_history</em>&nbsp;</td><td>True if the parameters norm history vector is to be reserved, false otherwise. </td></tr>
  </table>
</dl>

<p>Definition at line <a class="el" href="conjugate__gradient_8cpp_source.html#l00961">961</a> of file <a class="el" href="conjugate__gradient_8cpp_source.html">conjugate_gradient.cpp</a>.</p>

</div>
</div><p>
<a class="anchor" name="eb7604ee6718eeda10dbff12695ca215"></a><!-- doxytag: member="OpenNN::ConjugateGradient::set_reserve_evaluation_history" ref="eb7604ee6718eeda10dbff12695ca215" args="(const bool &amp;)" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void OpenNN::ConjugateGradient::set_reserve_evaluation_history           </td>
          <td>(</td>
          <td class="paramtype">const bool &amp;&nbsp;</td>
          <td class="paramname"> <em>new_reserve_evaluation_history</em>          </td>
          <td>&nbsp;)&nbsp;</td>
          <td></td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
This method makes the evaluation history vector to be reseved or not in memory. <dl compact><dt><b>Parameters:</b></dt><dd>
  <table border="0" cellspacing="2" cellpadding="0">
    <tr><td valign="top"></td><td valign="top"><em>new_reserve_evaluation_history</em>&nbsp;</td><td>True if the evaluation history vector is to be reserved, false otherwise. </td></tr>
  </table>
</dl>

<p>Definition at line <a class="el" href="conjugate__gradient_8cpp_source.html#l00972">972</a> of file <a class="el" href="conjugate__gradient_8cpp_source.html">conjugate_gradient.cpp</a>.</p>

</div>
</div><p>
<a class="anchor" name="97eaf29840f91536f1a55878bc077882"></a><!-- doxytag: member="OpenNN::ConjugateGradient::set_reserve_generalization_evaluation_history" ref="97eaf29840f91536f1a55878bc077882" args="(const bool &amp;)" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void OpenNN::ConjugateGradient::set_reserve_generalization_evaluation_history           </td>
          <td>(</td>
          <td class="paramtype">const bool &amp;&nbsp;</td>
          <td class="paramname"> <em>new_reserve_generalization_evaluation_history</em>          </td>
          <td>&nbsp;)&nbsp;</td>
          <td></td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
This method makes the Generalization evaluation history to be reserved or not in memory. This is a vector. <dl compact><dt><b>Parameters:</b></dt><dd>
  <table border="0" cellspacing="2" cellpadding="0">
    <tr><td valign="top"></td><td valign="top"><em>new_reserve_generalization_evaluation_history</em>&nbsp;</td><td>True if the Generalization evaluation history is to be reserved, false otherwise. </td></tr>
  </table>
</dl>

<p>Definition at line <a class="el" href="conjugate__gradient_8cpp_source.html#l01043">1043</a> of file <a class="el" href="conjugate__gradient_8cpp_source.html">conjugate_gradient.cpp</a>.</p>

</div>
</div><p>
<a class="anchor" name="faef3aac943440a248a9f2e9851eb9c0"></a><!-- doxytag: member="OpenNN::ConjugateGradient::set_reserve_gradient_history" ref="faef3aac943440a248a9f2e9851eb9c0" args="(const bool &amp;)" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void OpenNN::ConjugateGradient::set_reserve_gradient_history           </td>
          <td>(</td>
          <td class="paramtype">const bool &amp;&nbsp;</td>
          <td class="paramname"> <em>new_reserve_gradient_history</em>          </td>
          <td>&nbsp;)&nbsp;</td>
          <td></td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
This method makes the gradient history vector of vectors to be reseved or not in memory. <dl compact><dt><b>Parameters:</b></dt><dd>
  <table border="0" cellspacing="2" cellpadding="0">
    <tr><td valign="top"></td><td valign="top"><em>new_reserve_gradient_history</em>&nbsp;</td><td>True if the gradient history matrix is to be reserved, false otherwise. </td></tr>
  </table>
</dl>

<p>Definition at line <a class="el" href="conjugate__gradient_8cpp_source.html#l00983">983</a> of file <a class="el" href="conjugate__gradient_8cpp_source.html">conjugate_gradient.cpp</a>.</p>

</div>
</div><p>
<a class="anchor" name="0c59f4b561c506844b01718945db2ea8"></a><!-- doxytag: member="OpenNN::ConjugateGradient::set_reserve_gradient_norm_history" ref="0c59f4b561c506844b01718945db2ea8" args="(const bool &amp;)" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void OpenNN::ConjugateGradient::set_reserve_gradient_norm_history           </td>
          <td>(</td>
          <td class="paramtype">const bool &amp;&nbsp;</td>
          <td class="paramname"> <em>new_reserve_gradient_norm_history</em>          </td>
          <td>&nbsp;)&nbsp;</td>
          <td></td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
This method makes the gradient norm history vector to be reseved or not in memory. <dl compact><dt><b>Parameters:</b></dt><dd>
  <table border="0" cellspacing="2" cellpadding="0">
    <tr><td valign="top"></td><td valign="top"><em>new_reserve_gradient_norm_history</em>&nbsp;</td><td>True if the gradient norm history matrix is to be reserved, false otherwise. </td></tr>
  </table>
</dl>

<p>Definition at line <a class="el" href="conjugate__gradient_8cpp_source.html#l00995">995</a> of file <a class="el" href="conjugate__gradient_8cpp_source.html">conjugate_gradient.cpp</a>.</p>

</div>
</div><p>
<a class="anchor" name="379aa30482f6ce0a1ad2071a4e6f6b61"></a><!-- doxytag: member="OpenNN::ConjugateGradient::set_reserve_training_direction_history" ref="379aa30482f6ce0a1ad2071a4e6f6b61" args="(const bool &amp;)" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void OpenNN::ConjugateGradient::set_reserve_training_direction_history           </td>
          <td>(</td>
          <td class="paramtype">const bool &amp;&nbsp;</td>
          <td class="paramname"> <em>new_reserve_training_direction_history</em>          </td>
          <td>&nbsp;)&nbsp;</td>
          <td></td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
This method makes the training direction history vector of vectors to be reseved or not in memory. <dl compact><dt><b>Parameters:</b></dt><dd>
  <table border="0" cellspacing="2" cellpadding="0">
    <tr><td valign="top"></td><td valign="top"><em>new_reserve_training_direction_history</em>&nbsp;</td><td>True if the training direction history matrix is to be reserved, false otherwise. </td></tr>
  </table>
</dl>

<p>Definition at line <a class="el" href="conjugate__gradient_8cpp_source.html#l01007">1007</a> of file <a class="el" href="conjugate__gradient_8cpp_source.html">conjugate_gradient.cpp</a>.</p>

</div>
</div><p>
<a class="anchor" name="e46832a168326e64d3e19ef769335771"></a><!-- doxytag: member="OpenNN::ConjugateGradient::set_reserve_training_rate_history" ref="e46832a168326e64d3e19ef769335771" args="(const bool &amp;)" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void OpenNN::ConjugateGradient::set_reserve_training_rate_history           </td>
          <td>(</td>
          <td class="paramtype">const bool &amp;&nbsp;</td>
          <td class="paramname"> <em>new_reserve_training_rate_history</em>          </td>
          <td>&nbsp;)&nbsp;</td>
          <td></td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
This method makes the training rate history vector to be reseved or not in memory. <dl compact><dt><b>Parameters:</b></dt><dd>
  <table border="0" cellspacing="2" cellpadding="0">
    <tr><td valign="top"></td><td valign="top"><em>new_reserve_training_rate_history</em>&nbsp;</td><td>True if the training rate history vector is to be reserved, false otherwise. </td></tr>
  </table>
</dl>

<p>Definition at line <a class="el" href="conjugate__gradient_8cpp_source.html#l01019">1019</a> of file <a class="el" href="conjugate__gradient_8cpp_source.html">conjugate_gradient.cpp</a>.</p>

</div>
</div><p>
<a class="anchor" name="98b68a0401e023dc61692d4b7377a4ac"></a><!-- doxytag: member="OpenNN::ConjugateGradient::set_reserve_elapsed_time_history" ref="98b68a0401e023dc61692d4b7377a4ac" args="(const bool &amp;)" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void OpenNN::ConjugateGradient::set_reserve_elapsed_time_history           </td>
          <td>(</td>
          <td class="paramtype">const bool &amp;&nbsp;</td>
          <td class="paramname"> <em>new_reserve_elapsed_time_history</em>          </td>
          <td>&nbsp;)&nbsp;</td>
          <td></td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
This method makes the elapsed time over the epochs to be reseved or not in memory. This is a vector. <dl compact><dt><b>Parameters:</b></dt><dd>
  <table border="0" cellspacing="2" cellpadding="0">
    <tr><td valign="top"></td><td valign="top"><em>new_reserve_elapsed_time_history</em>&nbsp;</td><td>True if the elapsed time history vector is to be reserved, false otherwise. </td></tr>
  </table>
</dl>

<p>Definition at line <a class="el" href="conjugate__gradient_8cpp_source.html#l01031">1031</a> of file <a class="el" href="conjugate__gradient_8cpp_source.html">conjugate_gradient.cpp</a>.</p>

</div>
</div><p>
<a class="anchor" name="5b21e8e16b09531d93384dd9339c02f5"></a><!-- doxytag: member="OpenNN::ConjugateGradient::set_reserve_all_training_history" ref="5b21e8e16b09531d93384dd9339c02f5" args="(const bool &amp;)" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void OpenNN::ConjugateGradient::set_reserve_all_training_history           </td>
          <td>(</td>
          <td class="paramtype">const bool &amp;&nbsp;</td>
          <td class="paramname"> <em>new_reserve_all_training_history</em>          </td>
          <td>&nbsp;)&nbsp;</td>
          <td></td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
This method makes the training history of all variables to reseved or not in memory when training. <ul>
<li>
Parameters. </li>
<li>
Parameters norm. </li>
<li>
Evaluation. </li>
<li>
Gradient. </li>
<li>
Gradient norm. </li>
<li>
Generalization performance. </li>
<li>
Training direction. </li>
<li>
Training direction norm. </li>
<li>
Training rate. </li>
</ul>
<p>
<dl compact><dt><b>Parameters:</b></dt><dd>
  <table border="0" cellspacing="2" cellpadding="0">
    <tr><td valign="top"></td><td valign="top"><em>new_reserve_all_training_history</em>&nbsp;</td><td>True if all training history variables are to be reserved, false otherwise. </td></tr>
  </table>
</dl>

<p>Definition at line <a class="el" href="conjugate__gradient_8cpp_source.html#l00460">460</a> of file <a class="el" href="conjugate__gradient_8cpp_source.html">conjugate_gradient.cpp</a>.</p>

</div>
</div><p>
<a class="anchor" name="a38aa187051cc3605a507a35d36b63be"></a><!-- doxytag: member="OpenNN::ConjugateGradient::set_display_period" ref="a38aa187051cc3605a507a35d36b63be" args="(const unsigned int &amp;)" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void OpenNN::ConjugateGradient::set_display_period           </td>
          <td>(</td>
          <td class="paramtype">const unsigned int &amp;&nbsp;</td>
          <td class="paramname"> <em>new_display_period</em>          </td>
          <td>&nbsp;)&nbsp;</td>
          <td></td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
This method sets a new number of epochs between the training showing progress. <dl compact><dt><b>Parameters:</b></dt><dd>
  <table border="0" cellspacing="2" cellpadding="0">
    <tr><td valign="top"></td><td valign="top"><em>new_display_period</em>&nbsp;</td><td>Number of epochs between the training showing progress. </td></tr>
  </table>
</dl>

<p>Definition at line <a class="el" href="conjugate__gradient_8cpp_source.html#l01055">1055</a> of file <a class="el" href="conjugate__gradient_8cpp_source.html">conjugate_gradient.cpp</a>.</p>

</div>
</div><p>
<a class="anchor" name="f73bcb65142c7608cca02496f6bc484b"></a><!-- doxytag: member="OpenNN::ConjugateGradient::calculate_PR_parameter" ref="f73bcb65142c7608cca02496f6bc484b" args="(const Vector&lt; double &gt; &amp;, const Vector&lt; double &gt; &amp;) const " -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">double OpenNN::ConjugateGradient::calculate_PR_parameter           </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="class_open_n_n_1_1_vector.html">Vector</a>&lt; double &gt; &amp;&nbsp;</td>
          <td class="paramname"> <em>old_gradient</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="class_open_n_n_1_1_vector.html">Vector</a>&lt; double &gt; &amp;&nbsp;</td>
          <td class="paramname"> <em>gradient</em></td><td>&nbsp;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td><td> const</td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
This method returns the Polak-Ribiere parameter used to calculate the training direction. <dl compact><dt><b>Parameters:</b></dt><dd>
  <table border="0" cellspacing="2" cellpadding="0">
    <tr><td valign="top"></td><td valign="top"><em>old_gradient</em>&nbsp;</td><td>Previous objective function gradient. </td></tr>
    <tr><td valign="top"></td><td valign="top"><em>gradient</em>&nbsp;</td><td>Current objective function gradient. </td></tr>
  </table>
</dl>

<p>Definition at line <a class="el" href="conjugate__gradient_8cpp_source.html#l01122">1122</a> of file <a class="el" href="conjugate__gradient_8cpp_source.html">conjugate_gradient.cpp</a>.</p>

</div>
</div><p>
<a class="anchor" name="eef9bc0433ecff10db98d87945b553ae"></a><!-- doxytag: member="OpenNN::ConjugateGradient::calculate_FR_parameter" ref="eef9bc0433ecff10db98d87945b553ae" args="(const Vector&lt; double &gt; &amp;, const Vector&lt; double &gt; &amp;) const " -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">double OpenNN::ConjugateGradient::calculate_FR_parameter           </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="class_open_n_n_1_1_vector.html">Vector</a>&lt; double &gt; &amp;&nbsp;</td>
          <td class="paramname"> <em>old_gradient</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="class_open_n_n_1_1_vector.html">Vector</a>&lt; double &gt; &amp;&nbsp;</td>
          <td class="paramname"> <em>gradient</em></td><td>&nbsp;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td><td> const</td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
This method returns the Fletcher-Reeves parameter used to calculate the training direction.<p>
<dl compact><dt><b>Parameters:</b></dt><dd>
  <table border="0" cellspacing="2" cellpadding="0">
    <tr><td valign="top"></td><td valign="top"><em>old_gradient</em>&nbsp;</td><td>Previous objective function gradient. </td></tr>
    <tr><td valign="top"></td><td valign="top"><em>gradient,:</em>&nbsp;</td><td>Current objective function gradient. </td></tr>
  </table>
</dl>

<p>Definition at line <a class="el" href="conjugate__gradient_8cpp_source.html#l01086">1086</a> of file <a class="el" href="conjugate__gradient_8cpp_source.html">conjugate_gradient.cpp</a>.</p>

</div>
</div><p>
<a class="anchor" name="349d877b87f39e34f2041ca12578493f"></a><!-- doxytag: member="OpenNN::ConjugateGradient::calculate_PR_training_direction" ref="349d877b87f39e34f2041ca12578493f" args="(const Vector&lt; double &gt; &amp;, const Vector&lt; double &gt; &amp;, const Vector&lt; double &gt; &amp;) const " -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="class_open_n_n_1_1_vector.html">Vector</a>&lt; double &gt; OpenNN::ConjugateGradient::calculate_PR_training_direction           </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="class_open_n_n_1_1_vector.html">Vector</a>&lt; double &gt; &amp;&nbsp;</td>
          <td class="paramname"> <em>old_gradient</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="class_open_n_n_1_1_vector.html">Vector</a>&lt; double &gt; &amp;&nbsp;</td>
          <td class="paramname"> <em>gradient</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="class_open_n_n_1_1_vector.html">Vector</a>&lt; double &gt; &amp;&nbsp;</td>
          <td class="paramname"> <em>old_training_direction</em></td><td>&nbsp;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td><td> const</td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
This method returns the training direction using the Polak-Ribiere update. <dl compact><dt><b>Parameters:</b></dt><dd>
  <table border="0" cellspacing="2" cellpadding="0">
    <tr><td valign="top"></td><td valign="top"><em>old_gradient</em>&nbsp;</td><td>Previous objective function gradient. </td></tr>
    <tr><td valign="top"></td><td valign="top"><em>gradient</em>&nbsp;</td><td>Current objective function gradient. </td></tr>
    <tr><td valign="top"></td><td valign="top"><em>old_training_direction</em>&nbsp;</td><td>Previous training direction vector. </td></tr>
  </table>
</dl>

<p>Definition at line <a class="el" href="conjugate__gradient_8cpp_source.html#l01160">1160</a> of file <a class="el" href="conjugate__gradient_8cpp_source.html">conjugate_gradient.cpp</a>.</p>

</div>
</div><p>
<a class="anchor" name="eb3e308b272d1bffa46c96cbb1160be7"></a><!-- doxytag: member="OpenNN::ConjugateGradient::calculate_FR_training_direction" ref="eb3e308b272d1bffa46c96cbb1160be7" args="(const Vector&lt; double &gt; &amp;, const Vector&lt; double &gt; &amp;, const Vector&lt; double &gt; &amp;) const " -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="class_open_n_n_1_1_vector.html">Vector</a>&lt; double &gt; OpenNN::ConjugateGradient::calculate_FR_training_direction           </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="class_open_n_n_1_1_vector.html">Vector</a>&lt; double &gt; &amp;&nbsp;</td>
          <td class="paramname"> <em>old_gradient</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="class_open_n_n_1_1_vector.html">Vector</a>&lt; double &gt; &amp;&nbsp;</td>
          <td class="paramname"> <em>gradient</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="class_open_n_n_1_1_vector.html">Vector</a>&lt; double &gt; &amp;&nbsp;</td>
          <td class="paramname"> <em>old_training_direction</em></td><td>&nbsp;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td><td> const</td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
This method returns the training direction using the Fletcher-Reeves update. <dl compact><dt><b>Parameters:</b></dt><dd>
  <table border="0" cellspacing="2" cellpadding="0">
    <tr><td valign="top"></td><td valign="top"><em>old_gradient</em>&nbsp;</td><td>Previous objective function gradient. </td></tr>
    <tr><td valign="top"></td><td valign="top"><em>gradient</em>&nbsp;</td><td>Current objective function gradient. </td></tr>
    <tr><td valign="top"></td><td valign="top"><em>old_training_direction</em>&nbsp;</td><td>Previous training direction vector. </td></tr>
  </table>
</dl>

<p>Definition at line <a class="el" href="conjugate__gradient_8cpp_source.html#l01183">1183</a> of file <a class="el" href="conjugate__gradient_8cpp_source.html">conjugate_gradient.cpp</a>.</p>

</div>
</div><p>
<a class="anchor" name="24e0e461557d5f855c97dbeedf43d0cb"></a><!-- doxytag: member="OpenNN::ConjugateGradient::calculate_training_direction" ref="24e0e461557d5f855c97dbeedf43d0cb" args="(const Vector&lt; double &gt; &amp;, const Vector&lt; double &gt; &amp;, const Vector&lt; double &gt; &amp;) const " -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="class_open_n_n_1_1_vector.html">Vector</a>&lt; double &gt; OpenNN::ConjugateGradient::calculate_training_direction           </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="class_open_n_n_1_1_vector.html">Vector</a>&lt; double &gt; &amp;&nbsp;</td>
          <td class="paramname"> <em>old_gradient</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="class_open_n_n_1_1_vector.html">Vector</a>&lt; double &gt; &amp;&nbsp;</td>
          <td class="paramname"> <em>gradient</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="class_open_n_n_1_1_vector.html">Vector</a>&lt; double &gt; &amp;&nbsp;</td>
          <td class="paramname"> <em>old_training_direction</em></td><td>&nbsp;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td><td> const</td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
This method returns the conjugate gradient training direction, which has been previously normalized. <dl compact><dt><b>Parameters:</b></dt><dd>
  <table border="0" cellspacing="2" cellpadding="0">
    <tr><td valign="top"></td><td valign="top"><em>old_gradient</em>&nbsp;</td><td>Gradient vector in the previous epoch. </td></tr>
    <tr><td valign="top"></td><td valign="top"><em>gradient</em>&nbsp;</td><td>Current gradient vector. </td></tr>
    <tr><td valign="top"></td><td valign="top"><em>old_training_direction</em>&nbsp;</td><td>Training direction in the previous epoch. </td></tr>
  </table>
</dl>

<p>Definition at line <a class="el" href="conjugate__gradient_8cpp_source.html#l01206">1206</a> of file <a class="el" href="conjugate__gradient_8cpp_source.html">conjugate_gradient.cpp</a>.</p>

</div>
</div><p>
<a class="anchor" name="42e7f404e32cceabb10a25d2b66f6ca4"></a><!-- doxytag: member="OpenNN::ConjugateGradient::calculate_gradient_descent_training_direction" ref="42e7f404e32cceabb10a25d2b66f6ca4" args="(const Vector&lt; double &gt; &amp;) const " -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="class_open_n_n_1_1_vector.html">Vector</a>&lt; double &gt; OpenNN::ConjugateGradient::calculate_gradient_descent_training_direction           </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="class_open_n_n_1_1_vector.html">Vector</a>&lt; double &gt; &amp;&nbsp;</td>
          <td class="paramname"> <em>gradient</em>          </td>
          <td>&nbsp;)&nbsp;</td>
          <td> const</td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
This method returns the gradient descent training direction, which is the negative of the normalized gradient. <dl compact><dt><b>Parameters:</b></dt><dd>
  <table border="0" cellspacing="2" cellpadding="0">
    <tr><td valign="top"></td><td valign="top"><em>gradient</em>&nbsp;</td><td>Gradient vector. </td></tr>
  </table>
</dl>

<p>Definition at line <a class="el" href="conjugate__gradient_8cpp_source.html#l01242">1242</a> of file <a class="el" href="conjugate__gradient_8cpp_source.html">conjugate_gradient.cpp</a>.</p>

</div>
</div><p>
<a class="anchor" name="21c8810233ae2c5da6f6e5b923759d4f"></a><!-- doxytag: member="OpenNN::ConjugateGradient::perform_training" ref="21c8810233ae2c5da6f6e5b923759d4f" args="(void)" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="struct_open_n_n_1_1_conjugate_gradient_1_1_conjugate_gradient_results.html">ConjugateGradient::ConjugateGradientResults</a> * OpenNN::ConjugateGradient::perform_training           </td>
          <td>(</td>
          <td class="paramtype">void&nbsp;</td>
          <td class="paramname">          </td>
          <td>&nbsp;)&nbsp;</td>
          <td><code> [virtual]</code></td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
This method trains a neural network with an associated performance functional according to the conjugate gradient algorithm. Training occurs according to the training operators, training parameters and stopping criteria. 
<p>Implements <a class="el" href="class_open_n_n_1_1_training_algorithm.html#3ed4426c63e74939ae52730e3505cfdf">OpenNN::TrainingAlgorithm</a>.</p>

<p>Definition at line <a class="el" href="conjugate__gradient_8cpp_source.html#l01367">1367</a> of file <a class="el" href="conjugate__gradient_8cpp_source.html">conjugate_gradient.cpp</a>.</p>

</div>
</div><p>
<a class="anchor" name="da7b8d4a49f4e401f94a08a287d5359e"></a><!-- doxytag: member="OpenNN::ConjugateGradient::write_training_algorithm_type" ref="da7b8d4a49f4e401f94a08a287d5359e" args="(void) const " -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">std::string OpenNN::ConjugateGradient::write_training_algorithm_type           </td>
          <td>(</td>
          <td class="paramtype">void&nbsp;</td>
          <td class="paramname">          </td>
          <td>&nbsp;)&nbsp;</td>
          <td> const<code> [virtual]</code></td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
This method writes a string with the type of training algoritm. 
<p>

<p>Reimplemented from <a class="el" href="class_open_n_n_1_1_training_algorithm.html#a24b5c6f5571d780d1b61c684fd0eb2d">OpenNN::TrainingAlgorithm</a>.</p>

<p>Definition at line <a class="el" href="conjugate__gradient_8cpp_source.html#l01773">1773</a> of file <a class="el" href="conjugate__gradient_8cpp_source.html">conjugate_gradient.cpp</a>.</p>

</div>
</div><p>
<a class="anchor" name="6c49f6f5185b73909d10decaed887b2a"></a><!-- doxytag: member="OpenNN::ConjugateGradient::to_XML" ref="6c49f6f5185b73909d10decaed887b2a" args="(void) const " -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">TiXmlElement * OpenNN::ConjugateGradient::to_XML           </td>
          <td>(</td>
          <td class="paramtype">void&nbsp;</td>
          <td class="paramname">          </td>
          <td>&nbsp;)&nbsp;</td>
          <td> const<code> [virtual]</code></td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
This method serializes the conjugate gradient object into a XML element of the TinyXML library. See the OpenNN manual for more information about the format of this element. 
<p>Reimplemented from <a class="el" href="class_open_n_n_1_1_training_algorithm.html#ed80f94b3ad79dbe95c49097c9302be8">OpenNN::TrainingAlgorithm</a>.</p>

<p>Definition at line <a class="el" href="conjugate__gradient_8cpp_source.html#l01784">1784</a> of file <a class="el" href="conjugate__gradient_8cpp_source.html">conjugate_gradient.cpp</a>.</p>

</div>
</div><p>
<a class="anchor" name="0a4d9795e258a93cf261b996eb785018"></a><!-- doxytag: member="OpenNN::ConjugateGradient::from_XML" ref="0a4d9795e258a93cf261b996eb785018" args="(TiXmlElement *)" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void OpenNN::ConjugateGradient::from_XML           </td>
          <td>(</td>
          <td class="paramtype">TiXmlElement *&nbsp;</td>
          <td class="paramname"> <em>conjugate_gradient_element</em>          </td>
          <td>&nbsp;)&nbsp;</td>
          <td><code> [virtual]</code></td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
This method deserializes the conjugate gradient object from a XML element of the TinyXML library. See the OpenNN manual for more information about the format of this element. <dl compact><dt><b>Parameters:</b></dt><dd>
  <table border="0" cellspacing="2" cellpadding="0">
    <tr><td valign="top"></td><td valign="top"><em>conjugate_gradient_element</em>&nbsp;</td><td>Pointer to a TinyXML element containing the member data. </td></tr>
  </table>
</dl>

<p>Reimplemented from <a class="el" href="class_open_n_n_1_1_training_algorithm.html#29d7f1ea8665e574f31aee359a58f505">OpenNN::TrainingAlgorithm</a>.</p>

<p>Definition at line <a class="el" href="conjugate__gradient_8cpp_source.html#l02106">2106</a> of file <a class="el" href="conjugate__gradient_8cpp_source.html">conjugate_gradient.cpp</a>.</p>

</div>
</div><p>
<hr>The documentation for this class was generated from the following files:<ul>
<li><a class="el" href="conjugate__gradient_8h_source.html">conjugate_gradient.h</a><li><a class="el" href="conjugate__gradient_8cpp_source.html">conjugate_gradient.cpp</a></ul>
</div>
<hr size="1"><address style="text-align: right;"><small>Generated on Sun Aug 26 11:58:20 2012 for OpenNN by&nbsp;
<a href="http://www.doxygen.org/index.html">
<img src="doxygen.png" alt="doxygen" align="middle" border="0"></a> 1.5.9 </small></address>
</body>
</html>
