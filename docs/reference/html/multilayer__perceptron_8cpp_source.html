<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html><head><meta http-equiv="Content-Type" content="text/html;charset=UTF-8">
<title>OpenNN: multilayer_perceptron.cpp Source File</title>
<link href="tabs.css" rel="stylesheet" type="text/css">
<link href="doxygen.css" rel="stylesheet" type="text/css">
</head><body>
<!-- Generated by Doxygen 1.5.9 -->
<div class="navigation" id="top">
  <div class="tabs">
    <ul>
      <li><a href="index.html"><span>Main&nbsp;Page</span></a></li>
      <li><a href="pages.html"><span>Related&nbsp;Pages</span></a></li>
      <li><a href="annotated.html"><span>Classes</span></a></li>
      <li class="current"><a href="files.html"><span>Files</span></a></li>
    </ul>
  </div>
  <div class="tabs">
    <ul>
      <li><a href="files.html"><span>File&nbsp;List</span></a></li>
    </ul>
  </div>
<h1>multilayer_perceptron.cpp</h1><div class="fragment"><pre class="fragment"><a name="l00001"></a>00001 <span class="comment">/****************************************************************************************************************/</span>
<a name="l00002"></a>00002 <span class="comment">/*                                                                                                              */</span>
<a name="l00003"></a>00003 <span class="comment">/*   OpenNN: Open Neural MultilayerPerceptrons Library                                                          */</span>
<a name="l00004"></a>00004 <span class="comment">/*   www.opennn.cimne.com                                                                                       */</span>
<a name="l00005"></a>00005 <span class="comment">/*                                                                                                              */</span>
<a name="l00006"></a>00006 <span class="comment">/*   M U L T I L A Y E R   P E R C E P T R O N   C L A S S                                                      */</span>
<a name="l00007"></a>00007 <span class="comment">/*                                                                                                              */</span>
<a name="l00008"></a>00008 <span class="comment">/*   Roberto Lopez                                                                                              */</span>
<a name="l00009"></a>00009 <span class="comment">/*   International Center for Numerical Methods in Engineering (CIMNE)                                          */</span>
<a name="l00010"></a>00010 <span class="comment">/*   Technical University of Catalonia (UPC)                                                                    */</span>
<a name="l00011"></a>00011 <span class="comment">/*   Barcelona, Spain                                                                                           */</span>
<a name="l00012"></a>00012 <span class="comment">/*   E-mail: rlopez@cimne.upc.edu                                                                               */</span>
<a name="l00013"></a>00013 <span class="comment">/*                                                                                                              */</span>
<a name="l00014"></a>00014 <span class="comment">/****************************************************************************************************************/</span>
<a name="l00015"></a>00015 
<a name="l00016"></a>00016 <span class="comment">// System includes</span>
<a name="l00017"></a>00017 
<a name="l00018"></a>00018 <span class="preprocessor">#include &lt;cmath&gt;</span>   
<a name="l00019"></a>00019 <span class="preprocessor">#include &lt;cstdlib&gt;</span>
<a name="l00020"></a>00020 <span class="preprocessor">#include &lt;fstream&gt;</span>
<a name="l00021"></a>00021 <span class="preprocessor">#include &lt;iostream&gt;</span>
<a name="l00022"></a>00022 <span class="preprocessor">#include &lt;string&gt;</span>
<a name="l00023"></a>00023 <span class="preprocessor">#include &lt;sstream&gt;</span>
<a name="l00024"></a>00024 
<a name="l00025"></a>00025 <span class="comment">// OpenNN includes</span>
<a name="l00026"></a>00026 
<a name="l00027"></a>00027 <span class="preprocessor">#include "multilayer_perceptron.h"</span>
<a name="l00028"></a>00028 
<a name="l00029"></a>00029 
<a name="l00030"></a>00030 <span class="keyword">namespace </span>OpenNN
<a name="l00031"></a>00031 {
<a name="l00032"></a>00032 
<a name="l00033"></a>00033 <span class="comment">// DEFAULT CONSTRUCTOR</span>
<a name="l00034"></a>00034 
<a name="l00038"></a>00038 
<a name="l00039"></a><a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#49c7a04dcbd36afbb8424061af6abf09">00039</a> <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#49c7a04dcbd36afbb8424061af6abf09">MultilayerPerceptron::MultilayerPerceptron</a>(<span class="keywordtype">void</span>)
<a name="l00040"></a>00040 {
<a name="l00041"></a>00041    <span class="keyword">set</span>();
<a name="l00042"></a>00042 }
<a name="l00043"></a>00043 
<a name="l00044"></a>00044 
<a name="l00045"></a>00045 <span class="comment">// LAYERS CONSTRUCTOR</span>
<a name="l00046"></a>00046 
<a name="l00050"></a>00050 
<a name="l00051"></a><a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#28b06845aa9083222d2bfcfab4d698c1">00051</a> <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#49c7a04dcbd36afbb8424061af6abf09">MultilayerPerceptron::MultilayerPerceptron</a>(<span class="keyword">const</span> <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt;PerceptronLayer&gt;</a>&amp; new_layers)
<a name="l00052"></a>00052 {
<a name="l00053"></a>00053    <span class="keyword">set</span>(new_layers);
<a name="l00054"></a>00054 }
<a name="l00055"></a>00055 
<a name="l00056"></a>00056 
<a name="l00057"></a>00057 <span class="comment">// NETWORK ARCHITECTURE CONSTRUCTOR</span>
<a name="l00058"></a>00058 
<a name="l00066"></a>00066 
<a name="l00067"></a><a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#0119d672b942a5a0bdfa796fd3b8d2ae">00067</a> <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#49c7a04dcbd36afbb8424061af6abf09">MultilayerPerceptron::MultilayerPerceptron</a>(<span class="keyword">const</span> <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt;unsigned int&gt;</a>&amp; new_architecture)
<a name="l00068"></a>00068 {
<a name="l00069"></a>00069    <span class="keyword">set</span>(new_architecture);
<a name="l00070"></a>00070 }
<a name="l00071"></a>00071 
<a name="l00072"></a>00072 
<a name="l00073"></a>00073 <span class="comment">// ONE LAYER CONSTRUCTOR</span>
<a name="l00074"></a>00074 
<a name="l00084"></a>00084 
<a name="l00085"></a><a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#d40063a69b6f67a18e23559f6e2ae3c6">00085</a> <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#49c7a04dcbd36afbb8424061af6abf09">MultilayerPerceptron::MultilayerPerceptron</a>(<span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span>&amp; new_inputs_number, <span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span>&amp; new_neurons_number)
<a name="l00086"></a>00086 {
<a name="l00087"></a>00087    <span class="keyword">set</span>(new_inputs_number, new_neurons_number);
<a name="l00088"></a>00088 }
<a name="l00089"></a>00089 
<a name="l00090"></a>00090 
<a name="l00091"></a>00091 <span class="comment">// TWO LAYERS CONSTRUCTOR</span>
<a name="l00092"></a>00092 
<a name="l00101"></a>00101 
<a name="l00102"></a><a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#898b28c6bdb5c76b97ab37c73050eb7e">00102</a> <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#49c7a04dcbd36afbb8424061af6abf09">MultilayerPerceptron::MultilayerPerceptron</a>(<span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span>&amp; new_inputs_number, <span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span>&amp; new_hidden_neurons_number, <span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span>&amp; new_outputs_number)
<a name="l00103"></a>00103 {
<a name="l00104"></a>00104    <span class="keyword">set</span>(new_inputs_number, new_hidden_neurons_number, new_outputs_number);
<a name="l00105"></a>00105 
<a name="l00106"></a>00106    <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#563c8d829b36217cf392f3c94c7eaa4a">set_default</a>();
<a name="l00107"></a>00107 }
<a name="l00108"></a>00108 
<a name="l00109"></a>00109 
<a name="l00110"></a>00110 <span class="comment">// COPY CONSTRUCTOR</span>
<a name="l00111"></a>00111 
<a name="l00115"></a>00115 
<a name="l00116"></a><a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#a0b0c932c8bd74694876b671c21b21f1">00116</a> <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#49c7a04dcbd36afbb8424061af6abf09">MultilayerPerceptron::MultilayerPerceptron</a>(<span class="keyword">const</span> <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html">MultilayerPerceptron</a>&amp; other_multilayer_perceptron)
<a name="l00117"></a>00117 {
<a name="l00118"></a>00118    <span class="keyword">set</span>(other_multilayer_perceptron);
<a name="l00119"></a>00119 }
<a name="l00120"></a>00120 
<a name="l00121"></a>00121 
<a name="l00122"></a>00122 <span class="comment">// DESTRUCTOR</span>
<a name="l00123"></a>00123 
<a name="l00126"></a>00126 
<a name="l00127"></a><a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#9444d2b6d1c4315ddb5255bb43942505">00127</a> <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#9444d2b6d1c4315ddb5255bb43942505">MultilayerPerceptron::~MultilayerPerceptron</a>(<span class="keywordtype">void</span>)
<a name="l00128"></a>00128 {
<a name="l00129"></a>00129 }
<a name="l00130"></a>00130 
<a name="l00131"></a>00131 
<a name="l00132"></a>00132 <span class="comment">// ASSIGNMENT OPERATOR</span>
<a name="l00133"></a>00133 
<a name="l00137"></a>00137 
<a name="l00138"></a><a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#c28a4ca2acd774f5b5ca80fec8f9a3ab">00138</a> <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html">MultilayerPerceptron</a>&amp; <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#c28a4ca2acd774f5b5ca80fec8f9a3ab">MultilayerPerceptron::operator = </a>(<span class="keyword">const</span> <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html">MultilayerPerceptron</a>&amp; other_multilayer_perceptron)
<a name="l00139"></a>00139 {
<a name="l00140"></a>00140    <span class="keywordflow">if</span>(<span class="keyword">this</span> != &amp;other_multilayer_perceptron) 
<a name="l00141"></a>00141    {
<a name="l00142"></a>00142       <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#ea970635dd856cb0f9acdf458177312b">layers</a> = other_multilayer_perceptron.<a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#ea970635dd856cb0f9acdf458177312b">layers</a>;
<a name="l00143"></a>00143    
<a name="l00144"></a>00144       <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#24c63c4f903e9cbde9beabca81a6682f" title="Display messages to screen.">display</a> = other_multilayer_perceptron.<a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#24c63c4f903e9cbde9beabca81a6682f" title="Display messages to screen.">display</a>;
<a name="l00145"></a>00145    }
<a name="l00146"></a>00146 
<a name="l00147"></a>00147    <span class="keywordflow">return</span>(*<span class="keyword">this</span>);
<a name="l00148"></a>00148 }
<a name="l00149"></a>00149 
<a name="l00150"></a>00150 
<a name="l00151"></a>00151 <span class="comment">// EQUAL TO OPERATOR</span>
<a name="l00152"></a>00152 
<a name="l00153"></a>00153 <span class="comment">// bool operator == (const MultilayerPerceptron&amp;) const method</span>
<a name="l00154"></a>00154 
<a name="l00159"></a>00159 
<a name="l00160"></a><a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#e3418bf3f90ca7880bc99907e8db5cb2">00160</a> <span class="keywordtype">bool</span> <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#e3418bf3f90ca7880bc99907e8db5cb2">MultilayerPerceptron::operator == </a>(<span class="keyword">const</span> <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html">MultilayerPerceptron</a>&amp; other_multilayer_perceptron)<span class="keyword"> const</span>
<a name="l00161"></a>00161 <span class="keyword"></span>{
<a name="l00162"></a>00162    <span class="keywordflow">if</span>(<a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#ea970635dd856cb0f9acdf458177312b">layers</a> == other_multilayer_perceptron.<a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#ea970635dd856cb0f9acdf458177312b">layers</a>   
<a name="l00163"></a>00163    &amp;&amp; <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#24c63c4f903e9cbde9beabca81a6682f" title="Display messages to screen.">display</a> == other_multilayer_perceptron.<a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#24c63c4f903e9cbde9beabca81a6682f" title="Display messages to screen.">display</a>)
<a name="l00164"></a>00164    {
<a name="l00165"></a>00165       <span class="keywordflow">return</span>(<span class="keyword">true</span>);   
<a name="l00166"></a>00166    }
<a name="l00167"></a>00167    <span class="keywordflow">else</span>
<a name="l00168"></a>00168    {
<a name="l00169"></a>00169       <span class="keywordflow">return</span>(<span class="keyword">false</span>);
<a name="l00170"></a>00170    }
<a name="l00171"></a>00171 }
<a name="l00172"></a>00172 
<a name="l00173"></a>00173 
<a name="l00174"></a>00174 <span class="comment">// METHODS</span>
<a name="l00175"></a>00175 
<a name="l00176"></a>00176 <span class="comment">// const Vector&lt;PerceptronLayer&gt;&amp; get_layers(void) const method</span>
<a name="l00177"></a>00177 
<a name="l00181"></a>00181 
<a name="l00182"></a><a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#13107516ad0edcd9e5fc690606fe810b">00182</a> <span class="keyword">const</span> <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt;PerceptronLayer&gt;</a>&amp; <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#13107516ad0edcd9e5fc690606fe810b">MultilayerPerceptron::get_layers</a>(<span class="keywordtype">void</span>)<span class="keyword"> const </span>
<a name="l00183"></a>00183 <span class="keyword"></span>{
<a name="l00184"></a>00184    <span class="keywordflow">return</span>(<a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#ea970635dd856cb0f9acdf458177312b">layers</a>);
<a name="l00185"></a>00185 }
<a name="l00186"></a>00186 
<a name="l00187"></a>00187 
<a name="l00188"></a>00188 <span class="comment">// const PerceptronLayer&amp; get_layer(const unsigned int&amp;) const method</span>
<a name="l00189"></a>00189 
<a name="l00192"></a>00192 
<a name="l00193"></a><a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#cf2e2b6a8beaba24200a19ca23bc6d0d">00193</a> <span class="keyword">const</span> <a class="code" href="class_open_n_n_1_1_perceptron_layer.html">PerceptronLayer</a>&amp; <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#cf2e2b6a8beaba24200a19ca23bc6d0d">MultilayerPerceptron::get_layer</a>(<span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span>&amp; i)<span class="keyword"> const </span>
<a name="l00194"></a>00194 <span class="keyword"></span>{
<a name="l00195"></a>00195    <span class="comment">// Control sentence (if debug)</span>
<a name="l00196"></a>00196 
<a name="l00197"></a>00197 <span class="preprocessor">   #ifdef _DEBUG </span>
<a name="l00198"></a>00198 <span class="preprocessor"></span>
<a name="l00199"></a>00199    <span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> layers_number = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#e5f41a6d170161f9b2896e95bb186423" title="This method returns the number of layers in the multilayer perceptron.">count_layers_number</a>();
<a name="l00200"></a>00200 
<a name="l00201"></a>00201    <span class="keywordflow">if</span>(i &gt;= layers_number)
<a name="l00202"></a>00202    {
<a name="l00203"></a>00203       std::ostringstream buffer;
<a name="l00204"></a>00204 
<a name="l00205"></a>00205       buffer &lt;&lt; <span class="stringliteral">"OpenNN Exception: MultilayerPerceptron class.\n"</span>
<a name="l00206"></a>00206              &lt;&lt; <span class="stringliteral">"const PerceptronLayer get_layer(const unsigned int&amp;) const method.\n"</span>
<a name="l00207"></a>00207              &lt;&lt; <span class="stringliteral">"Index of layer must be less than number of layers.\n"</span>;
<a name="l00208"></a>00208 
<a name="l00209"></a>00209           <span class="keywordflow">throw</span> std::logic_error(buffer.str());
<a name="l00210"></a>00210    }
<a name="l00211"></a>00211 
<a name="l00212"></a>00212 <span class="preprocessor">   #endif</span>
<a name="l00213"></a>00213 <span class="preprocessor"></span> 
<a name="l00214"></a>00214    <span class="keywordflow">return</span>(<a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#ea970635dd856cb0f9acdf458177312b">layers</a>[i]);
<a name="l00215"></a>00215 }
<a name="l00216"></a>00216 
<a name="l00217"></a>00217 
<a name="l00218"></a>00218 <span class="comment">// PerceptronLayer* get_layer_pointer(const unsigned int&amp;) const method</span>
<a name="l00219"></a>00219 
<a name="l00222"></a>00222 
<a name="l00223"></a><a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#eab103cc8d4997cf0dd55f4656a56d53">00223</a> <a class="code" href="class_open_n_n_1_1_perceptron_layer.html">PerceptronLayer</a>* <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#eab103cc8d4997cf0dd55f4656a56d53">MultilayerPerceptron::get_layer_pointer</a>(<span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span>&amp; i) 
<a name="l00224"></a>00224 {
<a name="l00225"></a>00225    <span class="comment">// Control sentence (if debug)</span>
<a name="l00226"></a>00226 
<a name="l00227"></a>00227 <span class="preprocessor">   #ifdef _DEBUG </span>
<a name="l00228"></a>00228 <span class="preprocessor"></span>
<a name="l00229"></a>00229    <span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> layers_number = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#e5f41a6d170161f9b2896e95bb186423" title="This method returns the number of layers in the multilayer perceptron.">count_layers_number</a>();
<a name="l00230"></a>00230 
<a name="l00231"></a>00231    <span class="keywordflow">if</span>(i &gt;= layers_number)
<a name="l00232"></a>00232    {
<a name="l00233"></a>00233       std::ostringstream buffer;
<a name="l00234"></a>00234 
<a name="l00235"></a>00235       buffer &lt;&lt; <span class="stringliteral">"OpenNN Exception: MultilayerPerceptron class.\n"</span>
<a name="l00236"></a>00236              &lt;&lt; <span class="stringliteral">"PerceptronLayer* get_layer_pointer(const unsigned int&amp;) const method.\n"</span>
<a name="l00237"></a>00237              &lt;&lt; <span class="stringliteral">"Index of layer must be less than number of layers.\n"</span>;
<a name="l00238"></a>00238 
<a name="l00239"></a>00239           <span class="keywordflow">throw</span> std::logic_error(buffer.str());
<a name="l00240"></a>00240    }
<a name="l00241"></a>00241 
<a name="l00242"></a>00242 <span class="preprocessor">   #endif</span>
<a name="l00243"></a>00243 <span class="preprocessor"></span> 
<a name="l00244"></a>00244    <span class="keywordflow">return</span>(&amp;<a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#ea970635dd856cb0f9acdf458177312b">layers</a>[i]);
<a name="l00245"></a>00245 }
<a name="l00246"></a>00246 
<a name="l00247"></a>00247 
<a name="l00248"></a>00248 <span class="comment">// unsigned int count_perceptrons_number(void) const method</span>
<a name="l00249"></a>00249 
<a name="l00252"></a>00252 
<a name="l00253"></a><a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#5b9af3feecbf5d6dabce9a4669c2837c">00253</a> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#5b9af3feecbf5d6dabce9a4669c2837c">MultilayerPerceptron::count_perceptrons_number</a>(<span class="keywordtype">void</span>)<span class="keyword"> const</span>
<a name="l00254"></a>00254 <span class="keyword"></span>{
<a name="l00255"></a>00255    <span class="keyword">const</span> <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt;unsigned int&gt;</a> layers_perceptrons_number = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#bac4febc8f59639eadd9d8b896148f5e" title="This method returns a vector with the size of each layer.">arrange_layers_perceptrons_numbers</a>();
<a name="l00256"></a>00256 
<a name="l00257"></a>00257    <span class="keywordflow">return</span>(layers_perceptrons_number.<a class="code" href="class_open_n_n_1_1_vector.html#58893067fb44da94c0111e3b578bea21" title="This method returns the sum of the elements in the vector.">calculate_sum</a>());
<a name="l00258"></a>00258 }
<a name="l00259"></a>00259 
<a name="l00260"></a>00260 
<a name="l00261"></a>00261 <span class="comment">// Vector&lt;unsigned int&gt; count_cumulative_perceptrons_number(void) const method</span>
<a name="l00262"></a>00262 
<a name="l00264"></a>00264 
<a name="l00265"></a><a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#3e67c74221ee6bf5da04b7a939e74ffc">00265</a> <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt;unsigned int&gt;</a> <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#3e67c74221ee6bf5da04b7a939e74ffc" title="This method returns a vector of size the number of layers, where each element is...">MultilayerPerceptron::count_cumulative_perceptrons_number</a>(<span class="keywordtype">void</span>)<span class="keyword"> const</span>
<a name="l00266"></a>00266 <span class="keyword"></span>{
<a name="l00267"></a>00267    <span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> layers_number = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#e5f41a6d170161f9b2896e95bb186423" title="This method returns the number of layers in the multilayer perceptron.">count_layers_number</a>();
<a name="l00268"></a>00268 
<a name="l00269"></a>00269    <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt;unsigned int&gt;</a> cumulative_neurons_number(layers_number);
<a name="l00270"></a>00270 
<a name="l00271"></a>00271    <span class="keywordflow">if</span>(layers_number != 0)
<a name="l00272"></a>00272    {
<a name="l00273"></a>00273       <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt;unsigned int&gt;</a> layers_size = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#bac4febc8f59639eadd9d8b896148f5e" title="This method returns a vector with the size of each layer.">arrange_layers_perceptrons_numbers</a>();
<a name="l00274"></a>00274 
<a name="l00275"></a>00275       cumulative_neurons_number[0] = layers_size[0];
<a name="l00276"></a>00276 
<a name="l00277"></a>00277       <span class="keywordflow">for</span>(<span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> i = 1; i &lt; layers_number; i++)
<a name="l00278"></a>00278       {
<a name="l00279"></a>00279          cumulative_neurons_number[i] = cumulative_neurons_number[i-1] + layers_size[i];   
<a name="l00280"></a>00280       }
<a name="l00281"></a>00281    }  
<a name="l00282"></a>00282 
<a name="l00283"></a>00283    <span class="keywordflow">return</span>(cumulative_neurons_number);
<a name="l00284"></a>00284 }
<a name="l00285"></a>00285 
<a name="l00286"></a>00286 
<a name="l00287"></a>00287 <span class="comment">// Vector&lt;unsigned int&gt; arrange_layers_parameters_number(void) const method</span>
<a name="l00288"></a>00288 
<a name="l00291"></a>00291 
<a name="l00292"></a><a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#d275175679d7733c41642117d90ebe97">00292</a> <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt;unsigned int&gt;</a> <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#d275175679d7733c41642117d90ebe97">MultilayerPerceptron::arrange_layers_parameters_number</a>(<span class="keywordtype">void</span>)<span class="keyword"> const</span>
<a name="l00293"></a>00293 <span class="keyword"></span>{
<a name="l00294"></a>00294    <span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> layers_number = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#e5f41a6d170161f9b2896e95bb186423" title="This method returns the number of layers in the multilayer perceptron.">count_layers_number</a>();
<a name="l00295"></a>00295 
<a name="l00296"></a>00296    <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt;unsigned int&gt;</a> layers_parameters_number(layers_number);
<a name="l00297"></a>00297 
<a name="l00298"></a>00298    <span class="keywordflow">for</span>(<span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> i = 0; i &lt; layers_number; i++)
<a name="l00299"></a>00299    {
<a name="l00300"></a>00300       layers_parameters_number[i] = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#ea970635dd856cb0f9acdf458177312b">layers</a>[i].count_parameters_number();
<a name="l00301"></a>00301    }
<a name="l00302"></a>00302 
<a name="l00303"></a>00303    <span class="keywordflow">return</span>(layers_parameters_number);
<a name="l00304"></a>00304 }
<a name="l00305"></a>00305 
<a name="l00306"></a>00306 
<a name="l00307"></a>00307 <span class="comment">// Vector&lt;unsigned int&gt; arrange_layers_cumulative_parameters_number(void) const method</span>
<a name="l00308"></a>00308 
<a name="l00311"></a>00311 
<a name="l00312"></a><a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#9bdce6921d0310a6ba0bd4df49b38225">00312</a> <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt;unsigned int&gt;</a> <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#9bdce6921d0310a6ba0bd4df49b38225">MultilayerPerceptron::arrange_layers_cumulative_parameters_number</a>(<span class="keywordtype">void</span>)<span class="keyword"> const</span>
<a name="l00313"></a>00313 <span class="keyword"></span>{
<a name="l00314"></a>00314    <span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> layers_number = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#e5f41a6d170161f9b2896e95bb186423" title="This method returns the number of layers in the multilayer perceptron.">count_layers_number</a>();
<a name="l00315"></a>00315 
<a name="l00316"></a>00316    <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt;unsigned int&gt;</a> layers_cumulative_parameters_number(layers_number);
<a name="l00317"></a>00317 
<a name="l00318"></a>00318    layers_cumulative_parameters_number[0] = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#ea970635dd856cb0f9acdf458177312b">layers</a>[0].count_parameters_number();
<a name="l00319"></a>00319 
<a name="l00320"></a>00320    <span class="keywordflow">for</span>(<span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> i = 1; i &lt; layers_number; i++)
<a name="l00321"></a>00321    {
<a name="l00322"></a>00322       layers_cumulative_parameters_number[i] = layers_cumulative_parameters_number[i-1] + <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#ea970635dd856cb0f9acdf458177312b">layers</a>[i].count_parameters_number();   
<a name="l00323"></a>00323    }
<a name="l00324"></a>00324 
<a name="l00325"></a>00325    <span class="keywordflow">return</span>(layers_cumulative_parameters_number);
<a name="l00326"></a>00326 }
<a name="l00327"></a>00327 
<a name="l00328"></a>00328 
<a name="l00329"></a>00329 <span class="comment">// Vector&lt; Vector&lt;double&gt; &gt; arrange_layers_biases(void) const method</span>
<a name="l00330"></a>00330 
<a name="l00335"></a>00335 
<a name="l00336"></a><a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#f2fbdb1edf0cd7a665803c3dbdfb262d">00336</a> <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt; Vector&lt;double&gt;</a> &gt; <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#f2fbdb1edf0cd7a665803c3dbdfb262d">MultilayerPerceptron::arrange_layers_biases</a>(<span class="keywordtype">void</span>)<span class="keyword"> const</span>
<a name="l00337"></a>00337 <span class="keyword"></span>{
<a name="l00338"></a>00338    <span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> layers_number = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#e5f41a6d170161f9b2896e95bb186423" title="This method returns the number of layers in the multilayer perceptron.">count_layers_number</a>();
<a name="l00339"></a>00339 
<a name="l00340"></a>00340    <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt; Vector&lt;double&gt;</a> &gt; layers_biases(layers_number);
<a name="l00341"></a>00341 
<a name="l00342"></a>00342    <span class="keywordflow">for</span>(<span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> i = 0; i &lt; layers_number; i++)
<a name="l00343"></a>00343    {
<a name="l00344"></a>00344       layers_biases[i] = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#ea970635dd856cb0f9acdf458177312b">layers</a>[i].arrange_biases();
<a name="l00345"></a>00345    }
<a name="l00346"></a>00346 
<a name="l00347"></a>00347    <span class="keywordflow">return</span>(layers_biases);
<a name="l00348"></a>00348 }
<a name="l00349"></a>00349 
<a name="l00350"></a>00350 
<a name="l00351"></a>00351 <span class="comment">// Vector&lt; Matrix&lt;double&gt; &gt; arrange_layers_synaptic_weights(void) const method</span>
<a name="l00352"></a>00352 
<a name="l00358"></a>00358 
<a name="l00359"></a><a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#724c4181d557355c39041940129cbc3e">00359</a> <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt; Matrix&lt;double&gt;</a> &gt; <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#724c4181d557355c39041940129cbc3e">MultilayerPerceptron::arrange_layers_synaptic_weights</a>(<span class="keywordtype">void</span>)<span class="keyword"> const</span>
<a name="l00360"></a>00360 <span class="keyword"></span>{
<a name="l00361"></a>00361    <span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> layers_number = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#e5f41a6d170161f9b2896e95bb186423" title="This method returns the number of layers in the multilayer perceptron.">count_layers_number</a>();
<a name="l00362"></a>00362 
<a name="l00363"></a>00363    <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt; Matrix&lt;double&gt;</a> &gt; layers_synaptic_weights(layers_number);
<a name="l00364"></a>00364 
<a name="l00365"></a>00365    <span class="keywordflow">for</span>(<span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> i = 0; i &lt; layers_number; i++)
<a name="l00366"></a>00366    {
<a name="l00367"></a>00367       layers_synaptic_weights[i] = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#ea970635dd856cb0f9acdf458177312b">layers</a>[i].arrange_synaptic_weights();   
<a name="l00368"></a>00368    }
<a name="l00369"></a>00369 
<a name="l00370"></a>00370    <span class="keywordflow">return</span>(layers_synaptic_weights);
<a name="l00371"></a>00371 }
<a name="l00372"></a>00372 
<a name="l00373"></a>00373 
<a name="l00374"></a>00374 <span class="comment">// Vector&lt; Matrix&lt;double&gt; &gt; get_layers_parameters(void) const method</span>
<a name="l00375"></a>00375 
<a name="l00382"></a>00382 
<a name="l00383"></a><a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#8d316d15718fe7e0c97a4ab43b1b6c99">00383</a> <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt; Vector&lt;double&gt;</a> &gt; <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#8d316d15718fe7e0c97a4ab43b1b6c99">MultilayerPerceptron::get_layers_parameters</a>(<span class="keywordtype">void</span>)<span class="keyword"> const</span>
<a name="l00384"></a>00384 <span class="keyword"></span>{
<a name="l00385"></a>00385    <span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> layers_number = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#e5f41a6d170161f9b2896e95bb186423" title="This method returns the number of layers in the multilayer perceptron.">count_layers_number</a>();
<a name="l00386"></a>00386 
<a name="l00387"></a>00387    <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt; Vector&lt;double&gt;</a> &gt; layers_parameters(layers_number);
<a name="l00388"></a>00388 
<a name="l00389"></a>00389    <span class="keywordflow">for</span>(<span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> i = 0; i &lt; layers_number; i++)
<a name="l00390"></a>00390    {
<a name="l00391"></a>00391       layers_parameters[i] = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#ea970635dd856cb0f9acdf458177312b">layers</a>[i].arrange_parameters();   
<a name="l00392"></a>00392    }
<a name="l00393"></a>00393 
<a name="l00394"></a>00394    <span class="keywordflow">return</span>(layers_parameters);
<a name="l00395"></a>00395 }
<a name="l00396"></a>00396 
<a name="l00397"></a>00397 
<a name="l00398"></a>00398 <span class="comment">// unsigned int count_parameters_number(void) const method</span>
<a name="l00399"></a>00399 
<a name="l00401"></a>00401 
<a name="l00402"></a><a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#591e0e7ee4ae2c15d09e135652e30797">00402</a> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#591e0e7ee4ae2c15d09e135652e30797" title="This method returns the number of parameters (biases and synaptic weights) in the...">MultilayerPerceptron::count_parameters_number</a>(<span class="keywordtype">void</span>)<span class="keyword"> const</span>
<a name="l00403"></a>00403 <span class="keyword"></span>{
<a name="l00404"></a>00404    <span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> layers_number = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#e5f41a6d170161f9b2896e95bb186423" title="This method returns the number of layers in the multilayer perceptron.">count_layers_number</a>();
<a name="l00405"></a>00405 
<a name="l00406"></a>00406    <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> parameters_number = 0;
<a name="l00407"></a>00407 
<a name="l00408"></a>00408    <span class="keywordflow">for</span>(<span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> i = 0; i &lt; layers_number; i++)
<a name="l00409"></a>00409    {
<a name="l00410"></a>00410       parameters_number += <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#ea970635dd856cb0f9acdf458177312b">layers</a>[i].count_parameters_number();
<a name="l00411"></a>00411    }
<a name="l00412"></a>00412 
<a name="l00413"></a>00413    <span class="keywordflow">return</span>(parameters_number);
<a name="l00414"></a>00414 }
<a name="l00415"></a>00415 
<a name="l00416"></a>00416 
<a name="l00417"></a>00417 <span class="comment">// Vector&lt;double&gt; arrange_parameters(void) const method</span>
<a name="l00418"></a>00418 
<a name="l00420"></a>00420 
<a name="l00421"></a><a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#598b7b498c5f6adf417f84abad92f9fc">00421</a> <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt;double&gt;</a> <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#598b7b498c5f6adf417f84abad92f9fc" title="This method returns the values of all the biases and synaptic weights in the multilayer...">MultilayerPerceptron::arrange_parameters</a>(<span class="keywordtype">void</span>)<span class="keyword"> const</span>
<a name="l00422"></a>00422 <span class="keyword"></span>{
<a name="l00423"></a>00423    <span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> layers_number = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#e5f41a6d170161f9b2896e95bb186423" title="This method returns the number of layers in the multilayer perceptron.">count_layers_number</a>();
<a name="l00424"></a>00424 
<a name="l00425"></a>00425    <span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> parameters_number = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#591e0e7ee4ae2c15d09e135652e30797" title="This method returns the number of parameters (biases and synaptic weights) in the...">count_parameters_number</a>();
<a name="l00426"></a>00426 
<a name="l00427"></a>00427    <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt;double&gt;</a> parameters(parameters_number);
<a name="l00428"></a>00428 
<a name="l00429"></a>00429    <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> position = 0;
<a name="l00430"></a>00430 
<a name="l00431"></a>00431    <span class="keywordflow">for</span>(<span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> i = 0; i &lt; layers_number; i++)
<a name="l00432"></a>00432    {
<a name="l00433"></a>00433       <span class="keyword">const</span> <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt;double&gt;</a> layer_parameters = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#ea970635dd856cb0f9acdf458177312b">layers</a>[i].arrange_parameters();
<a name="l00434"></a>00434       <span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> layer_parameters_number = layer_parameters.size();
<a name="l00435"></a>00435 
<a name="l00436"></a>00436       parameters.<a class="code" href="class_open_n_n_1_1_vector.html#be51fdf8b728f64fd9a272991e09f15b">tuck_in</a>(position, layer_parameters);
<a name="l00437"></a>00437       position += layer_parameters_number; 
<a name="l00438"></a>00438    }
<a name="l00439"></a>00439 
<a name="l00440"></a>00440    <span class="keywordflow">return</span>(parameters);
<a name="l00441"></a>00441 }
<a name="l00442"></a>00442 
<a name="l00443"></a>00443 
<a name="l00444"></a>00444 <span class="comment">// unsigned int get_layer_index(const unsigned int&amp;) const method</span>
<a name="l00445"></a>00445 
<a name="l00448"></a>00448 
<a name="l00449"></a><a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#8ee8442efa9b661b57ba0e2bae6123ca">00449</a> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#8ee8442efa9b661b57ba0e2bae6123ca">MultilayerPerceptron::get_layer_index</a>(<span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span>&amp; neuron_index)<span class="keyword"> const</span>
<a name="l00450"></a>00450 <span class="keyword"></span>{
<a name="l00451"></a>00451    <span class="comment">// Control sentence (if debug)</span>
<a name="l00452"></a>00452 
<a name="l00453"></a>00453 <span class="preprocessor">   #ifdef _DEBUG </span>
<a name="l00454"></a>00454 <span class="preprocessor"></span>
<a name="l00455"></a>00455    <span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> neurons_number = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#5b9af3feecbf5d6dabce9a4669c2837c">count_perceptrons_number</a>();
<a name="l00456"></a>00456 
<a name="l00457"></a>00457    <span class="keywordflow">if</span>(neuron_index &gt;= neurons_number)
<a name="l00458"></a>00458    {
<a name="l00459"></a>00459       std::ostringstream buffer;
<a name="l00460"></a>00460 
<a name="l00461"></a>00461       buffer &lt;&lt; <span class="stringliteral">"OpenNN Exception: MultilayerPerceptron class.\n"</span>
<a name="l00462"></a>00462              &lt;&lt; <span class="stringliteral">"int get_layer_index(const unsigned int&amp;) const method.\n"</span>
<a name="l00463"></a>00463              &lt;&lt; <span class="stringliteral">"Index of neuron must be less than number of neurons.\n"</span>;
<a name="l00464"></a>00464 
<a name="l00465"></a>00465           <span class="keywordflow">throw</span> std::logic_error(buffer.str());
<a name="l00466"></a>00466    }
<a name="l00467"></a>00467 
<a name="l00468"></a>00468 <span class="preprocessor">   #endif</span>
<a name="l00469"></a>00469 <span class="preprocessor"></span>
<a name="l00470"></a>00470    <span class="keyword">const</span> <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt;unsigned int&gt;</a> cumulative_neurons_number = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#3e67c74221ee6bf5da04b7a939e74ffc" title="This method returns a vector of size the number of layers, where each element is...">count_cumulative_perceptrons_number</a>();
<a name="l00471"></a>00471 
<a name="l00472"></a>00472    <span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> layer_index = cumulative_neurons_number.<a class="code" href="class_open_n_n_1_1_vector.html#496dfcb0c8292afee13c568b26d44ca4">calculate_cumulative_index</a>(neuron_index);
<a name="l00473"></a>00473 
<a name="l00474"></a>00474    <span class="keywordflow">return</span>(layer_index);
<a name="l00475"></a>00475 }
<a name="l00476"></a>00476 
<a name="l00477"></a>00477 
<a name="l00478"></a>00478 <span class="comment">// unsigned int get_perceptron_index(const unsigned int&amp;, const unsigned int&amp;) const method</span>
<a name="l00479"></a>00479 
<a name="l00483"></a>00483 
<a name="l00484"></a><a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#47821c7a9b6dbf1f20b68e3967c4bfa1">00484</a> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#47821c7a9b6dbf1f20b68e3967c4bfa1">MultilayerPerceptron::get_perceptron_index</a>(<span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span>&amp; layer_index, <span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span>&amp; perceptron_position)<span class="keyword"> const</span>
<a name="l00485"></a>00485 <span class="keyword"></span>{
<a name="l00486"></a>00486    <span class="keywordflow">if</span>(layer_index == 0)
<a name="l00487"></a>00487    {
<a name="l00488"></a>00488       <span class="keywordflow">return</span>(perceptron_position);
<a name="l00489"></a>00489    }
<a name="l00490"></a>00490    <span class="keywordflow">else</span>
<a name="l00491"></a>00491    {
<a name="l00492"></a>00492       <span class="keyword">const</span> <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt;unsigned int&gt;</a> cumulative_neurons_number = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#3e67c74221ee6bf5da04b7a939e74ffc" title="This method returns a vector of size the number of layers, where each element is...">count_cumulative_perceptrons_number</a>();
<a name="l00493"></a>00493 
<a name="l00494"></a>00494       <span class="keywordflow">return</span>(cumulative_neurons_number[layer_index-1] + perceptron_position);
<a name="l00495"></a>00495    }
<a name="l00496"></a>00496 }
<a name="l00497"></a>00497 
<a name="l00498"></a>00498 
<a name="l00499"></a>00499 <span class="comment">// unsigned int get_layer_bias_index(const unsigned int&amp;, const unsigned int&amp;) const method</span>
<a name="l00500"></a>00500 
<a name="l00504"></a>00504 
<a name="l00505"></a><a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#6e6d329fee27d6d037750775f29e55c1">00505</a> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#6e6d329fee27d6d037750775f29e55c1">MultilayerPerceptron::get_layer_bias_index</a>(<span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span>&amp; layer_index, <span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span>&amp; perceptron_index)<span class="keyword"> const</span>
<a name="l00506"></a>00506 <span class="keyword"></span>{  
<a name="l00507"></a>00507    <span class="comment">// Control sentence (if debug)</span>
<a name="l00508"></a>00508 
<a name="l00509"></a>00509 <span class="preprocessor">   #ifdef _DEBUG </span>
<a name="l00510"></a>00510 <span class="preprocessor"></span>
<a name="l00511"></a>00511    <span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> layers_number = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#e5f41a6d170161f9b2896e95bb186423" title="This method returns the number of layers in the multilayer perceptron.">count_layers_number</a>();
<a name="l00512"></a>00512 
<a name="l00513"></a>00513    <span class="keywordflow">if</span>(layer_index &gt;= layers_number)
<a name="l00514"></a>00514    {
<a name="l00515"></a>00515       std::ostringstream buffer;
<a name="l00516"></a>00516 
<a name="l00517"></a>00517       buffer &lt;&lt; <span class="stringliteral">"OpenNN Exception: MultilayerPerceptron class.\n"</span>
<a name="l00518"></a>00518              &lt;&lt; <span class="stringliteral">"unsigned int get_layer_bias_index(const unsigned int&amp;, const unsigned int&amp;) const method.\n"</span>
<a name="l00519"></a>00519              &lt;&lt; <span class="stringliteral">"Index of layer must be less than number of layers.\n"</span>;
<a name="l00520"></a>00520 
<a name="l00521"></a>00521           <span class="keywordflow">throw</span> std::logic_error(buffer.str());
<a name="l00522"></a>00522    }
<a name="l00523"></a>00523 
<a name="l00524"></a>00524    <span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> layer_perceptrons_number = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#ea970635dd856cb0f9acdf458177312b">layers</a>[layer_index].count_perceptrons_number(); 
<a name="l00525"></a>00525 
<a name="l00526"></a>00526    <span class="keywordflow">if</span>(perceptron_index &gt;= layer_perceptrons_number)
<a name="l00527"></a>00527    {
<a name="l00528"></a>00528       std::ostringstream buffer;
<a name="l00529"></a>00529 
<a name="l00530"></a>00530       buffer &lt;&lt; <span class="stringliteral">"OpenNN Exception: MultilayerPerceptron class.\n"</span>
<a name="l00531"></a>00531              &lt;&lt; <span class="stringliteral">"unsigned int get_layer_bias_index(const unsigned int&amp;, const unsigned int&amp;) const method.\n"</span>
<a name="l00532"></a>00532              &lt;&lt; <span class="stringliteral">"Index of perceptron must be less than number of perceptrons in that layer.\n"</span>;
<a name="l00533"></a>00533 
<a name="l00534"></a>00534           <span class="keywordflow">throw</span> std::logic_error(buffer.str());
<a name="l00535"></a>00535    }
<a name="l00536"></a>00536 
<a name="l00537"></a>00537 <span class="preprocessor">   #endif</span>
<a name="l00538"></a>00538 <span class="preprocessor"></span>
<a name="l00539"></a>00539    <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> layer_bias_index = 0;
<a name="l00540"></a>00540 
<a name="l00541"></a>00541    <span class="comment">// Previous layers</span>
<a name="l00542"></a>00542 
<a name="l00543"></a>00543    <span class="keywordflow">for</span>(<span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> i = 0; i &lt; layer_index; i++)
<a name="l00544"></a>00544    {
<a name="l00545"></a>00545       layer_bias_index += <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#ea970635dd856cb0f9acdf458177312b">layers</a>[i].count_parameters_number();
<a name="l00546"></a>00546    }
<a name="l00547"></a>00547 
<a name="l00548"></a>00548    <span class="comment">// Previous layer neurons</span>
<a name="l00549"></a>00549 
<a name="l00550"></a>00550    <span class="keywordflow">for</span>(<span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> j = 0; j &lt; perceptron_index; j++)
<a name="l00551"></a>00551    {
<a name="l00552"></a>00552       layer_bias_index += <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#ea970635dd856cb0f9acdf458177312b">layers</a>[layer_index].get_perceptron(j).count_parameters_number();
<a name="l00553"></a>00553    }
<a name="l00554"></a>00554 
<a name="l00555"></a>00555    <span class="keywordflow">return</span>(layer_bias_index);
<a name="l00556"></a>00556 }
<a name="l00557"></a>00557 
<a name="l00558"></a>00558 
<a name="l00559"></a>00559 <span class="comment">// unsigned int get_layer_synaptic_weight_index(const unsigned int&amp;, const unsigned int&amp;, const unsigned int&amp;) const method</span>
<a name="l00560"></a>00560 
<a name="l00565"></a>00565 
<a name="l00566"></a>00566 <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#24072dcef5f66b7d780c954b2a5f1c04">MultilayerPerceptron::get_layer_synaptic_weight_index</a>
<a name="l00567"></a><a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#24072dcef5f66b7d780c954b2a5f1c04">00567</a> (<span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span>&amp; layer_index, <span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span>&amp; perceptron_index, <span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span>&amp; input_index) <span class="keyword">const</span>
<a name="l00568"></a>00568 {
<a name="l00569"></a>00569    <span class="comment">// Control sentence (if debug)</span>
<a name="l00570"></a>00570 
<a name="l00571"></a>00571 <span class="preprocessor">   #ifdef _DEBUG </span>
<a name="l00572"></a>00572 <span class="preprocessor"></span>
<a name="l00573"></a>00573    <span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> layers_number = count_layers_number();
<a name="l00574"></a>00574 
<a name="l00575"></a>00575    <span class="keywordflow">if</span>(layer_index &gt;= layers_number)
<a name="l00576"></a>00576    {
<a name="l00577"></a>00577       std::ostringstream buffer;
<a name="l00578"></a>00578 
<a name="l00579"></a>00579       buffer &lt;&lt; <span class="stringliteral">"OpenNN Exception: MultilayerPerceptron class.\n"</span>
<a name="l00580"></a>00580              &lt;&lt; <span class="stringliteral">"unsigned int get_layer_synaptic_weight_index(const unsigned int&amp;, const unsigned int&amp;, const unsigned int&amp;) method.\n"</span>
<a name="l00581"></a>00581              &lt;&lt; <span class="stringliteral">"Index of layer must be less than number of layers.\n"</span>;
<a name="l00582"></a>00582 
<a name="l00583"></a>00583           <span class="keywordflow">throw</span> std::logic_error(buffer.str());
<a name="l00584"></a>00584    }
<a name="l00585"></a>00585 
<a name="l00586"></a>00586    <span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> layer_perceptrons_number = layers[layer_index].count_perceptrons_number();
<a name="l00587"></a>00587 
<a name="l00588"></a>00588    <span class="keywordflow">if</span>(perceptron_index &gt;= layer_perceptrons_number)
<a name="l00589"></a>00589    {
<a name="l00590"></a>00590       std::ostringstream buffer;
<a name="l00591"></a>00591 
<a name="l00592"></a>00592       buffer &lt;&lt; <span class="stringliteral">"OpenNN Exception: MultilayerPerceptron class.\n"</span>
<a name="l00593"></a>00593              &lt;&lt; <span class="stringliteral">"unsigned int get_layer_synaptic_weight_index(const unsigned int&amp;, const unsigned int&amp;, const unsigned int&amp;) method.\n"</span>
<a name="l00594"></a>00594              &lt;&lt; <span class="stringliteral">"Index of perceptron must be less than number of perceptrons in layer.\n"</span>;
<a name="l00595"></a>00595 
<a name="l00596"></a>00596           <span class="keywordflow">throw</span> std::logic_error(buffer.str());
<a name="l00597"></a>00597    }
<a name="l00598"></a>00598 
<a name="l00599"></a>00599    <span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> layer_inputs_number = layers[layer_index].count_inputs_number();
<a name="l00600"></a>00600 
<a name="l00601"></a>00601    <span class="keywordflow">if</span>(input_index &gt;= layer_inputs_number)
<a name="l00602"></a>00602    {
<a name="l00603"></a>00603       std::ostringstream buffer;
<a name="l00604"></a>00604 
<a name="l00605"></a>00605       buffer &lt;&lt; <span class="stringliteral">"OpenNN Exception: MultilayerPerceptron class.\n"</span>
<a name="l00606"></a>00606              &lt;&lt; <span class="stringliteral">"unsigned int get_layer_synaptic_weight_index(const unsigned int&amp;, const unsigned int&amp;, const unsigned int&amp;) method.\n"</span>
<a name="l00607"></a>00607              &lt;&lt; <span class="stringliteral">"Index of inputs must be less than number of inputs in perceptron.\n"</span>;
<a name="l00608"></a>00608 
<a name="l00609"></a>00609           <span class="keywordflow">throw</span> std::logic_error(buffer.str());
<a name="l00610"></a>00610    }
<a name="l00611"></a>00611 
<a name="l00612"></a>00612 <span class="preprocessor">   #endif</span>
<a name="l00613"></a>00613 <span class="preprocessor"></span>
<a name="l00614"></a>00614    <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> layer_synaptic_weight_index = 0;
<a name="l00615"></a>00615 
<a name="l00616"></a>00616    <span class="comment">// Previous layers</span>
<a name="l00617"></a>00617 
<a name="l00618"></a>00618    <span class="keywordflow">if</span>(layer_index &gt; 0)
<a name="l00619"></a>00619    {
<a name="l00620"></a>00620       <span class="keywordflow">for</span>(<span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> i = 0; i &lt; layer_index-1; i++)
<a name="l00621"></a>00621       {
<a name="l00622"></a>00622          layer_synaptic_weight_index += layers[layer_index].count_parameters_number();
<a name="l00623"></a>00623       }
<a name="l00624"></a>00624    }
<a name="l00625"></a>00625 
<a name="l00626"></a>00626    <span class="comment">// Previous layer neurons</span>
<a name="l00627"></a>00627 
<a name="l00628"></a>00628    <span class="keywordflow">if</span>(perceptron_index &gt; 0)
<a name="l00629"></a>00629    {
<a name="l00630"></a>00630       <span class="keywordflow">for</span>(<span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> i = 0; i &lt; perceptron_index-1; i++)
<a name="l00631"></a>00631       {
<a name="l00632"></a>00632          layer_synaptic_weight_index += layers[layer_index].get_perceptron(i).count_parameters_number();
<a name="l00633"></a>00633       }
<a name="l00634"></a>00634    }
<a name="l00635"></a>00635 
<a name="l00636"></a>00636    <span class="comment">// Hidden neuron bias</span>
<a name="l00637"></a>00637 
<a name="l00638"></a>00638    layer_synaptic_weight_index += 1;
<a name="l00639"></a>00639 
<a name="l00640"></a>00640    <span class="comment">// Synaptic weight index</span>
<a name="l00641"></a>00641 
<a name="l00642"></a>00642    layer_synaptic_weight_index += input_index;
<a name="l00643"></a>00643 
<a name="l00644"></a>00644    <span class="keywordflow">return</span>(layer_synaptic_weight_index);
<a name="l00645"></a>00645 }
<a name="l00646"></a>00646 
<a name="l00647"></a>00647 
<a name="l00648"></a>00648 <span class="comment">// Vector&lt;unsigned int&gt; arrange_parameter_indices(const unsigned int&amp;) const method</span>
<a name="l00649"></a>00649 
<a name="l00652"></a>00652 
<a name="l00653"></a><a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#d93415b65a74777d7e983581a2d3ca0e">00653</a> <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt;unsigned int&gt;</a> <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#d93415b65a74777d7e983581a2d3ca0e">MultilayerPerceptron::arrange_parameter_indices</a>(<span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span>&amp; parameter_index)<span class="keyword"> const</span>
<a name="l00654"></a>00654 <span class="keyword"></span>{
<a name="l00655"></a>00655    <span class="comment">// Control sentence (if debug)</span>
<a name="l00656"></a>00656 
<a name="l00657"></a>00657 <span class="preprocessor">   #ifdef _DEBUG </span>
<a name="l00658"></a>00658 <span class="preprocessor"></span>
<a name="l00659"></a>00659    <span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> parameters_number = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#591e0e7ee4ae2c15d09e135652e30797" title="This method returns the number of parameters (biases and synaptic weights) in the...">count_parameters_number</a>();
<a name="l00660"></a>00660 
<a name="l00661"></a>00661    <span class="keywordflow">if</span>(parameter_index &gt;= parameters_number)
<a name="l00662"></a>00662    {
<a name="l00663"></a>00663       std::ostringstream buffer;
<a name="l00664"></a>00664 
<a name="l00665"></a>00665       buffer &lt;&lt; <span class="stringliteral">"OpenNN Exception: MultilayerPerceptron class.\n"</span>
<a name="l00666"></a>00666              &lt;&lt; <span class="stringliteral">"Vector&lt;int&gt; arrange_parameter_indices(const unsigned int&amp;) const method.\n"</span>
<a name="l00667"></a>00667              &lt;&lt; <span class="stringliteral">"Index of neural parameter must be less than number of multilayer_perceptron_pointer parameters.\n"</span>;
<a name="l00668"></a>00668 
<a name="l00669"></a>00669           <span class="keywordflow">throw</span> std::logic_error(buffer.str());
<a name="l00670"></a>00670    }
<a name="l00671"></a>00671 
<a name="l00672"></a>00672 <span class="preprocessor">   #endif</span>
<a name="l00673"></a>00673 <span class="preprocessor"></span>
<a name="l00674"></a>00674    <span class="keywordflow">return</span>(<a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#b81eaefa02c5050823a3d2d48cec9147">arrange_parameters_indices</a>().arrange_row(parameter_index));
<a name="l00675"></a>00675 }
<a name="l00676"></a>00676 
<a name="l00677"></a>00677 
<a name="l00678"></a>00678 <span class="comment">// Matrix&lt;unsigned int&gt; arrange_parameters_indices(void) const method</span>
<a name="l00679"></a>00679 
<a name="l00684"></a>00684 
<a name="l00685"></a><a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#b81eaefa02c5050823a3d2d48cec9147">00685</a> <a class="code" href="class_open_n_n_1_1_matrix.html">Matrix&lt;unsigned int&gt;</a> <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#b81eaefa02c5050823a3d2d48cec9147">MultilayerPerceptron::arrange_parameters_indices</a>(<span class="keywordtype">void</span>)<span class="keyword"> const</span>
<a name="l00686"></a>00686 <span class="keyword"></span>{
<a name="l00687"></a>00687    <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> perceptron_parameters_number;
<a name="l00688"></a>00688 
<a name="l00689"></a>00689    <span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> layers_number = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#e5f41a6d170161f9b2896e95bb186423" title="This method returns the number of layers in the multilayer perceptron.">count_layers_number</a>();
<a name="l00690"></a>00690    <span class="keyword">const</span> <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt;unsigned int&gt;</a> layers_size = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#bac4febc8f59639eadd9d8b896148f5e" title="This method returns a vector with the size of each layer.">arrange_layers_perceptrons_numbers</a>();
<a name="l00691"></a>00691 
<a name="l00692"></a>00692    <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> parameters_number = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#591e0e7ee4ae2c15d09e135652e30797" title="This method returns the number of parameters (biases and synaptic weights) in the...">count_parameters_number</a>();
<a name="l00693"></a>00693 
<a name="l00694"></a>00694    <a class="code" href="class_open_n_n_1_1_matrix.html">Matrix&lt;unsigned int&gt;</a> parameters_indices(parameters_number, 3);
<a name="l00695"></a>00695    
<a name="l00696"></a>00696    <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> parameter_index = 0;
<a name="l00697"></a>00697 
<a name="l00698"></a>00698    <span class="keywordflow">for</span>(<span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> i = 0; i &lt; layers_number; i++)
<a name="l00699"></a>00699    {
<a name="l00700"></a>00700       <span class="keywordflow">for</span>(<span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> j = 0; j &lt; layers_size[i]; j++)
<a name="l00701"></a>00701           {
<a name="l00702"></a>00702          perceptron_parameters_number = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#ea970635dd856cb0f9acdf458177312b">layers</a>[i].get_perceptron(j).count_parameters_number();
<a name="l00703"></a>00703 
<a name="l00704"></a>00704              <span class="keywordflow">for</span>(<span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> k = 0; k &lt; perceptron_parameters_number; k++)
<a name="l00705"></a>00705                  {
<a name="l00706"></a>00706                     parameters_indices[parameter_index][0] = i;
<a name="l00707"></a>00707                     parameters_indices[parameter_index][1] = j;
<a name="l00708"></a>00708                     parameters_indices[parameter_index][2] = k;
<a name="l00709"></a>00709             parameter_index++;
<a name="l00710"></a>00710                  }
<a name="l00711"></a>00711           }
<a name="l00712"></a>00712    }
<a name="l00713"></a>00713 
<a name="l00714"></a>00714    <span class="keywordflow">return</span>(parameters_indices);
<a name="l00715"></a>00715 }
<a name="l00716"></a>00716 
<a name="l00717"></a>00717 
<a name="l00718"></a>00718 <span class="comment">// Vector&lt;Perceptron::ActivationFunction&gt; get_layers_activation_function(void) const method</span>
<a name="l00719"></a>00719 
<a name="l00721"></a>00721 
<a name="l00722"></a><a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#4abe40b47a3e89c6e89510ebe26f910b">00722</a> <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt;Perceptron::ActivationFunction&gt;</a> <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#4abe40b47a3e89c6e89510ebe26f910b" title="This method returns the activation function of every layer in a single vector.">MultilayerPerceptron::get_layers_activation_function</a>(<span class="keywordtype">void</span>)<span class="keyword"> const</span>
<a name="l00723"></a>00723 <span class="keyword"></span>{
<a name="l00724"></a>00724    <span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> layers_number = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#e5f41a6d170161f9b2896e95bb186423" title="This method returns the number of layers in the multilayer perceptron.">count_layers_number</a>();
<a name="l00725"></a>00725 
<a name="l00726"></a>00726    <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt;Perceptron::ActivationFunction&gt;</a> layers_activation_function(layers_number);
<a name="l00727"></a>00727 
<a name="l00728"></a>00728    <span class="keywordflow">for</span>(<span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> i = 0; i &lt; layers_number; i++)
<a name="l00729"></a>00729    {
<a name="l00730"></a>00730           layers_activation_function[i] = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#ea970635dd856cb0f9acdf458177312b">layers</a>[i].get_activation_function();
<a name="l00731"></a>00731    }
<a name="l00732"></a>00732 
<a name="l00733"></a>00733    <span class="keywordflow">return</span>(layers_activation_function);
<a name="l00734"></a>00734 }
<a name="l00735"></a>00735    
<a name="l00736"></a>00736 
<a name="l00737"></a>00737 <span class="comment">// Vector&lt;std::string&gt; write_layers_activation_function(void) const method</span>
<a name="l00738"></a>00738 
<a name="l00741"></a>00741 
<a name="l00742"></a><a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#b138e01b62f7638306d8d48d37d5347d">00742</a> <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt;std::string&gt;</a> <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#b138e01b62f7638306d8d48d37d5347d">MultilayerPerceptron::write_layers_activation_function</a>(<span class="keywordtype">void</span>)<span class="keyword"> const</span>
<a name="l00743"></a>00743 <span class="keyword"></span>{
<a name="l00744"></a>00744    <span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> layers_number = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#e5f41a6d170161f9b2896e95bb186423" title="This method returns the number of layers in the multilayer perceptron.">count_layers_number</a>();
<a name="l00745"></a>00745 
<a name="l00746"></a>00746    <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt;std::string&gt;</a> layers_activation_function_name(layers_number);
<a name="l00747"></a>00747 
<a name="l00748"></a>00748    <span class="keywordflow">for</span>(<span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> i = 0; i &lt; layers_number; i++)
<a name="l00749"></a>00749    {
<a name="l00750"></a>00750       layers_activation_function_name[i] = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#ea970635dd856cb0f9acdf458177312b">layers</a>[i].write_activation_function_name();
<a name="l00751"></a>00751    }
<a name="l00752"></a>00752 
<a name="l00753"></a>00753    <span class="keywordflow">return</span>(layers_activation_function_name);
<a name="l00754"></a>00754 }
<a name="l00755"></a>00755 
<a name="l00756"></a>00756 
<a name="l00757"></a>00757 <span class="comment">// const bool&amp; get_display(void) const method</span>
<a name="l00758"></a>00758 
<a name="l00761"></a>00761 
<a name="l00762"></a><a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#02166b5db1c266601ffe865a8bd0c5c6">00762</a> <span class="keyword">const</span> <span class="keywordtype">bool</span>&amp; <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#02166b5db1c266601ffe865a8bd0c5c6">MultilayerPerceptron::get_display</a>(<span class="keywordtype">void</span>)<span class="keyword"> const</span>
<a name="l00763"></a>00763 <span class="keyword"></span>{
<a name="l00764"></a>00764    <span class="keywordflow">return</span>(<a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#24c63c4f903e9cbde9beabca81a6682f" title="Display messages to screen.">display</a>);
<a name="l00765"></a>00765 }
<a name="l00766"></a>00766 
<a name="l00767"></a>00767 
<a name="l00768"></a>00768 <span class="comment">// void set_default(void) method</span>
<a name="l00769"></a>00769 
<a name="l00776"></a>00776 
<a name="l00777"></a><a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#563c8d829b36217cf392f3c94c7eaa4a">00777</a> <span class="keywordtype">void</span> <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#563c8d829b36217cf392f3c94c7eaa4a">MultilayerPerceptron::set_default</a>(<span class="keywordtype">void</span>)
<a name="l00778"></a>00778 {
<a name="l00779"></a>00779    <span class="comment">// Multilayer perceptron architecture</span>
<a name="l00780"></a>00780 
<a name="l00781"></a>00781    <span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> layers_number = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#e5f41a6d170161f9b2896e95bb186423" title="This method returns the number of layers in the multilayer perceptron.">count_layers_number</a>();
<a name="l00782"></a>00782 
<a name="l00783"></a>00783    <span class="keywordflow">if</span>(layers_number &gt; 0)
<a name="l00784"></a>00784    { 
<a name="l00785"></a>00785       <span class="keywordflow">for</span>(<span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> i = 0; i &lt; layers_number-1; i++)
<a name="l00786"></a>00786       {
<a name="l00787"></a>00787          <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#ea970635dd856cb0f9acdf458177312b">layers</a>[i].set_activation_function(Perceptron::HyperbolicTangent);         
<a name="l00788"></a>00788       }
<a name="l00789"></a>00789 
<a name="l00790"></a>00790       <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#ea970635dd856cb0f9acdf458177312b">layers</a>[layers_number-1].set_activation_function(Perceptron::Linear);
<a name="l00791"></a>00791    }
<a name="l00792"></a>00792  
<a name="l00793"></a>00793    <span class="comment">// Display messages</span>
<a name="l00794"></a>00794    
<a name="l00795"></a>00795    <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#b1dab55d760434a9243259492797ec82">set_display</a>(<span class="keyword">true</span>);
<a name="l00796"></a>00796 }
<a name="l00797"></a>00797 
<a name="l00798"></a>00798 
<a name="l00799"></a>00799 <span class="comment">// void set(void) method</span>
<a name="l00800"></a>00800 
<a name="l00802"></a>00802 
<a name="l00803"></a><a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#623067035f448edabef76ddc5d88b473">00803</a> <span class="keywordtype">void</span> <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#623067035f448edabef76ddc5d88b473" title="This method sets an empty multilayer_perceptron_pointer architecture.">MultilayerPerceptron::set</a>(<span class="keywordtype">void</span>)
<a name="l00804"></a>00804 {
<a name="l00805"></a>00805    <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#ea970635dd856cb0f9acdf458177312b">layers</a>.<a class="code" href="class_open_n_n_1_1_vector.html#78a81ff993befcd4e75ab75da2976a9a" title="This method sets the size of a vector to zero.">set</a>();        
<a name="l00806"></a>00806 }
<a name="l00807"></a>00807 
<a name="l00808"></a>00808 
<a name="l00809"></a>00809 <span class="comment">// void set(const Vector&lt;PerceptronLayer&gt;&amp;) method</span>
<a name="l00810"></a>00810 
<a name="l00813"></a>00813 
<a name="l00814"></a><a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#5e62adf001b988392ec7144cd55db2a8">00814</a> <span class="keywordtype">void</span> <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#623067035f448edabef76ddc5d88b473" title="This method sets an empty multilayer_perceptron_pointer architecture.">MultilayerPerceptron::set</a>(<span class="keyword">const</span> <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt;PerceptronLayer&gt;</a>&amp; new_layers)
<a name="l00815"></a>00815 {
<a name="l00816"></a>00816    <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#ea970635dd856cb0f9acdf458177312b">layers</a> = new_layers;   
<a name="l00817"></a>00817 }
<a name="l00818"></a>00818 
<a name="l00819"></a>00819 
<a name="l00820"></a>00820 <span class="comment">// void set(const Vector&lt;unsigned int&gt;&amp;) method</span>
<a name="l00821"></a>00821 
<a name="l00829"></a>00829 
<a name="l00830"></a><a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#d99e981d495d8e73d40aa4934f0c4324">00830</a> <span class="keywordtype">void</span> <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#623067035f448edabef76ddc5d88b473" title="This method sets an empty multilayer_perceptron_pointer architecture.">MultilayerPerceptron::set</a>(<span class="keyword">const</span> <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt;unsigned int&gt;</a>&amp; new_architecture)
<a name="l00831"></a>00831 {
<a name="l00832"></a>00832    std::ostringstream buffer;
<a name="l00833"></a>00833 
<a name="l00834"></a>00834    <span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> new_architecture_size = new_architecture.size();
<a name="l00835"></a>00835 
<a name="l00836"></a>00836    <span class="keywordflow">if</span>(new_architecture_size == 0)
<a name="l00837"></a>00837    {
<a name="l00838"></a>00838       <span class="keyword">set</span>();
<a name="l00839"></a>00839    }
<a name="l00840"></a>00840    <span class="keywordflow">else</span> <span class="keywordflow">if</span>(new_architecture_size == 1)
<a name="l00841"></a>00841    {
<a name="l00842"></a>00842       buffer &lt;&lt; <span class="stringliteral">"OpenNN Exception: MultilayerPerceptron class.\n"</span> 
<a name="l00843"></a>00843              &lt;&lt; <span class="stringliteral">"void set_architecture(const Vector&lt;unsigned int&gt;&amp;) method.\n"</span>
<a name="l00844"></a>00844              &lt;&lt; <span class="stringliteral">"Size of architecture cannot be one.\n"</span>;
<a name="l00845"></a>00845 
<a name="l00846"></a>00846           <span class="keywordflow">throw</span> std::logic_error(buffer.str());   
<a name="l00847"></a>00847    }
<a name="l00848"></a>00848    <span class="keywordflow">else</span>
<a name="l00849"></a>00849    {
<a name="l00850"></a>00850       <span class="keywordflow">for</span>(<span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> i = 0; i &lt; new_architecture_size; i++)
<a name="l00851"></a>00851       {
<a name="l00852"></a>00852          <span class="keywordflow">if</span>(new_architecture[i] == 0)
<a name="l00853"></a>00853          {
<a name="l00854"></a>00854             buffer &lt;&lt; <span class="stringliteral">"OpenNN Exception: MultilayerPerceptron class.\n"</span> 
<a name="l00855"></a>00855                    &lt;&lt; <span class="stringliteral">"void set_architecture(const Vector&lt;unsigned int&gt;&amp;) method.\n"</span>
<a name="l00856"></a>00856                    &lt;&lt; <span class="stringliteral">"Size "</span> &lt;&lt; i &lt;&lt; <span class="stringliteral">" must be greater than zero.\n"</span>;
<a name="l00857"></a>00857 
<a name="l00858"></a>00858                 <span class="keywordflow">throw</span> std::logic_error(buffer.str());
<a name="l00859"></a>00859          }
<a name="l00860"></a>00860       }
<a name="l00861"></a>00861 
<a name="l00862"></a>00862       <span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> new_layers_number = new_architecture_size-1;
<a name="l00863"></a>00863       <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#ea970635dd856cb0f9acdf458177312b">layers</a>.<a class="code" href="class_open_n_n_1_1_vector.html#78a81ff993befcd4e75ab75da2976a9a" title="This method sets the size of a vector to zero.">set</a>(new_layers_number);
<a name="l00864"></a>00864       
<a name="l00865"></a>00865      <span class="comment">// First layer</span>
<a name="l00866"></a>00866 
<a name="l00867"></a>00867       <span class="keywordflow">for</span>(<span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> i = 0; i &lt; new_layers_number; i++)
<a name="l00868"></a>00868       {
<a name="l00869"></a>00869              <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#ea970635dd856cb0f9acdf458177312b">layers</a>[i].set_perceptrons_number(new_architecture[i+1]);
<a name="l00870"></a>00870          <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#ea970635dd856cb0f9acdf458177312b">layers</a>[i].set_inputs_number(new_architecture[i]);
<a name="l00871"></a>00871       }
<a name="l00872"></a>00872    
<a name="l00873"></a>00873       <span class="comment">// Activation</span>
<a name="l00874"></a>00874 
<a name="l00875"></a>00875       <span class="keywordflow">for</span>(<span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> i = 0; i &lt; new_layers_number-1; i++)
<a name="l00876"></a>00876       {
<a name="l00877"></a>00877          <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#ea970635dd856cb0f9acdf458177312b">layers</a>[i].set_activation_function(Perceptron::HyperbolicTangent);
<a name="l00878"></a>00878       }
<a name="l00879"></a>00879 
<a name="l00880"></a>00880       <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#ea970635dd856cb0f9acdf458177312b">layers</a>[new_layers_number-1].set_activation_function(Perceptron::Linear);
<a name="l00881"></a>00881    }
<a name="l00882"></a>00882 }   
<a name="l00883"></a>00883 
<a name="l00884"></a>00884 
<a name="l00885"></a>00885 <span class="comment">// void set(const unsigned int&amp;, const unsigned int&amp;) method</span>
<a name="l00886"></a>00886 
<a name="l00890"></a>00890 
<a name="l00891"></a><a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#f172dff8b1de5cc41178a92fba80137a">00891</a> <span class="keywordtype">void</span> <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#623067035f448edabef76ddc5d88b473" title="This method sets an empty multilayer_perceptron_pointer architecture.">MultilayerPerceptron::set</a>(<span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span>&amp; new_inputs_number, <span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span>&amp; new_perceptrons_number)
<a name="l00892"></a>00892 {
<a name="l00893"></a>00893    <span class="comment">// Control sentence (if debug)</span>
<a name="l00894"></a>00894 
<a name="l00895"></a>00895 <span class="preprocessor">   #ifdef _DEBUG </span>
<a name="l00896"></a>00896 <span class="preprocessor"></span>
<a name="l00897"></a>00897    std::ostringstream buffer;
<a name="l00898"></a>00898 
<a name="l00899"></a>00899    <span class="keywordflow">if</span>(new_inputs_number == 0)
<a name="l00900"></a>00900    {  
<a name="l00901"></a>00901       buffer &lt;&lt; <span class="stringliteral">"OpenNN Exception: MultilayerPerceptron class.\n"</span> 
<a name="l00902"></a>00902              &lt;&lt; <span class="stringliteral">"void set(const unsigned int&amp;, const unsigned int&amp;) method.\n"</span>
<a name="l00903"></a>00903              &lt;&lt; <span class="stringliteral">"Number of inputs cannot be zero.\n"</span>;
<a name="l00904"></a>00904 
<a name="l00905"></a>00905           <span class="keywordflow">throw</span> std::logic_error(buffer.str());
<a name="l00906"></a>00906    }   
<a name="l00907"></a>00907    <span class="keywordflow">else</span> <span class="keywordflow">if</span>(new_perceptrons_number == 0)
<a name="l00908"></a>00908    {  
<a name="l00909"></a>00909       buffer &lt;&lt; <span class="stringliteral">"OpenNN Exception: MultilayerPerceptron class.\n"</span> 
<a name="l00910"></a>00910              &lt;&lt; <span class="stringliteral">"void set_architecture(const unsigned int&amp;, const unsigned int&amp;) method.\n"</span>
<a name="l00911"></a>00911              &lt;&lt; <span class="stringliteral">"Number of perceptrons cannot be zero.\n"</span>;
<a name="l00912"></a>00912 
<a name="l00913"></a>00913           <span class="keywordflow">throw</span> std::logic_error(buffer.str());
<a name="l00914"></a>00914    }
<a name="l00915"></a>00915 
<a name="l00916"></a>00916 <span class="preprocessor">   #endif</span>
<a name="l00917"></a>00917 <span class="preprocessor"></span>
<a name="l00918"></a>00918    <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#ea970635dd856cb0f9acdf458177312b">layers</a>.<a class="code" href="class_open_n_n_1_1_vector.html#78a81ff993befcd4e75ab75da2976a9a" title="This method sets the size of a vector to zero.">set</a>(1);
<a name="l00919"></a>00919 
<a name="l00920"></a>00920    <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#ea970635dd856cb0f9acdf458177312b">layers</a>[0].<a class="code" href="class_open_n_n_1_1_vector.html#78a81ff993befcd4e75ab75da2976a9a" title="This method sets the size of a vector to zero.">set</a>(new_inputs_number, new_perceptrons_number);
<a name="l00921"></a>00921 }
<a name="l00922"></a>00922 
<a name="l00923"></a>00923 
<a name="l00924"></a>00924 <span class="comment">// void set(const unsigned int&amp;, const unsigned int&amp;, const unsigned int&amp;) method</span>
<a name="l00925"></a>00925 
<a name="l00930"></a>00930 
<a name="l00931"></a><a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#0c809406584bb0690da1185c7614d691">00931</a> <span class="keywordtype">void</span> <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#623067035f448edabef76ddc5d88b473" title="This method sets an empty multilayer_perceptron_pointer architecture.">MultilayerPerceptron::set</a>(<span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span>&amp; new_inputs_number, <span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span>&amp; new_hidden_neurons_number, <span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span>&amp; new_outputs_number)
<a name="l00932"></a>00932 {
<a name="l00933"></a>00933   <span class="comment">// Control sentence (if debug)</span>
<a name="l00934"></a>00934 
<a name="l00935"></a>00935 <span class="preprocessor">   #ifdef _DEBUG </span>
<a name="l00936"></a>00936 <span class="preprocessor"></span>
<a name="l00937"></a>00937    std::ostringstream buffer;
<a name="l00938"></a>00938 
<a name="l00939"></a>00939    <span class="keywordflow">if</span>(new_inputs_number == 0)
<a name="l00940"></a>00940    {
<a name="l00941"></a>00941       buffer &lt;&lt; <span class="stringliteral">"OpenNN Exception: MultilayerPerceptron class.\n"</span> 
<a name="l00942"></a>00942              &lt;&lt; <span class="stringliteral">"void set(const unsigned int&amp;, const unsigned int&amp;, const unsigned int&amp;) method.\n"</span>
<a name="l00943"></a>00943              &lt;&lt; <span class="stringliteral">"Number of inputs must be greater than zero.\n"</span>;
<a name="l00944"></a>00944 
<a name="l00945"></a>00945           <span class="keywordflow">throw</span> std::logic_error(buffer.str());
<a name="l00946"></a>00946    }
<a name="l00947"></a>00947    <span class="keywordflow">else</span> <span class="keywordflow">if</span>(new_hidden_neurons_number == 0)
<a name="l00948"></a>00948    {
<a name="l00949"></a>00949       buffer &lt;&lt; <span class="stringliteral">"OpenNN Exception: MultilayerPerceptron class.\n"</span> 
<a name="l00950"></a>00950              &lt;&lt; <span class="stringliteral">"void set(const unsigned int&amp;, const unsigned int&amp;, const unsigned int&amp;) method.\n"</span>
<a name="l00951"></a>00951              &lt;&lt; <span class="stringliteral">"Number of hidden neurons must be greater than zero.\n"</span>;
<a name="l00952"></a>00952 
<a name="l00953"></a>00953           <span class="keywordflow">throw</span> std::logic_error(buffer.str());
<a name="l00954"></a>00954    }
<a name="l00955"></a>00955    <span class="keywordflow">else</span> <span class="keywordflow">if</span>(new_outputs_number == 0)
<a name="l00956"></a>00956    {
<a name="l00957"></a>00957       buffer &lt;&lt; <span class="stringliteral">"OpenNN Exception: MultilayerPerceptron class.\n"</span> 
<a name="l00958"></a>00958              &lt;&lt; <span class="stringliteral">"void set(const unsigned int&amp;, const unsigned int&amp;, const unsigned int&amp;) method.\n"</span>
<a name="l00959"></a>00959              &lt;&lt; <span class="stringliteral">"Number of outputs must be greater than zero.\n"</span>;
<a name="l00960"></a>00960    
<a name="l00961"></a>00961           <span class="keywordflow">throw</span> std::logic_error(buffer.str());
<a name="l00962"></a>00962    }
<a name="l00963"></a>00963    
<a name="l00964"></a>00964 <span class="preprocessor">   #endif</span>
<a name="l00965"></a>00965 <span class="preprocessor"></span>
<a name="l00966"></a>00966    <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#ea970635dd856cb0f9acdf458177312b">layers</a>.<a class="code" href="class_open_n_n_1_1_vector.html#78a81ff993befcd4e75ab75da2976a9a" title="This method sets the size of a vector to zero.">set</a>(2);
<a name="l00967"></a>00967 
<a name="l00968"></a>00968    <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#ea970635dd856cb0f9acdf458177312b">layers</a>[0].<a class="code" href="class_open_n_n_1_1_vector.html#78a81ff993befcd4e75ab75da2976a9a" title="This method sets the size of a vector to zero.">set</a>(new_inputs_number, new_hidden_neurons_number);
<a name="l00969"></a>00969    <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#ea970635dd856cb0f9acdf458177312b">layers</a>[0].set_activation_function(Perceptron::HyperbolicTangent);
<a name="l00970"></a>00970 
<a name="l00971"></a>00971    <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#ea970635dd856cb0f9acdf458177312b">layers</a>[1].<a class="code" href="class_open_n_n_1_1_vector.html#78a81ff993befcd4e75ab75da2976a9a" title="This method sets the size of a vector to zero.">set</a>(new_hidden_neurons_number, new_outputs_number);
<a name="l00972"></a>00972    <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#ea970635dd856cb0f9acdf458177312b">layers</a>[1].set_activation_function(Perceptron::Linear);
<a name="l00973"></a>00973 }
<a name="l00974"></a>00974 
<a name="l00975"></a>00975 
<a name="l00976"></a>00976 <span class="comment">// void set(const MultilayerPerceptron&amp;) method</span>
<a name="l00977"></a>00977 
<a name="l00980"></a>00980 
<a name="l00981"></a><a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#5c740c4d8261d4d34873b043e05a8487">00981</a> <span class="keywordtype">void</span> <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#623067035f448edabef76ddc5d88b473" title="This method sets an empty multilayer_perceptron_pointer architecture.">MultilayerPerceptron::set</a>(<span class="keyword">const</span> <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html">MultilayerPerceptron</a>&amp; other_multilayer_perceptron)
<a name="l00982"></a>00982 {
<a name="l00983"></a>00983    <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#ea970635dd856cb0f9acdf458177312b">layers</a> = other_multilayer_perceptron.<a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#ea970635dd856cb0f9acdf458177312b">layers</a>;
<a name="l00984"></a>00984 
<a name="l00985"></a>00985    <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#24c63c4f903e9cbde9beabca81a6682f" title="Display messages to screen.">display</a> = other_multilayer_perceptron.<a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#24c63c4f903e9cbde9beabca81a6682f" title="Display messages to screen.">display</a>;
<a name="l00986"></a>00986 }
<a name="l00987"></a>00987 
<a name="l00988"></a>00988 
<a name="l00989"></a>00989 <span class="comment">// void set_inputs_number(const unsigned int) method</span>
<a name="l00990"></a>00990 
<a name="l00993"></a>00993 
<a name="l00994"></a><a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#30e33c633f14ccdec802dd30e1ed5a4f">00994</a> <span class="keywordtype">void</span> <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#30e33c633f14ccdec802dd30e1ed5a4f">MultilayerPerceptron::set_inputs_number</a>(<span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> new_inputs_number)
<a name="l00995"></a>00995 {
<a name="l00996"></a>00996    <span class="keywordflow">if</span>(<a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#1bd9d1e92e346e85d8ec5e6daa694cba" title="This method returns true if the number of layers in the multilayer perceptron is...">is_empty</a>())
<a name="l00997"></a>00997    {
<a name="l00998"></a>00998       std::ostringstream buffer;
<a name="l00999"></a>00999    
<a name="l01000"></a>01000       buffer &lt;&lt; <span class="stringliteral">"OpenNN Exception: MultilayerPerceptron class.\n"</span> 
<a name="l01001"></a>01001              &lt;&lt; <span class="stringliteral">"void set_inputs_number(const unsigned int&amp;) method.\n"</span>
<a name="l01002"></a>01002              &lt;&lt; <span class="stringliteral">"Multilayer perceptron is empty.\n"</span>;
<a name="l01003"></a>01003 
<a name="l01004"></a>01004           <span class="keywordflow">throw</span> std::logic_error(buffer.str());
<a name="l01005"></a>01005    } 
<a name="l01006"></a>01006 
<a name="l01007"></a>01007    <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#ea970635dd856cb0f9acdf458177312b">layers</a>[0].set_inputs_number(new_inputs_number);
<a name="l01008"></a>01008 }
<a name="l01009"></a>01009 
<a name="l01010"></a>01010 
<a name="l01011"></a>01011 <span class="comment">// void set_layers_perceptrons_number(const Vector&lt;unsigned int&gt;&amp;) method</span>
<a name="l01012"></a>01012 
<a name="l01017"></a>01017 
<a name="l01018"></a><a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#b0726bc41d881a87a172ca4118a61e24">01018</a> <span class="keywordtype">void</span> <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#b0726bc41d881a87a172ca4118a61e24">MultilayerPerceptron::set_layers_perceptrons_number</a>(<span class="keyword">const</span> <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt;unsigned int&gt;</a>&amp; new_layers_size)
<a name="l01019"></a>01019 {
<a name="l01020"></a>01020    <span class="keyword">const</span> <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt;unsigned int&gt;</a> inputs_number(1, <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#0998a82ea1845b0fd26872218b02b3f4" title="This method returns the number of inputs to the multilayer perceptron.">count_inputs_number</a>());
<a name="l01021"></a>01021 
<a name="l01022"></a>01022    <span class="keyword">set</span>(inputs_number.<a class="code" href="class_open_n_n_1_1_vector.html#a67a4283b5e4dfd60c7c244973f55050">get_assembly</a>(new_layers_size));
<a name="l01023"></a>01023 }
<a name="l01024"></a>01024 
<a name="l01025"></a>01025 
<a name="l01026"></a>01026 <span class="comment">// void set_layer_perceptrons_number(const unsigned int&amp;, const unsigned int&amp;) method</span>
<a name="l01027"></a>01027 
<a name="l01032"></a>01032 
<a name="l01033"></a><a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#a4bcca9a3bd39e288830ff939fe27721">01033</a> <span class="keywordtype">void</span> <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#a4bcca9a3bd39e288830ff939fe27721">MultilayerPerceptron::set_layer_perceptrons_number</a>(<span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span>&amp; layer_index, <span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span>&amp; new_layer_perceptrons_number)
<a name="l01034"></a>01034 {
<a name="l01035"></a>01035    <span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> layer_inputs_number = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#ea970635dd856cb0f9acdf458177312b">layers</a>[layer_index].count_inputs_number();
<a name="l01036"></a>01036 
<a name="l01037"></a>01037    <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#ea970635dd856cb0f9acdf458177312b">layers</a>[layer_index].set_perceptrons_number(new_layer_perceptrons_number);
<a name="l01038"></a>01038    
<a name="l01039"></a>01039    <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#ea970635dd856cb0f9acdf458177312b">layers</a>[layer_index].set_inputs_number(layer_inputs_number);
<a name="l01040"></a>01040 
<a name="l01041"></a>01041    <span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> layers_number = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#e5f41a6d170161f9b2896e95bb186423" title="This method returns the number of layers in the multilayer perceptron.">count_layers_number</a>();
<a name="l01042"></a>01042 
<a name="l01043"></a>01043    <span class="keywordflow">if</span>(layer_index &lt; layers_number-1)
<a name="l01044"></a>01044    {
<a name="l01045"></a>01045       <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#ea970635dd856cb0f9acdf458177312b">layers</a>[layer_index+1].set_inputs_number(new_layer_perceptrons_number);   
<a name="l01046"></a>01046    }
<a name="l01047"></a>01047 }
<a name="l01048"></a>01048 
<a name="l01049"></a>01049 
<a name="l01050"></a>01050 <span class="comment">// void set_layers(const Vector&lt;PerceptronLayer&gt;&amp;) method</span>
<a name="l01051"></a>01051 
<a name="l01054"></a>01054 
<a name="l01055"></a><a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#885a7dd6b7f0c39301e0a60e015ab730">01055</a> <span class="keywordtype">void</span> <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#885a7dd6b7f0c39301e0a60e015ab730">MultilayerPerceptron::set_layers</a>(<span class="keyword">const</span> <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt;PerceptronLayer&gt;</a>&amp; new_layers)
<a name="l01056"></a>01056 {
<a name="l01057"></a>01057    <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#ea970635dd856cb0f9acdf458177312b">layers</a> = new_layers;
<a name="l01058"></a>01058 }
<a name="l01059"></a>01059 
<a name="l01060"></a>01060 
<a name="l01061"></a>01061 <span class="comment">// void set_layers_biases(const Vector&lt; Vector&lt;double&gt; &gt;&amp;) method</span>
<a name="l01062"></a>01062 
<a name="l01068"></a>01068 
<a name="l01069"></a><a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#d7ce33f9334c11db37cd463fb45b92d0">01069</a> <span class="keywordtype">void</span> <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#d7ce33f9334c11db37cd463fb45b92d0">MultilayerPerceptron::set_layers_biases</a>(<span class="keyword">const</span> <a class="code" href="class_open_n_n_1_1_vector.html">Vector</a>&lt; <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt;double&gt;</a> &gt;&amp; new_layers_biases)
<a name="l01070"></a>01070 {
<a name="l01071"></a>01071    <span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> layers_number = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#e5f41a6d170161f9b2896e95bb186423" title="This method returns the number of layers in the multilayer perceptron.">count_layers_number</a>();
<a name="l01072"></a>01072 
<a name="l01073"></a>01073    <span class="comment">// Control sentence (if debug)</span>
<a name="l01074"></a>01074 
<a name="l01075"></a>01075 <span class="preprocessor">   #ifdef _DEBUG </span>
<a name="l01076"></a>01076 <span class="preprocessor"></span>
<a name="l01077"></a>01077    <span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> size = new_layers_biases.size();
<a name="l01078"></a>01078 
<a name="l01079"></a>01079    <span class="keywordflow">if</span>(size != layers_number)
<a name="l01080"></a>01080    {
<a name="l01081"></a>01081       std::ostringstream buffer;
<a name="l01082"></a>01082 
<a name="l01083"></a>01083       buffer &lt;&lt; <span class="stringliteral">"OpenNN Exception: MultilayerPerceptron class.\n"</span>
<a name="l01084"></a>01084              &lt;&lt; <span class="stringliteral">"void set_layers_biases(const Vector&lt; Vector&lt;double&gt; &gt;&amp;) method.\n"</span>
<a name="l01085"></a>01085              &lt;&lt; <span class="stringliteral">"Size ("</span> &lt;&lt; size &lt;&lt; <span class="stringliteral">") must be equal to number of layers ("</span> &lt;&lt; layers_number &lt;&lt; <span class="stringliteral">").\n"</span>;
<a name="l01086"></a>01086 
<a name="l01087"></a>01087           <span class="keywordflow">throw</span> std::logic_error(buffer.str());
<a name="l01088"></a>01088    }
<a name="l01089"></a>01089 
<a name="l01090"></a>01090 <span class="preprocessor">   #endif</span>
<a name="l01091"></a>01091 <span class="preprocessor"></span>
<a name="l01092"></a>01092    <span class="keyword">const</span> <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt;unsigned int&gt;</a> layers_size = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#bac4febc8f59639eadd9d8b896148f5e" title="This method returns a vector with the size of each layer.">arrange_layers_perceptrons_numbers</a>();
<a name="l01093"></a>01093 
<a name="l01094"></a>01094    <span class="keywordflow">for</span>(<span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> i = 0; i &lt; layers_number; i++)
<a name="l01095"></a>01095    {
<a name="l01096"></a>01096       <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#ea970635dd856cb0f9acdf458177312b">layers</a>[i].set_biases(new_layers_biases[i]); 
<a name="l01097"></a>01097    }
<a name="l01098"></a>01098 }
<a name="l01099"></a>01099 
<a name="l01100"></a>01100 
<a name="l01101"></a>01101 <span class="comment">// void set_layers_synaptic_weights(const Vector&lt; Matrix&lt;double&gt; &gt;&amp;) method</span>
<a name="l01102"></a>01102 
<a name="l01109"></a>01109 
<a name="l01110"></a><a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#84b540d6851a13266ef6038ab96feb44">01110</a> <span class="keywordtype">void</span> <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#84b540d6851a13266ef6038ab96feb44">MultilayerPerceptron::set_layers_synaptic_weights</a>(<span class="keyword">const</span> <a class="code" href="class_open_n_n_1_1_vector.html">Vector</a>&lt; <a class="code" href="class_open_n_n_1_1_matrix.html">Matrix&lt;double&gt;</a> &gt;&amp; new_layers_synaptic_weights)
<a name="l01111"></a>01111 {
<a name="l01112"></a>01112    <span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> layers_number = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#e5f41a6d170161f9b2896e95bb186423" title="This method returns the number of layers in the multilayer perceptron.">count_layers_number</a>();
<a name="l01113"></a>01113 
<a name="l01114"></a>01114    <span class="comment">// Control sentence (if debug)</span>
<a name="l01115"></a>01115 
<a name="l01116"></a>01116 <span class="preprocessor">   #ifdef _DEBUG </span>
<a name="l01117"></a>01117 <span class="preprocessor"></span>
<a name="l01118"></a>01118    <span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> size = new_layers_synaptic_weights.size();
<a name="l01119"></a>01119 
<a name="l01120"></a>01120    <span class="keywordflow">if</span>(size != layers_number)
<a name="l01121"></a>01121    {
<a name="l01122"></a>01122       std::ostringstream buffer;
<a name="l01123"></a>01123 
<a name="l01124"></a>01124           buffer &lt;&lt; <span class="stringliteral">"OpenNN Exception: MultilayerPerceptron class.\n"</span>
<a name="l01125"></a>01125              &lt;&lt; <span class="stringliteral">"void set_layers_synaptic_weights(const Vector&lt; Matrix&lt;double&gt; &gt;&amp;) method.\n"</span>
<a name="l01126"></a>01126              &lt;&lt; <span class="stringliteral">"Size must be equal to number of layers.\n"</span>;
<a name="l01127"></a>01127 
<a name="l01128"></a>01128           <span class="keywordflow">throw</span> std::logic_error(buffer.str());
<a name="l01129"></a>01129    }
<a name="l01130"></a>01130 
<a name="l01131"></a>01131 <span class="preprocessor">   #endif</span>
<a name="l01132"></a>01132 <span class="preprocessor"></span>
<a name="l01133"></a>01133    <span class="keywordflow">for</span>(<span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> i = 0; i &lt; layers_number; i++)
<a name="l01134"></a>01134    {
<a name="l01135"></a>01135       <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#ea970635dd856cb0f9acdf458177312b">layers</a>[i].set_synaptic_weights(new_layers_synaptic_weights[i]);
<a name="l01136"></a>01136    }
<a name="l01137"></a>01137 
<a name="l01138"></a>01138 }
<a name="l01139"></a>01139 
<a name="l01140"></a>01140 
<a name="l01141"></a>01141 <span class="comment">// void set_layers_parameters(const Vector&lt; Vector&lt;double&gt; &gt;&amp;) method</span>
<a name="l01142"></a>01142 
<a name="l01148"></a>01148 
<a name="l01149"></a><a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#401e06b911242db8f30d476d314a8eb6">01149</a> <span class="keywordtype">void</span> <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#401e06b911242db8f30d476d314a8eb6">MultilayerPerceptron::set_layers_parameters</a>(<span class="keyword">const</span> <a class="code" href="class_open_n_n_1_1_vector.html">Vector</a>&lt; <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt;double&gt;</a> &gt;&amp; new_layers_parameters)
<a name="l01150"></a>01150 {
<a name="l01151"></a>01151    <span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> layers_number = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#e5f41a6d170161f9b2896e95bb186423" title="This method returns the number of layers in the multilayer perceptron.">count_layers_number</a>();
<a name="l01152"></a>01152 
<a name="l01153"></a>01153    <span class="comment">// Control sentence (if debug)</span>
<a name="l01154"></a>01154 
<a name="l01155"></a>01155 <span class="preprocessor">   #ifdef _DEBUG </span>
<a name="l01156"></a>01156 <span class="preprocessor"></span>
<a name="l01157"></a>01157    <span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> new_layers_parameters_size = new_layers_parameters.size();
<a name="l01158"></a>01158 
<a name="l01159"></a>01159    <span class="keywordflow">if</span>(new_layers_parameters_size != layers_number)
<a name="l01160"></a>01160    {
<a name="l01161"></a>01161       std::ostringstream buffer;
<a name="l01162"></a>01162 
<a name="l01163"></a>01163       buffer &lt;&lt; <span class="stringliteral">"OpenNN Exception: MultilayerPerceptron class.\n"</span>
<a name="l01164"></a>01164              &lt;&lt; <span class="stringliteral">"void set_layers_parameters(const Vector&lt; Vector&lt;double&gt; &gt;&amp;) method.\n"</span>
<a name="l01165"></a>01165              &lt;&lt; <span class="stringliteral">"Size of layer parameters must be equal to number of layers.\n"</span>;
<a name="l01166"></a>01166 
<a name="l01167"></a>01167           <span class="keywordflow">throw</span> std::logic_error(buffer.str());
<a name="l01168"></a>01168    }
<a name="l01169"></a>01169 
<a name="l01170"></a>01170 <span class="preprocessor">   #endif</span>
<a name="l01171"></a>01171 <span class="preprocessor"></span>
<a name="l01172"></a>01172    <span class="keywordflow">for</span>(<span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> i = 0; i &lt; layers_number; i++)
<a name="l01173"></a>01173    {
<a name="l01174"></a>01174       <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#ea970635dd856cb0f9acdf458177312b">layers</a>[i].set_parameters(new_layers_parameters[i]);
<a name="l01175"></a>01175    }
<a name="l01176"></a>01176 }
<a name="l01177"></a>01177 
<a name="l01178"></a>01178 
<a name="l01179"></a>01179 <span class="comment">// void set_parameters(const Vector&lt;double&gt;&amp;) method</span>
<a name="l01180"></a>01180 
<a name="l01183"></a>01183 
<a name="l01184"></a><a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#b15a55807eb7d574061178c7d701985d">01184</a> <span class="keywordtype">void</span> <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#b15a55807eb7d574061178c7d701985d">MultilayerPerceptron::set_parameters</a>(<span class="keyword">const</span> <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt;double&gt;</a>&amp; new_parameters)
<a name="l01185"></a>01185 {
<a name="l01186"></a>01186    <span class="comment">// Control sentence (if debug)</span>
<a name="l01187"></a>01187 
<a name="l01188"></a>01188 <span class="preprocessor">   #ifdef _DEBUG </span>
<a name="l01189"></a>01189 <span class="preprocessor"></span>
<a name="l01190"></a>01190    <span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> size = new_parameters.size();
<a name="l01191"></a>01191 
<a name="l01192"></a>01192    <span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> parameters_number = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#591e0e7ee4ae2c15d09e135652e30797" title="This method returns the number of parameters (biases and synaptic weights) in the...">count_parameters_number</a>();
<a name="l01193"></a>01193 
<a name="l01194"></a>01194    <span class="keywordflow">if</span>(size != parameters_number)
<a name="l01195"></a>01195    {
<a name="l01196"></a>01196       std::ostringstream buffer;
<a name="l01197"></a>01197 
<a name="l01198"></a>01198       buffer &lt;&lt; <span class="stringliteral">"OpenNN Exception: MultilayerPerceptron class.\n"</span>
<a name="l01199"></a>01199              &lt;&lt; <span class="stringliteral">"void set_parameters(const Vector&lt;double&gt;&amp;) method.\n"</span>
<a name="l01200"></a>01200              &lt;&lt; <span class="stringliteral">"Size must be equal to number of biases and synaptic weights.\n"</span>;
<a name="l01201"></a>01201 
<a name="l01202"></a>01202           <span class="keywordflow">throw</span> std::logic_error(buffer.str());
<a name="l01203"></a>01203    }
<a name="l01204"></a>01204 
<a name="l01205"></a>01205 <span class="preprocessor">   #endif</span>
<a name="l01206"></a>01206 <span class="preprocessor"></span>
<a name="l01207"></a>01207    <span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> layers_number = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#e5f41a6d170161f9b2896e95bb186423" title="This method returns the number of layers in the multilayer perceptron.">count_layers_number</a>();
<a name="l01208"></a>01208 
<a name="l01209"></a>01209    <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> layer_parameters_number;
<a name="l01210"></a>01210    <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt;double&gt;</a> layer_parameters;
<a name="l01211"></a>01211 
<a name="l01212"></a>01212    <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> position = 0;
<a name="l01213"></a>01213 
<a name="l01214"></a>01214    <span class="keywordflow">for</span>(<span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> i = 0; i &lt; layers_number; i++)
<a name="l01215"></a>01215    {
<a name="l01216"></a>01216       layer_parameters_number = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#ea970635dd856cb0f9acdf458177312b">layers</a>[i].count_parameters_number();
<a name="l01217"></a>01217       layer_parameters = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#ea970635dd856cb0f9acdf458177312b">layers</a>[i].arrange_parameters();
<a name="l01218"></a>01218 
<a name="l01219"></a>01219       layer_parameters = new_parameters.<a class="code" href="class_open_n_n_1_1_vector.html#bb38987cdecb2660561635e4c91a3367">take_out</a>(position, layer_parameters_number);
<a name="l01220"></a>01220       <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#ea970635dd856cb0f9acdf458177312b">layers</a>[i].set_parameters(layer_parameters);
<a name="l01221"></a>01221       position += layer_parameters_number;
<a name="l01222"></a>01222    }
<a name="l01223"></a>01223 }
<a name="l01224"></a>01224 
<a name="l01225"></a>01225 
<a name="l01226"></a>01226 <span class="comment">// void set_layers_activation_function(const Vector&lt;Perceptron::ActivationFunction&gt;&amp;) method</span>
<a name="l01227"></a>01227 
<a name="l01232"></a>01232 
<a name="l01233"></a>01233 <span class="keywordtype">void</span> <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#37e821e19f542937d190cb0c61845769">MultilayerPerceptron::set_layers_activation_function</a>
<a name="l01234"></a><a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#37e821e19f542937d190cb0c61845769">01234</a> (<span class="keyword">const</span> <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt;Perceptron::ActivationFunction&gt;</a>&amp; new_layers_activation_function)
<a name="l01235"></a>01235 { 
<a name="l01236"></a>01236    <span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> layers_number = count_layers_number();
<a name="l01237"></a>01237 
<a name="l01238"></a>01238    <span class="comment">// Control sentence (if debug)</span>
<a name="l01239"></a>01239 
<a name="l01240"></a>01240 <span class="preprocessor">   #ifdef _DEBUG </span>
<a name="l01241"></a>01241 <span class="preprocessor"></span>
<a name="l01242"></a>01242    <span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> new_layers_activation_function_size = new_layers_activation_function.size();
<a name="l01243"></a>01243 
<a name="l01244"></a>01244    <span class="keywordflow">if</span>(new_layers_activation_function_size != layers_number)
<a name="l01245"></a>01245    {
<a name="l01246"></a>01246       std::ostringstream buffer;
<a name="l01247"></a>01247 
<a name="l01248"></a>01248       buffer &lt;&lt; <span class="stringliteral">"OpenNN Exception: MultilayerPerceptron class.\n"</span> 
<a name="l01249"></a>01249              &lt;&lt; <span class="stringliteral">"void set_layers_activation_function(const Vector&lt;Perceptron::ActivationFunction&gt;&amp;) method.\n"</span>
<a name="l01250"></a>01250              &lt;&lt; <span class="stringliteral">"Size of activation function of layers must be equal to number of layers.\n"</span>;
<a name="l01251"></a>01251 
<a name="l01252"></a>01252           <span class="keywordflow">throw</span> std::logic_error(buffer.str());
<a name="l01253"></a>01253    }
<a name="l01254"></a>01254 
<a name="l01255"></a>01255 <span class="preprocessor">   #endif</span>
<a name="l01256"></a>01256 <span class="preprocessor"></span>
<a name="l01257"></a>01257    <span class="keywordflow">for</span>(<span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> i = 0; i &lt; layers_number; i++)
<a name="l01258"></a>01258    {
<a name="l01259"></a>01259       layers[i].set_activation_function(new_layers_activation_function[i]);
<a name="l01260"></a>01260    }
<a name="l01261"></a>01261 }
<a name="l01262"></a>01262 
<a name="l01263"></a>01263 
<a name="l01264"></a>01264 <span class="comment">// void set_layers_activation_function(const Vector&lt;std::string&gt;&amp;) method</span>
<a name="l01265"></a>01265 
<a name="l01269"></a>01269 
<a name="l01270"></a><a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#dca37fb80c45fe4fe5dbd5fa5e47ecbe">01270</a> <span class="keywordtype">void</span> <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#37e821e19f542937d190cb0c61845769">MultilayerPerceptron::set_layers_activation_function</a>(<span class="keyword">const</span> <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt;std::string&gt;</a>&amp; new_layers_activation_function)
<a name="l01271"></a>01271 {
<a name="l01272"></a>01272    <span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> layers_number = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#e5f41a6d170161f9b2896e95bb186423" title="This method returns the number of layers in the multilayer perceptron.">count_layers_number</a>();
<a name="l01273"></a>01273 
<a name="l01274"></a>01274    <span class="keywordflow">for</span>(<span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> i = 0; i &lt; layers_number; i++)
<a name="l01275"></a>01275    {
<a name="l01276"></a>01276       <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#ea970635dd856cb0f9acdf458177312b">layers</a>[i].set_activation_function(new_layers_activation_function[i]);
<a name="l01277"></a>01277    }
<a name="l01278"></a>01278 }
<a name="l01279"></a>01279 
<a name="l01280"></a>01280 
<a name="l01281"></a>01281 <span class="comment">// void set_display(const bool&amp;) method</span>
<a name="l01282"></a>01282 
<a name="l01287"></a>01287 
<a name="l01288"></a><a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#b1dab55d760434a9243259492797ec82">01288</a> <span class="keywordtype">void</span> <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#b1dab55d760434a9243259492797ec82">MultilayerPerceptron::set_display</a>(<span class="keyword">const</span> <span class="keywordtype">bool</span>&amp; new_display)
<a name="l01289"></a>01289 {
<a name="l01290"></a>01290    <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#24c63c4f903e9cbde9beabca81a6682f" title="Display messages to screen.">display</a> = new_display;
<a name="l01291"></a>01291 }
<a name="l01292"></a>01292 
<a name="l01293"></a>01293 
<a name="l01294"></a>01294 <span class="comment">// bool is_empty(void) const method</span>
<a name="l01295"></a>01295 
<a name="l01297"></a>01297 
<a name="l01298"></a><a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#1bd9d1e92e346e85d8ec5e6daa694cba">01298</a> <span class="keywordtype">bool</span> <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#1bd9d1e92e346e85d8ec5e6daa694cba" title="This method returns true if the number of layers in the multilayer perceptron is...">MultilayerPerceptron::is_empty</a>(<span class="keywordtype">void</span>)<span class="keyword"> const</span>
<a name="l01299"></a>01299 <span class="keyword"></span>{
<a name="l01300"></a>01300    <span class="keywordflow">if</span>(<a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#ea970635dd856cb0f9acdf458177312b">layers</a>.empty())
<a name="l01301"></a>01301    {
<a name="l01302"></a>01302       <span class="keywordflow">return</span>(<span class="keyword">true</span>);
<a name="l01303"></a>01303    }
<a name="l01304"></a>01304    <span class="keywordflow">else</span>
<a name="l01305"></a>01305    {
<a name="l01306"></a>01306       <span class="keywordflow">return</span>(<span class="keyword">false</span>);
<a name="l01307"></a>01307    }
<a name="l01308"></a>01308 }
<a name="l01309"></a>01309 
<a name="l01310"></a>01310 
<a name="l01311"></a>01311 <span class="comment">// void grow_input(const unsigned int&amp;) method</span>
<a name="l01312"></a>01312 
<a name="l01314"></a>01314 
<a name="l01315"></a><a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#ff4d777a4453e1eacc5e70fefebc02ec">01315</a> <span class="keywordtype">void</span> <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#ff4d777a4453e1eacc5e70fefebc02ec">MultilayerPerceptron::grow_input</a>(<span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span>&amp;)
<a name="l01316"></a>01316 {
<a name="l01317"></a>01317 }
<a name="l01318"></a>01318 
<a name="l01319"></a>01319 
<a name="l01320"></a>01320 <span class="comment">// void grow_layer(int, int) method</span>
<a name="l01321"></a>01321 
<a name="l01323"></a>01323 
<a name="l01324"></a><a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#0fe5d752e6471cc253e99ad3d12a5084">01324</a> <span class="keywordtype">void</span> <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#0fe5d752e6471cc253e99ad3d12a5084">MultilayerPerceptron::grow_layer</a>(<span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span>&amp;, <span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span>&amp;)
<a name="l01325"></a>01325 {
<a name="l01326"></a>01326 }
<a name="l01327"></a>01327 
<a name="l01328"></a>01328 
<a name="l01329"></a>01329 <span class="comment">// void prune_input(int) method</span>
<a name="l01330"></a>01330 
<a name="l01332"></a>01332 
<a name="l01333"></a><a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#68a3a8bd53440f23fd4112b85cd7930c">01333</a> <span class="keywordtype">void</span> <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#68a3a8bd53440f23fd4112b85cd7930c">MultilayerPerceptron::prune_input</a>(<span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span>&amp;)
<a name="l01334"></a>01334 {
<a name="l01335"></a>01335 }
<a name="l01336"></a>01336 
<a name="l01337"></a>01337 
<a name="l01338"></a>01338 <span class="comment">// void prune_layer(int, int) method</span>
<a name="l01339"></a>01339 
<a name="l01341"></a>01341 
<a name="l01342"></a><a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#24bd83b3144f582e184583030022c7b5">01342</a> <span class="keywordtype">void</span> <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#24bd83b3144f582e184583030022c7b5">MultilayerPerceptron::prune_layer</a>(<span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span>&amp;, <span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span>&amp;)
<a name="l01343"></a>01343 {
<a name="l01344"></a>01344 }
<a name="l01345"></a>01345 
<a name="l01346"></a>01346 
<a name="l01347"></a>01347 <span class="comment">// void initialize_random(void) method</span>
<a name="l01348"></a>01348 
<a name="l01352"></a>01352 
<a name="l01353"></a><a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#068b369014c5572dce3c9f398f7f8b13">01353</a> <span class="keywordtype">void</span> <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#068b369014c5572dce3c9f398f7f8b13">MultilayerPerceptron::initialize_random</a>(<span class="keywordtype">void</span>)
<a name="l01354"></a>01354 {
<a name="l01355"></a>01355    <span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> architecture_size = rand()%10 + 2;
<a name="l01356"></a>01356 
<a name="l01357"></a>01357    <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt;unsigned int&gt;</a> architecture(architecture_size);
<a name="l01358"></a>01358 
<a name="l01359"></a>01359    <span class="keywordflow">for</span>(<span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> i = 0; i &lt; architecture_size; i++)
<a name="l01360"></a>01360    {
<a name="l01361"></a>01361       architecture[i]  = rand()%10 + 1;
<a name="l01362"></a>01362    }
<a name="l01363"></a>01363 
<a name="l01364"></a>01364    <span class="keyword">set</span>(architecture);
<a name="l01365"></a>01365 
<a name="l01366"></a>01366    <span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> layers_number = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#e5f41a6d170161f9b2896e95bb186423" title="This method returns the number of layers in the multilayer perceptron.">count_layers_number</a>();
<a name="l01367"></a>01367 
<a name="l01368"></a>01368    <span class="comment">// Layers activation function</span>
<a name="l01369"></a>01369 
<a name="l01370"></a>01370    <span class="keywordflow">for</span>(<span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> i = 0; i &lt; layers_number; i++)
<a name="l01371"></a>01371    {
<a name="l01372"></a>01372       <span class="keywordflow">switch</span>(rand()%5)
<a name="l01373"></a>01373       {
<a name="l01374"></a>01374          <span class="keywordflow">case</span> 0:
<a name="l01375"></a>01375          {
<a name="l01376"></a>01376             <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#ea970635dd856cb0f9acdf458177312b">layers</a>[i].set_activation_function(Perceptron::Logistic);
<a name="l01377"></a>01377          }
<a name="l01378"></a>01378          <span class="keywordflow">break</span>;
<a name="l01379"></a>01379 
<a name="l01380"></a>01380          <span class="keywordflow">case</span> 1:
<a name="l01381"></a>01381          {
<a name="l01382"></a>01382             <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#ea970635dd856cb0f9acdf458177312b">layers</a>[i].set_activation_function(Perceptron::HyperbolicTangent);
<a name="l01383"></a>01383          }
<a name="l01384"></a>01384          <span class="keywordflow">break</span>;
<a name="l01385"></a>01385 
<a name="l01386"></a>01386          <span class="keywordflow">case</span> 2:
<a name="l01387"></a>01387          {
<a name="l01388"></a>01388             <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#ea970635dd856cb0f9acdf458177312b">layers</a>[i].set_activation_function(Perceptron::Threshold);
<a name="l01389"></a>01389          }
<a name="l01390"></a>01390          <span class="keywordflow">break</span>;
<a name="l01391"></a>01391 
<a name="l01392"></a>01392          <span class="keywordflow">case</span> 3:
<a name="l01393"></a>01393          {
<a name="l01394"></a>01394             <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#ea970635dd856cb0f9acdf458177312b">layers</a>[i].set_activation_function(Perceptron::SymmetricThreshold);
<a name="l01395"></a>01395          }
<a name="l01396"></a>01396          <span class="keywordflow">break</span>;
<a name="l01397"></a>01397 
<a name="l01398"></a>01398          <span class="keywordflow">case</span> 4:
<a name="l01399"></a>01399          {
<a name="l01400"></a>01400             <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#ea970635dd856cb0f9acdf458177312b">layers</a>[i].set_activation_function(Perceptron::Linear);
<a name="l01401"></a>01401          }
<a name="l01402"></a>01402          <span class="keywordflow">break</span>;
<a name="l01403"></a>01403 
<a name="l01404"></a>01404          <span class="keywordflow">default</span>:
<a name="l01405"></a>01405          {
<a name="l01406"></a>01406             std::ostringstream buffer;
<a name="l01407"></a>01407 
<a name="l01408"></a>01408             buffer &lt;&lt; <span class="stringliteral">"OpenNN Exception: MultilayerPerceptron class.\n"</span>
<a name="l01409"></a>01409                    &lt;&lt; <span class="stringliteral">"void initialize_random(void) method.\n"</span>
<a name="l01410"></a>01410                    &lt;&lt; <span class="stringliteral">"Unknown layer activation function.\n"</span>;
<a name="l01411"></a>01411  
<a name="l01412"></a>01412                 <span class="keywordflow">throw</span> std::logic_error(buffer.str());
<a name="l01413"></a>01413          }
<a name="l01414"></a>01414          <span class="keywordflow">break</span>;
<a name="l01415"></a>01415       }        
<a name="l01416"></a>01416    }
<a name="l01417"></a>01417 
<a name="l01418"></a>01418    <span class="comment">// Display messages</span>
<a name="l01419"></a>01419    
<a name="l01420"></a>01420    <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#b1dab55d760434a9243259492797ec82">set_display</a>(<span class="keyword">true</span>);
<a name="l01421"></a>01421 }
<a name="l01422"></a>01422 
<a name="l01423"></a>01423 
<a name="l01424"></a>01424 <span class="comment">// void initialize_biases(const double&amp;) method</span>
<a name="l01425"></a>01425 
<a name="l01428"></a>01428 
<a name="l01429"></a><a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#5ebf91192c93c5fd18f1ec29207207ca">01429</a> <span class="keywordtype">void</span> <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#5ebf91192c93c5fd18f1ec29207207ca">MultilayerPerceptron::initialize_biases</a>(<span class="keyword">const</span> <span class="keywordtype">double</span>&amp; value)
<a name="l01430"></a>01430 {
<a name="l01431"></a>01431    <span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> layers_number = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#e5f41a6d170161f9b2896e95bb186423" title="This method returns the number of layers in the multilayer perceptron.">count_layers_number</a>();   
<a name="l01432"></a>01432 
<a name="l01433"></a>01433    <span class="keywordflow">for</span>(<span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> i = 0; i &lt; layers_number; i++)
<a name="l01434"></a>01434    {
<a name="l01435"></a>01435       <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#ea970635dd856cb0f9acdf458177312b">layers</a>[i].initialize_biases(value);
<a name="l01436"></a>01436    }
<a name="l01437"></a>01437 }
<a name="l01438"></a>01438 
<a name="l01439"></a>01439 
<a name="l01440"></a>01440 <span class="comment">// void initialize_synaptic_weights(const double&amp;) const method</span>
<a name="l01441"></a>01441 
<a name="l01444"></a>01444 
<a name="l01445"></a><a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#cf9501cd4bdbc4ffa3d9d5870b260490">01445</a> <span class="keywordtype">void</span> <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#cf9501cd4bdbc4ffa3d9d5870b260490">MultilayerPerceptron::initialize_synaptic_weights</a>(<span class="keyword">const</span> <span class="keywordtype">double</span>&amp; value) 
<a name="l01446"></a>01446 {
<a name="l01447"></a>01447    <span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> layers_number = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#e5f41a6d170161f9b2896e95bb186423" title="This method returns the number of layers in the multilayer perceptron.">count_layers_number</a>();   
<a name="l01448"></a>01448    <span class="keyword">const</span> <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt;unsigned int&gt;</a> layers_size = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#bac4febc8f59639eadd9d8b896148f5e" title="This method returns a vector with the size of each layer.">arrange_layers_perceptrons_numbers</a>();
<a name="l01449"></a>01449 
<a name="l01450"></a>01450    <span class="keywordflow">for</span>(<span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> i = 0; i &lt; layers_number; i++)
<a name="l01451"></a>01451    {
<a name="l01452"></a>01452       <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#ea970635dd856cb0f9acdf458177312b">layers</a>[i].initialize_synaptic_weights(value);
<a name="l01453"></a>01453    }
<a name="l01454"></a>01454 }
<a name="l01455"></a>01455 
<a name="l01456"></a>01456 
<a name="l01457"></a>01457 <span class="comment">// void initialize_parameters(const double&amp;) method</span>
<a name="l01458"></a>01458 
<a name="l01461"></a>01461 
<a name="l01462"></a><a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#a1923dd36ba03b81b879b6db5aed15c2">01462</a> <span class="keywordtype">void</span> <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#af500529dae76e5a5096ee8adced1882" title="This method initializes the parameters at random with values chosen from a normal...">MultilayerPerceptron::initialize_parameters</a>(<span class="keyword">const</span> <span class="keywordtype">double</span>&amp; value)
<a name="l01463"></a>01463 {
<a name="l01464"></a>01464    <span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> parameters_number = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#591e0e7ee4ae2c15d09e135652e30797" title="This method returns the number of parameters (biases and synaptic weights) in the...">count_parameters_number</a>();
<a name="l01465"></a>01465 
<a name="l01466"></a>01466    <span class="keyword">const</span> <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt;double&gt;</a> parameters(parameters_number, value);
<a name="l01467"></a>01467 
<a name="l01468"></a>01468    <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#b15a55807eb7d574061178c7d701985d">set_parameters</a>(parameters);
<a name="l01469"></a>01469 }
<a name="l01470"></a>01470 
<a name="l01471"></a>01471 
<a name="l01472"></a>01472 <span class="comment">// void initialize_parameters_uniform(void) method</span>
<a name="l01473"></a>01473 
<a name="l01476"></a>01476 
<a name="l01477"></a><a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#9902c106189e869b7862b6bce29a52fa">01477</a> <span class="keywordtype">void</span> <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#9902c106189e869b7862b6bce29a52fa">MultilayerPerceptron::initialize_parameters_uniform</a>(<span class="keywordtype">void</span>)
<a name="l01478"></a>01478 {
<a name="l01479"></a>01479    <span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> parameters_number = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#591e0e7ee4ae2c15d09e135652e30797" title="This method returns the number of parameters (biases and synaptic weights) in the...">count_parameters_number</a>();
<a name="l01480"></a>01480 
<a name="l01481"></a>01481    <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt;double&gt;</a> parameters(parameters_number);
<a name="l01482"></a>01482 
<a name="l01483"></a>01483    parameters.<a class="code" href="class_open_n_n_1_1_vector.html#ad3935a890aa294f7cef557a33c57db3" title="This method assigns a random value comprised between -1 and 1 to each element in...">initialize_uniform</a>();
<a name="l01484"></a>01484 
<a name="l01485"></a>01485    <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#b15a55807eb7d574061178c7d701985d">set_parameters</a>(parameters);
<a name="l01486"></a>01486 }
<a name="l01487"></a>01487 
<a name="l01488"></a>01488 
<a name="l01489"></a>01489 <span class="comment">// void initialize_parameters_uniform(const double&amp;, const double&amp;) method</span>
<a name="l01490"></a>01490 
<a name="l01495"></a>01495 
<a name="l01496"></a><a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#087aeadd4855f379fc2190d176424f08">01496</a> <span class="keywordtype">void</span> <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#9902c106189e869b7862b6bce29a52fa">MultilayerPerceptron::initialize_parameters_uniform</a>(<span class="keyword">const</span> <span class="keywordtype">double</span>&amp; minimum, <span class="keyword">const</span> <span class="keywordtype">double</span>&amp; maximum)
<a name="l01497"></a>01497 {
<a name="l01498"></a>01498    <span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> parameters_number = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#591e0e7ee4ae2c15d09e135652e30797" title="This method returns the number of parameters (biases and synaptic weights) in the...">count_parameters_number</a>();
<a name="l01499"></a>01499 
<a name="l01500"></a>01500    <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt;double&gt;</a> parameters(parameters_number);
<a name="l01501"></a>01501 
<a name="l01502"></a>01502    parameters.<a class="code" href="class_open_n_n_1_1_vector.html#ad3935a890aa294f7cef557a33c57db3" title="This method assigns a random value comprised between -1 and 1 to each element in...">initialize_uniform</a>(minimum, maximum);
<a name="l01503"></a>01503 
<a name="l01504"></a>01504    <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#b15a55807eb7d574061178c7d701985d">set_parameters</a>(parameters);
<a name="l01505"></a>01505 }
<a name="l01506"></a>01506 
<a name="l01507"></a>01507 
<a name="l01508"></a>01508 <span class="comment">// void initialize_parameters_uniform(const Vector&lt;double&gt;&amp;, const Vector&lt;double&gt;&amp;) method</span>
<a name="l01509"></a>01509 
<a name="l01514"></a>01514 
<a name="l01515"></a><a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#1a4d4591649fab5bb55677ed51a74d3a">01515</a> <span class="keywordtype">void</span> <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#9902c106189e869b7862b6bce29a52fa">MultilayerPerceptron::initialize_parameters_uniform</a>(<span class="keyword">const</span> <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt;double&gt;</a>&amp; minimum, <span class="keyword">const</span> <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt;double&gt;</a>&amp; maximum)
<a name="l01516"></a>01516 {
<a name="l01517"></a>01517    <span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> parameters_number = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#591e0e7ee4ae2c15d09e135652e30797" title="This method returns the number of parameters (biases and synaptic weights) in the...">count_parameters_number</a>();
<a name="l01518"></a>01518 
<a name="l01519"></a>01519    <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt;double&gt;</a> parameters(parameters_number);
<a name="l01520"></a>01520 
<a name="l01521"></a>01521    parameters.<a class="code" href="class_open_n_n_1_1_vector.html#ad3935a890aa294f7cef557a33c57db3" title="This method assigns a random value comprised between -1 and 1 to each element in...">initialize_uniform</a>(minimum, maximum);
<a name="l01522"></a>01522 
<a name="l01523"></a>01523    <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#b15a55807eb7d574061178c7d701985d">set_parameters</a>(parameters);
<a name="l01524"></a>01524 }
<a name="l01525"></a>01525 
<a name="l01526"></a>01526 
<a name="l01527"></a>01527 <span class="comment">// void initializeparameters_uniform(const Vector&lt; Vector&lt;double&gt; &gt;&amp;) method</span>
<a name="l01528"></a>01528 
<a name="l01535"></a>01535 
<a name="l01536"></a><a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#fe705ac9230d7e77b1b965ce8a95f959">01536</a> <span class="keywordtype">void</span> <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#9902c106189e869b7862b6bce29a52fa">MultilayerPerceptron::initialize_parameters_uniform</a>(<span class="keyword">const</span> <a class="code" href="class_open_n_n_1_1_vector.html">Vector</a>&lt; <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt;double&gt;</a> &gt;&amp; minimum_maximum)
<a name="l01537"></a>01537 {
<a name="l01538"></a>01538    <span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> parameters_number = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#591e0e7ee4ae2c15d09e135652e30797" title="This method returns the number of parameters (biases and synaptic weights) in the...">count_parameters_number</a>();
<a name="l01539"></a>01539 
<a name="l01540"></a>01540    <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt;double&gt;</a> parameters(parameters_number);
<a name="l01541"></a>01541 
<a name="l01542"></a>01542    parameters.<a class="code" href="class_open_n_n_1_1_vector.html#ad3935a890aa294f7cef557a33c57db3" title="This method assigns a random value comprised between -1 and 1 to each element in...">initialize_uniform</a>(minimum_maximum[0], minimum_maximum[1]);
<a name="l01543"></a>01543 
<a name="l01544"></a>01544    <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#b15a55807eb7d574061178c7d701985d">set_parameters</a>(parameters);
<a name="l01545"></a>01545 }
<a name="l01546"></a>01546 
<a name="l01547"></a>01547 
<a name="l01548"></a>01548 <span class="comment">// void initialize_parameters_normal(void) method</span>
<a name="l01549"></a>01549 
<a name="l01552"></a>01552 
<a name="l01553"></a><a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#31b1a85548a8a80ca3f1c3f232d1c7c9">01553</a> <span class="keywordtype">void</span> <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#31b1a85548a8a80ca3f1c3f232d1c7c9">MultilayerPerceptron::initialize_parameters_normal</a>(<span class="keywordtype">void</span>)
<a name="l01554"></a>01554 {
<a name="l01555"></a>01555    <span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> parameters_number = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#591e0e7ee4ae2c15d09e135652e30797" title="This method returns the number of parameters (biases and synaptic weights) in the...">count_parameters_number</a>();
<a name="l01556"></a>01556 
<a name="l01557"></a>01557    <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt;double&gt;</a> parameters(parameters_number);
<a name="l01558"></a>01558 
<a name="l01559"></a>01559    parameters.<a class="code" href="class_open_n_n_1_1_vector.html#47595886933f54a6057fa27cc8523881">initialize_normal</a>();
<a name="l01560"></a>01560 
<a name="l01561"></a>01561    <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#b15a55807eb7d574061178c7d701985d">set_parameters</a>(parameters);
<a name="l01562"></a>01562 }
<a name="l01563"></a>01563 
<a name="l01564"></a>01564 
<a name="l01565"></a>01565 <span class="comment">// void initialize_parameters_normal(const double&amp;, const double&amp;) method</span>
<a name="l01566"></a>01566 
<a name="l01571"></a>01571 
<a name="l01572"></a><a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#16f91c3c3e6abb63a3fa916ff4c01d15">01572</a> <span class="keywordtype">void</span> <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#31b1a85548a8a80ca3f1c3f232d1c7c9">MultilayerPerceptron::initialize_parameters_normal</a>(<span class="keyword">const</span> <span class="keywordtype">double</span>&amp; mean, <span class="keyword">const</span> <span class="keywordtype">double</span>&amp; standard_deviation)
<a name="l01573"></a>01573 {
<a name="l01574"></a>01574    <span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> parameters_number = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#591e0e7ee4ae2c15d09e135652e30797" title="This method returns the number of parameters (biases and synaptic weights) in the...">count_parameters_number</a>();
<a name="l01575"></a>01575 
<a name="l01576"></a>01576    <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt;double&gt;</a> parameters(parameters_number);
<a name="l01577"></a>01577 
<a name="l01578"></a>01578    parameters.<a class="code" href="class_open_n_n_1_1_vector.html#47595886933f54a6057fa27cc8523881">initialize_normal</a>(mean, standard_deviation);
<a name="l01579"></a>01579 
<a name="l01580"></a>01580    <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#b15a55807eb7d574061178c7d701985d">set_parameters</a>(parameters);
<a name="l01581"></a>01581 }
<a name="l01582"></a>01582 
<a name="l01583"></a>01583 
<a name="l01584"></a>01584 <span class="comment">// void initialize_parameters_normal(const Vector&lt;double&gt;&amp;, const Vector&lt;double&gt;&amp;) method</span>
<a name="l01585"></a>01585 
<a name="l01590"></a>01590 
<a name="l01591"></a><a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#227c54cc0481d7e0b9b3e6fe61dec7d2">01591</a> <span class="keywordtype">void</span> <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#31b1a85548a8a80ca3f1c3f232d1c7c9">MultilayerPerceptron::initialize_parameters_normal</a>(<span class="keyword">const</span> <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt;double&gt;</a>&amp; mean, <span class="keyword">const</span> <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt;double&gt;</a>&amp; standard_deviation)
<a name="l01592"></a>01592 {
<a name="l01593"></a>01593    <span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> parameters_number = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#591e0e7ee4ae2c15d09e135652e30797" title="This method returns the number of parameters (biases and synaptic weights) in the...">count_parameters_number</a>();
<a name="l01594"></a>01594 
<a name="l01595"></a>01595    <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt;double&gt;</a> parameters(parameters_number);
<a name="l01596"></a>01596 
<a name="l01597"></a>01597    parameters.<a class="code" href="class_open_n_n_1_1_vector.html#47595886933f54a6057fa27cc8523881">initialize_normal</a>(mean, standard_deviation);
<a name="l01598"></a>01598 
<a name="l01599"></a>01599    <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#b15a55807eb7d574061178c7d701985d">set_parameters</a>(parameters);
<a name="l01600"></a>01600 }
<a name="l01601"></a>01601 
<a name="l01602"></a>01602 
<a name="l01603"></a>01603 <span class="comment">// void initialize_parameters_normal(const Vector&lt; Vector&lt;double&gt; &gt;&amp;) method</span>
<a name="l01604"></a>01604 
<a name="l01611"></a>01611 
<a name="l01612"></a><a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#f6ec69d1ac7bc82bcf7835cf75ce09a8">01612</a> <span class="keywordtype">void</span> <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#31b1a85548a8a80ca3f1c3f232d1c7c9">MultilayerPerceptron::initialize_parameters_normal</a>(<span class="keyword">const</span> <a class="code" href="class_open_n_n_1_1_vector.html">Vector</a>&lt; <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt;double&gt;</a> &gt;&amp; mean_standard_deviation)
<a name="l01613"></a>01613 {
<a name="l01614"></a>01614    <span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> parameters_number = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#591e0e7ee4ae2c15d09e135652e30797" title="This method returns the number of parameters (biases and synaptic weights) in the...">count_parameters_number</a>();
<a name="l01615"></a>01615 
<a name="l01616"></a>01616    <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt;double&gt;</a> parameters(parameters_number);
<a name="l01617"></a>01617 
<a name="l01618"></a>01618    parameters.<a class="code" href="class_open_n_n_1_1_vector.html#47595886933f54a6057fa27cc8523881">initialize_normal</a>(mean_standard_deviation[0], mean_standard_deviation[1]);
<a name="l01619"></a>01619 
<a name="l01620"></a>01620    <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#b15a55807eb7d574061178c7d701985d">set_parameters</a>(parameters);
<a name="l01621"></a>01621 }
<a name="l01622"></a>01622 
<a name="l01623"></a>01623 
<a name="l01624"></a>01624 <span class="comment">// void initialize_parameters(void) method</span>
<a name="l01625"></a>01625 
<a name="l01627"></a>01627 
<a name="l01628"></a><a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#af500529dae76e5a5096ee8adced1882">01628</a> <span class="keywordtype">void</span> <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#af500529dae76e5a5096ee8adced1882" title="This method initializes the parameters at random with values chosen from a normal...">MultilayerPerceptron::initialize_parameters</a>(<span class="keywordtype">void</span>)
<a name="l01629"></a>01629 {
<a name="l01630"></a>01630    <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#31b1a85548a8a80ca3f1c3f232d1c7c9">initialize_parameters_normal</a>();
<a name="l01631"></a>01631 }
<a name="l01632"></a>01632 
<a name="l01633"></a>01633 
<a name="l01634"></a>01634 <span class="comment">// double calculate_parameters_norm(void) const const method</span>
<a name="l01635"></a>01635 
<a name="l01637"></a>01637 
<a name="l01638"></a><a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#697e5dfa795052802a1c656d2ea6cca2">01638</a> <span class="keywordtype">double</span> <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#697e5dfa795052802a1c656d2ea6cca2" title="This method returns the norm of the vector of multilayer_perceptron_pointer parameters...">MultilayerPerceptron::calculate_parameters_norm</a>(<span class="keywordtype">void</span>)<span class="keyword"> const </span>
<a name="l01639"></a>01639 <span class="keyword"></span>{
<a name="l01640"></a>01640    <span class="keyword">const</span> <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt;double&gt;</a> parameters = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#598b7b498c5f6adf417f84abad92f9fc" title="This method returns the values of all the biases and synaptic weights in the multilayer...">arrange_parameters</a>();
<a name="l01641"></a>01641 
<a name="l01642"></a>01642    <span class="keyword">const</span> <span class="keywordtype">double</span> parameters_norm = parameters.<a class="code" href="class_open_n_n_1_1_vector.html#17c63b7346189c7337602b0aac5f529f" title="This element returns the vector norm.">calculate_norm</a>();
<a name="l01643"></a>01643 
<a name="l01644"></a>01644    <span class="keywordflow">return</span>(parameters_norm);
<a name="l01645"></a>01645 }
<a name="l01646"></a>01646 
<a name="l01647"></a>01647 
<a name="l01648"></a>01648 <span class="comment">// Vector&lt;double&gt; calculate_outputs(const Vector&lt;double&gt;&amp;) const method</span>
<a name="l01649"></a>01649 
<a name="l01653"></a>01653 
<a name="l01654"></a><a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#7d098a8bfd2a26b8bc51bf4e3de90c27">01654</a> <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt;double&gt;</a> <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#7d098a8bfd2a26b8bc51bf4e3de90c27">MultilayerPerceptron::calculate_outputs</a>(<span class="keyword">const</span> <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt;double&gt;</a>&amp; inputs)<span class="keyword"> const</span>
<a name="l01655"></a>01655 <span class="keyword"></span>{
<a name="l01656"></a>01656    <span class="comment">// Control sentence (if debug)</span>
<a name="l01657"></a>01657 
<a name="l01658"></a>01658 <span class="preprocessor">   #ifdef _DEBUG </span>
<a name="l01659"></a>01659 <span class="preprocessor"></span>
<a name="l01660"></a>01660    <span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> size = inputs.size();
<a name="l01661"></a>01661 
<a name="l01662"></a>01662    <span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> inputs_number = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#0998a82ea1845b0fd26872218b02b3f4" title="This method returns the number of inputs to the multilayer perceptron.">count_inputs_number</a>();
<a name="l01663"></a>01663 
<a name="l01664"></a>01664    <span class="keywordflow">if</span>(size != inputs_number) 
<a name="l01665"></a>01665    {
<a name="l01666"></a>01666       std::ostringstream buffer;
<a name="l01667"></a>01667 
<a name="l01668"></a>01668       buffer &lt;&lt; <span class="stringliteral">"OpenNN Exception: MultilayerPerceptron class.\n"</span>
<a name="l01669"></a>01669              &lt;&lt; <span class="stringliteral">"Vector&lt;double&gt; calculate_outputs(const Vector&lt;double&gt;&amp;) const method.\n"</span>
<a name="l01670"></a>01670              &lt;&lt; <span class="stringliteral">"Size of inputs ("</span> &lt;&lt; size &lt;&lt;<span class="stringliteral">") must be equal to number of inputs ("</span> &lt;&lt; inputs_number &lt;&lt; <span class="stringliteral">").\n"</span>;
<a name="l01671"></a>01671 
<a name="l01672"></a>01672           <span class="keywordflow">throw</span> std::logic_error(buffer.str());
<a name="l01673"></a>01673    }   
<a name="l01674"></a>01674    
<a name="l01675"></a>01675 <span class="preprocessor">   #endif</span>
<a name="l01676"></a>01676 <span class="preprocessor"></span>
<a name="l01677"></a>01677    <span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> layers_number = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#e5f41a6d170161f9b2896e95bb186423" title="This method returns the number of layers in the multilayer perceptron.">count_layers_number</a>();
<a name="l01678"></a>01678 
<a name="l01679"></a>01679    <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt;double&gt;</a> outputs;
<a name="l01680"></a>01680 
<a name="l01681"></a>01681    <span class="keywordflow">if</span>(layers_number == 0)
<a name="l01682"></a>01682    {
<a name="l01683"></a>01683       <span class="keywordflow">return</span>(outputs);   
<a name="l01684"></a>01684    }
<a name="l01685"></a>01685    <span class="keywordflow">else</span>
<a name="l01686"></a>01686    {
<a name="l01687"></a>01687       outputs = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#ea970635dd856cb0f9acdf458177312b">layers</a>[0].calculate_outputs(inputs);
<a name="l01688"></a>01688 
<a name="l01689"></a>01689       <span class="keywordflow">for</span>(<span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> i = 1; i &lt; layers_number; i++)
<a name="l01690"></a>01690       {
<a name="l01691"></a>01691          outputs = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#ea970635dd856cb0f9acdf458177312b">layers</a>[i].calculate_outputs(outputs);
<a name="l01692"></a>01692       }
<a name="l01693"></a>01693    }
<a name="l01694"></a>01694 
<a name="l01695"></a>01695    <span class="keywordflow">return</span>(outputs);
<a name="l01696"></a>01696 }
<a name="l01697"></a>01697 
<a name="l01698"></a>01698 
<a name="l01699"></a>01699 <span class="comment">// Matrix&lt;double&gt; calculate_Jacobian(const Vector&lt;double&gt;&amp;) const method</span>
<a name="l01700"></a>01700 
<a name="l01704"></a>01704 
<a name="l01705"></a><a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#b1ee0f3ccc90b139c73613032aa49c02">01705</a> <a class="code" href="class_open_n_n_1_1_matrix.html">Matrix&lt;double&gt;</a> <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#b1ee0f3ccc90b139c73613032aa49c02">MultilayerPerceptron::calculate_Jacobian</a>(<span class="keyword">const</span> <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt;double&gt;</a>&amp; inputs)<span class="keyword"> const</span>
<a name="l01706"></a>01706 <span class="keyword"></span>{
<a name="l01707"></a>01707 <span class="preprocessor">   #ifdef _DEBUG </span>
<a name="l01708"></a>01708 <span class="preprocessor"></span>
<a name="l01709"></a>01709    <span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> size = inputs.size();
<a name="l01710"></a>01710 
<a name="l01711"></a>01711    <span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> inputs_number = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#0998a82ea1845b0fd26872218b02b3f4" title="This method returns the number of inputs to the multilayer perceptron.">count_inputs_number</a>();
<a name="l01712"></a>01712 
<a name="l01713"></a>01713    <span class="keywordflow">if</span>(size != inputs_number)
<a name="l01714"></a>01714    {
<a name="l01715"></a>01715       std::ostringstream buffer;
<a name="l01716"></a>01716 
<a name="l01717"></a>01717       buffer &lt;&lt; <span class="stringliteral">"OpenNN Exception: MultilayerPerceptron class.\n"</span>
<a name="l01718"></a>01718              &lt;&lt; <span class="stringliteral">"Matrix&lt;double&gt; calculate_Jacobian(const Vector&lt;double&gt;&amp;) const method.\n"</span>
<a name="l01719"></a>01719              &lt;&lt; <span class="stringliteral">"Size must be equal to number of inputs.\n"</span>;
<a name="l01720"></a>01720 
<a name="l01721"></a>01721           <span class="keywordflow">throw</span> std::logic_error(buffer.str());
<a name="l01722"></a>01722    }
<a name="l01723"></a>01723 
<a name="l01724"></a>01724 <span class="preprocessor">   #endif</span>
<a name="l01725"></a>01725 <span class="preprocessor"></span>
<a name="l01726"></a>01726    <span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> layers_number = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#e5f41a6d170161f9b2896e95bb186423" title="This method returns the number of layers in the multilayer perceptron.">count_layers_number</a>();
<a name="l01727"></a>01727 
<a name="l01728"></a>01728    <span class="keywordflow">if</span>(layers_number == 0)
<a name="l01729"></a>01729    {
<a name="l01730"></a>01730       <a class="code" href="class_open_n_n_1_1_matrix.html">Matrix&lt;double&gt;</a> Jacobian;
<a name="l01731"></a>01731 
<a name="l01732"></a>01732       <span class="keywordflow">return</span>(Jacobian);
<a name="l01733"></a>01733    }
<a name="l01734"></a>01734    <span class="keywordflow">else</span>
<a name="l01735"></a>01735    {   
<a name="l01736"></a>01736       <span class="keyword">const</span> <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt; Matrix&lt;double&gt;</a> &gt; layers_Jacobian = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#53f1a4eb6b4349c26dfeb874113f37d0">calculate_layers_Jacobian</a>(inputs);
<a name="l01737"></a>01737 
<a name="l01738"></a>01738       <a class="code" href="class_open_n_n_1_1_matrix.html">Matrix&lt;double&gt;</a> Jacobian = layers_Jacobian[layers_number-1];
<a name="l01739"></a>01739 
<a name="l01740"></a>01740       <span class="keywordflow">for</span>(<span class="keywordtype">int</span> i = layers_number-2; i &gt; -1; i--)
<a name="l01741"></a>01741       {
<a name="l01742"></a>01742          Jacobian = Jacobian.<a class="code" href="class_open_n_n_1_1_matrix.html#2defd189fbc758aec574c5ef6d28d835">dot</a>(layers_Jacobian[i]);   
<a name="l01743"></a>01743       }
<a name="l01744"></a>01744 
<a name="l01745"></a>01745       <span class="keywordflow">return</span>(Jacobian);
<a name="l01746"></a>01746    }
<a name="l01747"></a>01747 }
<a name="l01748"></a>01748 
<a name="l01749"></a>01749 
<a name="l01750"></a>01750 <span class="comment">// Vector&lt; Matrix&lt;double&gt; &gt; calculate_Hessian_form(const Vector&lt;double&gt;&amp;) const</span>
<a name="l01751"></a>01751 
<a name="l01755"></a>01755 
<a name="l01756"></a><a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#75683af2d71210a3905d1d529eda6e52">01756</a> <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt; Matrix&lt;double&gt;</a> &gt; <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#75683af2d71210a3905d1d529eda6e52">MultilayerPerceptron::calculate_Hessian_form</a>(<span class="keyword">const</span> <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt;double&gt;</a>&amp; inputs)<span class="keyword"> const</span>
<a name="l01757"></a>01757 <span class="keyword"></span>{   
<a name="l01758"></a>01758 <span class="preprocessor">   #ifdef _DEBUG </span>
<a name="l01759"></a>01759 <span class="preprocessor"></span>
<a name="l01760"></a>01760    <span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> size = inputs.size();
<a name="l01761"></a>01761 
<a name="l01762"></a>01762    <span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> inputs_number = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#0998a82ea1845b0fd26872218b02b3f4" title="This method returns the number of inputs to the multilayer perceptron.">count_inputs_number</a>();
<a name="l01763"></a>01763 
<a name="l01764"></a>01764    <span class="keywordflow">if</span>(size != inputs_number)
<a name="l01765"></a>01765    {
<a name="l01766"></a>01766       std::ostringstream buffer;
<a name="l01767"></a>01767 
<a name="l01768"></a>01768       buffer &lt;&lt; <span class="stringliteral">"OpenNN Exception: MultilayerPerceptron class.\n"</span>
<a name="l01769"></a>01769              &lt;&lt; <span class="stringliteral">"Vector&lt; Matrix&lt;double&gt; &gt; calculate_Hessian_form(const Vector&lt;double&gt;&amp;) const method.\n"</span>
<a name="l01770"></a>01770              &lt;&lt; <span class="stringliteral">"Size must be equal to number of inputs.\n"</span>;
<a name="l01771"></a>01771 
<a name="l01772"></a>01772           <span class="keywordflow">throw</span> std::logic_error(buffer.str());
<a name="l01773"></a>01773    }
<a name="l01774"></a>01774 
<a name="l01775"></a>01775 <span class="preprocessor">   #endif</span>
<a name="l01776"></a>01776 <span class="preprocessor"></span>
<a name="l01777"></a>01777    <span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> layers_number = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#e5f41a6d170161f9b2896e95bb186423" title="This method returns the number of layers in the multilayer perceptron.">count_layers_number</a>();
<a name="l01778"></a>01778    <span class="keyword">const</span> <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt;unsigned int&gt;</a> layers_size = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#bac4febc8f59639eadd9d8b896148f5e" title="This method returns a vector with the size of each layer.">arrange_layers_perceptrons_numbers</a>();
<a name="l01779"></a>01779    <span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> outputs_number = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#d73e53afdf816e7df8ae4cb450ea5be7" title="This method returns the number of outputs neurons in the multilayer perceptron.">count_outputs_number</a>();
<a name="l01780"></a>01780 
<a name="l01781"></a>01781    <span class="comment">// Calculate forward propagation of outputs, Jacobian and Hessian form</span>
<a name="l01782"></a>01782 
<a name="l01783"></a>01783    <span class="keyword">const</span> <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt; Matrix&lt;double&gt;</a> &gt; layers_Jacobian = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#53f1a4eb6b4349c26dfeb874113f37d0">calculate_layers_Jacobian</a>(inputs);
<a name="l01784"></a>01784 
<a name="l01785"></a>01785    <span class="keyword">const</span> <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt; Vector&lt; Matrix&lt;double&gt;</a> &gt; &gt; layers_Hessian_form = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#cd80d80291d14b9e677da6fcbeefb674">calculate_layers_Hessian_form</a>(inputs);
<a name="l01786"></a>01786 
<a name="l01787"></a>01787    <span class="comment">// Calculate multilayer_perceptron_pointer Hessian form</span>
<a name="l01788"></a>01788 
<a name="l01789"></a>01789    <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt; Matrix&lt;double&gt;</a> &gt; Hessian_form = layers_Hessian_form[layers_number-1];
<a name="l01790"></a>01790    <a class="code" href="class_open_n_n_1_1_matrix.html">Matrix&lt;double&gt;</a> Jacobian = layers_Jacobian[layers_number-1];
<a name="l01791"></a>01791 
<a name="l01792"></a>01792    <span class="keywordflow">for</span>(<span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> layer_index = layers_number-2; layer_index != 0; layer_index--)
<a name="l01793"></a>01793    {
<a name="l01794"></a>01794       <span class="keywordflow">for</span>(<span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> output_index = 0; output_index &lt; outputs_number; output_index++)
<a name="l01795"></a>01795       {
<a name="l01796"></a>01796          Hessian_form[output_index] = (layers_Jacobian[layer_index].calculate_transpose()).dot(Hessian_form[output_index]).<a class="code" href="class_open_n_n_1_1_vector.html#0af2b14634f3dc1cea8ce692f77eb94e">dot</a>(layers_Jacobian[layer_index]);
<a name="l01797"></a>01797 
<a name="l01798"></a>01798          <span class="keywordflow">for</span>(<span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> neuron_index = 0; neuron_index &lt; layers_size[layer_index]; neuron_index++)
<a name="l01799"></a>01799              {
<a name="l01800"></a>01800             Hessian_form[output_index] += layers_Hessian_form[layer_index][neuron_index]*Jacobian[output_index][neuron_index]; 
<a name="l01801"></a>01801              }
<a name="l01802"></a>01802           }
<a name="l01803"></a>01803 
<a name="l01804"></a>01804      Jacobian = Jacobian.<a class="code" href="class_open_n_n_1_1_matrix.html#2defd189fbc758aec574c5ef6d28d835">dot</a>(layers_Jacobian[layer_index]);   
<a name="l01805"></a>01805    }
<a name="l01806"></a>01806 
<a name="l01807"></a>01807 <span class="comment">//   Matrix&lt;double&gt; hidden_layer_Jacobian = layers_Jacobian[0];</span>
<a name="l01808"></a>01808 <span class="comment">//   Matrix&lt;double&gt; output_layer_Jacobian = layers_Jacobian[1];</span>
<a name="l01809"></a>01809 
<a name="l01810"></a>01810 <span class="comment">//   Vector&lt; Matrix&lt;double&gt; &gt; hidden_layer_Hessian_form = layers_Hessian_form[0];</span>
<a name="l01811"></a>01811 <span class="comment">//   Vector&lt; Matrix&lt;double&gt; &gt; output_layer_Hessian_form = layers_Hessian_form[1];</span>
<a name="l01812"></a>01812 
<a name="l01813"></a>01813 <span class="comment">//   Vector&lt; Matrix&lt;double&gt; &gt; Hessian_form(outputs_number);</span>
<a name="l01814"></a>01814 
<a name="l01815"></a>01815 <span class="comment">//   for(unsigned int output_index = 0; output_index &lt; outputs_number; output_index++)</span>
<a name="l01816"></a>01816 <span class="comment">//   {</span>
<a name="l01817"></a>01817 <span class="comment">//      Hessian_form[output_index] = (hidden_layer_Jacobian.calculate_transpose()).dot(output_layer_Hessian_form[output_index]).dot(hidden_layer_Jacobian);</span>
<a name="l01818"></a>01818 
<a name="l01819"></a>01819 <span class="comment">//      for(unsigned int neuron_index = 0; neuron_index &lt; layers_size[0]; neuron_index++)</span>
<a name="l01820"></a>01820 <span class="comment">//      {</span>
<a name="l01821"></a>01821 <span class="comment">//         Hessian_form[output_index] += hidden_layer_Hessian_form[neuron_index]*output_layer_Jacobian[output_index][neuron_index]; </span>
<a name="l01822"></a>01822 <span class="comment">//        }</span>
<a name="l01823"></a>01823 <span class="comment">//   }</span>
<a name="l01824"></a>01824 
<a name="l01825"></a>01825    <span class="keywordflow">return</span>(Hessian_form);
<a name="l01826"></a>01826 }
<a name="l01827"></a>01827 
<a name="l01828"></a>01828 
<a name="l01829"></a>01829 <span class="comment">// Vector&lt;double&gt; calculate_layer_combination_combination(const unsigned int&amp;, const Vector&lt;double&gt;&amp;) const method</span>
<a name="l01830"></a>01830 
<a name="l01834"></a>01834 
<a name="l01835"></a><a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#3018270faf19b2ebbf2991bd6de0764e">01835</a> <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt;double&gt;</a> <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#3018270faf19b2ebbf2991bd6de0764e">MultilayerPerceptron::calculate_layer_combination_combination</a>(<span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span>&amp; layer_index, <span class="keyword">const</span> <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt;double&gt;</a>&amp; previous_layer_combination)<span class="keyword"> const</span>
<a name="l01836"></a>01836 <span class="keyword"></span>{
<a name="l01837"></a>01837    <span class="comment">// Control sentence (if debug)</span>
<a name="l01838"></a>01838 
<a name="l01839"></a>01839 <span class="preprocessor">   #ifdef _DEBUG </span>
<a name="l01840"></a>01840 <span class="preprocessor"></span>
<a name="l01841"></a>01841    <span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> layers_number = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#e5f41a6d170161f9b2896e95bb186423" title="This method returns the number of layers in the multilayer perceptron.">count_layers_number</a>();
<a name="l01842"></a>01842 
<a name="l01843"></a>01843    <span class="keywordflow">if</span>(layer_index == 0)
<a name="l01844"></a>01844    {
<a name="l01845"></a>01845       std::ostringstream buffer;
<a name="l01846"></a>01846 
<a name="l01847"></a>01847       buffer &lt;&lt; <span class="stringliteral">"OpenNN Exception: MultilayerPerceptron class.\n"</span>
<a name="l01848"></a>01848              &lt;&lt; <span class="stringliteral">"Matrix&lt;double&gt; calculate_layer_combination_combination(const unsigned int&amp;, const Vector&lt;double&gt;&amp;) const.\n"</span>
<a name="l01849"></a>01849              &lt;&lt; <span class="stringliteral">"Index of layer must be greater than zero.\n"</span>;
<a name="l01850"></a>01850 
<a name="l01851"></a>01851           <span class="keywordflow">throw</span> std::logic_error(buffer.str());
<a name="l01852"></a>01852    }
<a name="l01853"></a>01853    <span class="keywordflow">else</span> <span class="keywordflow">if</span>(layer_index &gt;= layers_number)
<a name="l01854"></a>01854    {
<a name="l01855"></a>01855       std::ostringstream buffer;
<a name="l01856"></a>01856 
<a name="l01857"></a>01857       buffer &lt;&lt; <span class="stringliteral">"OpenNN Exception: MultilayerPerceptron class.\n"</span>
<a name="l01858"></a>01858              &lt;&lt; <span class="stringliteral">"Matrix&lt;double&gt; calculate_layer_combination_combination(const unsigned int&amp;, const Vector&lt;double&gt;&amp;) const.\n"</span>
<a name="l01859"></a>01859              &lt;&lt; <span class="stringliteral">"Index of layer must be less than numnber of layers.\n"</span>;
<a name="l01860"></a>01860 
<a name="l01861"></a>01861           <span class="keywordflow">throw</span> std::logic_error(buffer.str());
<a name="l01862"></a>01862    }
<a name="l01863"></a>01863 
<a name="l01864"></a>01864    <span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> size = previous_layer_combination.size();
<a name="l01865"></a>01865    <span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> previous_layer_perceptrons_number = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#ea970635dd856cb0f9acdf458177312b">layers</a>[layer_index-1].count_perceptrons_number();
<a name="l01866"></a>01866 
<a name="l01867"></a>01867    <span class="keywordflow">if</span>(size != previous_layer_perceptrons_number)
<a name="l01868"></a>01868    {
<a name="l01869"></a>01869       std::ostringstream buffer;
<a name="l01870"></a>01870 
<a name="l01871"></a>01871       buffer &lt;&lt; <span class="stringliteral">"OpenNN Exception: MultilayerPerceptron class.\n"</span>
<a name="l01872"></a>01872              &lt;&lt; <span class="stringliteral">"Matrix&lt;double&gt; calculate_layer_combination_combination(const unsigned int&amp;, const Vector&lt;double&gt;&amp;) const.\n"</span>
<a name="l01873"></a>01873              &lt;&lt; <span class="stringliteral">"Size must be equal to size of previous layer.\n"</span>;
<a name="l01874"></a>01874 
<a name="l01875"></a>01875           <span class="keywordflow">throw</span> std::logic_error(buffer.str());
<a name="l01876"></a>01876    }
<a name="l01877"></a>01877 
<a name="l01878"></a>01878 <span class="preprocessor">   #endif</span>
<a name="l01879"></a>01879 <span class="preprocessor"></span>
<a name="l01880"></a>01880    <span class="comment">// Calculate combination to layer</span>
<a name="l01881"></a>01881 
<a name="l01882"></a>01882    <span class="keyword">const</span> <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt;double&gt;</a> previous_layer_activation = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#ea970635dd856cb0f9acdf458177312b">layers</a>[layer_index-1].calculate_activation(previous_layer_combination);
<a name="l01883"></a>01883 
<a name="l01884"></a>01884    <span class="keyword">const</span> <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt;double&gt;</a> layer_combination_combination = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#ea970635dd856cb0f9acdf458177312b">layers</a>[layer_index].calculate_combination(previous_layer_activation);
<a name="l01885"></a>01885 
<a name="l01886"></a>01886    <span class="keywordflow">return</span>(layer_combination_combination);
<a name="l01887"></a>01887 }
<a name="l01888"></a>01888 
<a name="l01889"></a>01889 
<a name="l01890"></a>01890 <span class="comment">// Matrix&lt;double&gt; calculate_layer_combination_combination_Jacobian(const unsigned int&amp;, const Vector&lt;double&gt;&amp;) const method</span>
<a name="l01891"></a>01891 
<a name="l01897"></a>01897 
<a name="l01898"></a><a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#740b27401c566b406a85379e6731bb35">01898</a> <a class="code" href="class_open_n_n_1_1_matrix.html">Matrix&lt;double&gt;</a> <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#740b27401c566b406a85379e6731bb35">MultilayerPerceptron::calculate_layer_combination_combination_Jacobian</a>(<span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span>&amp; layer_index, <span class="keyword">const</span> <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt;double&gt;</a>&amp; previous_layer_activation_derivative)<span class="keyword"> const   </span>
<a name="l01899"></a>01899 <span class="keyword"></span>{
<a name="l01900"></a>01900    <span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> previous_layer_perceptrons_number = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#ea970635dd856cb0f9acdf458177312b">layers</a>[layer_index-1].count_perceptrons_number();
<a name="l01901"></a>01901 
<a name="l01902"></a>01902    <span class="comment">// Control sentence (if debug)</span>
<a name="l01903"></a>01903 
<a name="l01904"></a>01904 <span class="preprocessor">   #ifdef _DEBUG </span>
<a name="l01905"></a>01905 <span class="preprocessor"></span>
<a name="l01906"></a>01906    <span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> layers_number = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#e5f41a6d170161f9b2896e95bb186423" title="This method returns the number of layers in the multilayer perceptron.">count_layers_number</a>();
<a name="l01907"></a>01907 
<a name="l01908"></a>01908    <span class="keywordflow">if</span>(layer_index == 0)
<a name="l01909"></a>01909    {
<a name="l01910"></a>01910       std::ostringstream buffer;
<a name="l01911"></a>01911 
<a name="l01912"></a>01912       buffer &lt;&lt; <span class="stringliteral">"OpenNN Exception: MultilayerPerceptron class.\n"</span>
<a name="l01913"></a>01913              &lt;&lt; <span class="stringliteral">"Matrix&lt;double&gt; calculate_layer_combination_combination_Jacobian(const unsigned int&amp;, const Vector&lt;double&gt;&amp;) const.\n"</span>
<a name="l01914"></a>01914              &lt;&lt; <span class="stringliteral">"Index of layer must be greater than zero.\n"</span>;
<a name="l01915"></a>01915 
<a name="l01916"></a>01916           <span class="keywordflow">throw</span> std::logic_error(buffer.str());
<a name="l01917"></a>01917    }
<a name="l01918"></a>01918    <span class="keywordflow">else</span> <span class="keywordflow">if</span>(layer_index &gt;= layers_number)
<a name="l01919"></a>01919    {
<a name="l01920"></a>01920       std::ostringstream buffer;
<a name="l01921"></a>01921 
<a name="l01922"></a>01922       buffer &lt;&lt; <span class="stringliteral">"OpenNN Exception: MultilayerPerceptron class.\n"</span>
<a name="l01923"></a>01923              &lt;&lt; <span class="stringliteral">"Matrix&lt;double&gt; calculate_layer_combination_combination_Jacobian(const unsigned int&amp;, const Vector&lt;double&gt;&amp;) const.\n"</span>
<a name="l01924"></a>01924              &lt;&lt; <span class="stringliteral">"Index of layer must be less than numnber of layers.\n"</span>;
<a name="l01925"></a>01925 
<a name="l01926"></a>01926           <span class="keywordflow">throw</span> std::logic_error(buffer.str());
<a name="l01927"></a>01927    }
<a name="l01928"></a>01928 
<a name="l01929"></a>01929    <span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> size = previous_layer_activation_derivative.size();
<a name="l01930"></a>01930 
<a name="l01931"></a>01931    <span class="keywordflow">if</span>(size != previous_layer_perceptrons_number)
<a name="l01932"></a>01932    {
<a name="l01933"></a>01933       std::ostringstream buffer;
<a name="l01934"></a>01934 
<a name="l01935"></a>01935       buffer &lt;&lt; <span class="stringliteral">"OpenNN Exception: MultilayerPerceptron class.\n"</span>
<a name="l01936"></a>01936              &lt;&lt; <span class="stringliteral">"Matrix&lt;double&gt; calculate_layer_combination_combination_Jacobian(const unsigned int&amp;, const Vector&lt;double&gt;&amp;).\n"</span>
<a name="l01937"></a>01937              &lt;&lt; <span class="stringliteral">"Size of activation derivative must be equal to size of previous layer.\n"</span>;
<a name="l01938"></a>01938 
<a name="l01939"></a>01939           <span class="keywordflow">throw</span> std::logic_error(buffer.str());
<a name="l01940"></a>01940    }
<a name="l01941"></a>01941 
<a name="l01942"></a>01942 <span class="preprocessor">   #endif</span>
<a name="l01943"></a>01943 <span class="preprocessor"></span>
<a name="l01944"></a>01944    <span class="keyword">const</span> <a class="code" href="class_open_n_n_1_1_matrix.html">Matrix&lt;double&gt;</a> layer_synaptic_weights = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#ea970635dd856cb0f9acdf458177312b">layers</a>[layer_index].arrange_synaptic_weights();
<a name="l01945"></a>01945 
<a name="l01946"></a>01946    <a class="code" href="class_open_n_n_1_1_matrix.html">Matrix&lt;double&gt;</a> previous_layer_activation_Jacobian(previous_layer_perceptrons_number, previous_layer_perceptrons_number, 0.0);
<a name="l01947"></a>01947    previous_layer_activation_Jacobian.<a class="code" href="class_open_n_n_1_1_matrix.html#10d341e72a813e49ed783b11e03c435a">set_diagonal</a>(previous_layer_activation_derivative);
<a name="l01948"></a>01948 
<a name="l01949"></a>01949    <span class="keywordflow">return</span>(layer_synaptic_weights.<a class="code" href="class_open_n_n_1_1_matrix.html#2defd189fbc758aec574c5ef6d28d835">dot</a>(previous_layer_activation_Jacobian));
<a name="l01950"></a>01950 }
<a name="l01951"></a>01951 
<a name="l01952"></a>01952 
<a name="l01953"></a>01953 <span class="comment">// Vector&lt;double&gt; calculate_interlayer_combination_combination(const unsigned int&amp;, const unsigned int&amp;, const Vector&lt;double&gt;&amp;) const method</span>
<a name="l01954"></a>01954 
<a name="l01959"></a>01959 
<a name="l01960"></a><a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#aa881a7c4f25fd25d125a81ebb2755bd">01960</a> <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt;double&gt;</a> <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#aa881a7c4f25fd25d125a81ebb2755bd">MultilayerPerceptron::calculate_interlayer_combination_combination</a>(<span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span>&amp; domain_layer_index, <span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span>&amp; image_layer_index, <span class="keyword">const</span> <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt;double&gt;</a>&amp; domain_layer_combination)<span class="keyword"> const</span>
<a name="l01961"></a>01961 <span class="keyword"></span>{
<a name="l01962"></a>01962    <span class="keywordflow">if</span>(domain_layer_index &gt; image_layer_index)
<a name="l01963"></a>01963    {
<a name="l01964"></a>01964       std::ostringstream buffer;
<a name="l01965"></a>01965 
<a name="l01966"></a>01966       buffer &lt;&lt; <span class="stringliteral">"OpenNN Exception: MultilayerPerceptron class.\n"</span>
<a name="l01967"></a>01967              &lt;&lt; <span class="stringliteral">"Vector&lt;double&gt; calculate_interlayer_combination_combination(const unsigned int&amp;, const unsigned int&amp;, const Vector&lt;double&gt;&amp;) const method.\n"</span>
<a name="l01968"></a>01968              &lt;&lt; <span class="stringliteral">"Index of domain layer must be less or equal than index of image layer.\n"</span>;
<a name="l01969"></a>01969 
<a name="l01970"></a>01970           <span class="keywordflow">throw</span> std::logic_error(buffer.str());
<a name="l01971"></a>01971    }
<a name="l01972"></a>01972 
<a name="l01973"></a>01973    <span class="keywordflow">if</span>(domain_layer_index == image_layer_index)
<a name="l01974"></a>01974    {
<a name="l01975"></a>01975       <span class="keywordflow">return</span>(domain_layer_combination);
<a name="l01976"></a>01976    }
<a name="l01977"></a>01977    <span class="keywordflow">else</span>
<a name="l01978"></a>01978    {
<a name="l01979"></a>01979       <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt;double&gt;</a> interlayer_combination_combination(domain_layer_combination);     
<a name="l01980"></a>01980 
<a name="l01981"></a>01981       <span class="keywordflow">for</span>(<span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> i = domain_layer_index+1; i &lt;= image_layer_index; i++)
<a name="l01982"></a>01982       {
<a name="l01983"></a>01983          interlayer_combination_combination = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#3018270faf19b2ebbf2991bd6de0764e">calculate_layer_combination_combination</a>(i, interlayer_combination_combination);
<a name="l01984"></a>01984       }
<a name="l01985"></a>01985 
<a name="l01986"></a>01986       <span class="keywordflow">return</span>(interlayer_combination_combination); 
<a name="l01987"></a>01987    }
<a name="l01988"></a>01988 }
<a name="l01989"></a>01989 
<a name="l01990"></a>01990 
<a name="l01991"></a>01991 <span class="comment">// Matrix&lt;double&gt; calculate_interlayer_combination_combination_Jacobian(const unsigned int&amp;, const unsigned int&amp;, const Vector&lt;double&gt;&amp;) const method</span>
<a name="l01992"></a>01992 
<a name="l01998"></a>01998 
<a name="l01999"></a><a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#c6e766fbd7845f7d47b83da12705d866">01999</a> <a class="code" href="class_open_n_n_1_1_matrix.html">Matrix&lt;double&gt;</a> <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#c6e766fbd7845f7d47b83da12705d866">MultilayerPerceptron::calculate_interlayer_combination_combination_Jacobian</a>(<span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span>&amp; domain_layer_index, <span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span>&amp; image_layer_index, <span class="keyword">const</span> <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt;double&gt;</a>&amp; domain_layer_combination)<span class="keyword"> const</span>
<a name="l02000"></a>02000 <span class="keyword"></span>{
<a name="l02001"></a>02001    <a class="code" href="class_open_n_n_1_1_matrix.html">Matrix&lt;double&gt;</a> interlayer_combination_combination_Jacobian;
<a name="l02002"></a>02002 
<a name="l02003"></a>02003    <span class="keywordflow">if</span>(domain_layer_index &lt; image_layer_index)
<a name="l02004"></a>02004    {
<a name="l02005"></a>02005       <span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> size = image_layer_index-domain_layer_index;
<a name="l02006"></a>02006 
<a name="l02007"></a>02007       <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt; Vector&lt;double&gt;</a> &gt; layers_combination_combination(size);
<a name="l02008"></a>02008       <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt; Matrix&lt;double&gt;</a> &gt; layers_combination_combination_Jacobian(size);
<a name="l02009"></a>02009 
<a name="l02010"></a>02010       layers_combination_combination[0] = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#3018270faf19b2ebbf2991bd6de0764e">calculate_layer_combination_combination</a>(domain_layer_index+1, domain_layer_combination);      
<a name="l02011"></a>02011       layers_combination_combination_Jacobian[0] = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#740b27401c566b406a85379e6731bb35">calculate_layer_combination_combination_Jacobian</a>(domain_layer_index+1, <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#ea970635dd856cb0f9acdf458177312b">layers</a>[domain_layer_index].calculate_activation_derivative(domain_layer_combination));
<a name="l02012"></a>02012 
<a name="l02013"></a>02013       <span class="keywordflow">for</span>(<span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> i = 1; i &lt; size; i++)
<a name="l02014"></a>02014       {
<a name="l02015"></a>02015          layers_combination_combination[i] = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#3018270faf19b2ebbf2991bd6de0764e">calculate_layer_combination_combination</a>(domain_layer_index+i+1, layers_combination_combination[i-1]);
<a name="l02016"></a>02016 
<a name="l02017"></a>02017          layers_combination_combination_Jacobian[i] = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#740b27401c566b406a85379e6731bb35">calculate_layer_combination_combination_Jacobian</a>(domain_layer_index+i+1, layers_combination_combination[i-1]); 
<a name="l02018"></a>02018       }
<a name="l02019"></a>02019 
<a name="l02020"></a>02020       interlayer_combination_combination_Jacobian = layers_combination_combination_Jacobian[size-1];
<a name="l02021"></a>02021 
<a name="l02022"></a>02022       <span class="keywordflow">for</span>(<span class="keywordtype">int</span> i = size-2; i &gt; -1; i--)
<a name="l02023"></a>02023       {
<a name="l02024"></a>02024          interlayer_combination_combination_Jacobian = interlayer_combination_combination_Jacobian.<a class="code" href="class_open_n_n_1_1_matrix.html#2defd189fbc758aec574c5ef6d28d835">dot</a>(layers_combination_combination_Jacobian[i]);   
<a name="l02025"></a>02025       }
<a name="l02026"></a>02026    }
<a name="l02027"></a>02027    <span class="keywordflow">else</span> <span class="keywordflow">if</span>(domain_layer_index == image_layer_index)
<a name="l02028"></a>02028    {
<a name="l02029"></a>02029       <span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> image_layer_perceptrons_number = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#ea970635dd856cb0f9acdf458177312b">layers</a>[image_layer_index].count_perceptrons_number();
<a name="l02030"></a>02030 
<a name="l02031"></a>02031       interlayer_combination_combination_Jacobian.<a class="code" href="class_open_n_n_1_1_matrix.html#50d2298c61ed7a0a0437fc9093140b20">set_identity</a>(image_layer_perceptrons_number);
<a name="l02032"></a>02032    }
<a name="l02033"></a>02033    <span class="keywordflow">else</span>
<a name="l02034"></a>02034    {
<a name="l02035"></a>02035       <span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> image_layer_perceptrons_number = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#ea970635dd856cb0f9acdf458177312b">layers</a>[image_layer_index].count_perceptrons_number();
<a name="l02036"></a>02036       <span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> domain_layer_perceptrons_number = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#ea970635dd856cb0f9acdf458177312b">layers</a>[domain_layer_index].count_perceptrons_number();
<a name="l02037"></a>02037 
<a name="l02038"></a>02038       interlayer_combination_combination_Jacobian.<a class="code" href="class_open_n_n_1_1_matrix.html#2f3b762afad2ac1274da1aea2ce2852c" title="This method set the numbers of rows and columns of the matrix to zero.">set</a>(image_layer_perceptrons_number, domain_layer_perceptrons_number, 0.0);      
<a name="l02039"></a>02039    }
<a name="l02040"></a>02040 
<a name="l02041"></a>02041    <span class="keywordflow">return</span>(interlayer_combination_combination_Jacobian); 
<a name="l02042"></a>02042 }
<a name="l02043"></a>02043 
<a name="l02044"></a>02044 
<a name="l02045"></a>02045 <span class="comment">// Vector&lt;double&gt; calculate_output_layer_combination(const unsigned int&amp;, const Vector&lt;double&gt;&amp;) const method</span>
<a name="l02046"></a>02046 
<a name="l02050"></a>02050 
<a name="l02051"></a><a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#0dc13cc51880a33ef55923c06e4f2a38">02051</a> <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt;double&gt;</a> <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#0dc13cc51880a33ef55923c06e4f2a38">MultilayerPerceptron::calculate_output_layer_combination</a>(<span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span>&amp; layer_index, <span class="keyword">const</span> <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt;double&gt;</a>&amp; layer_combinations)<span class="keyword"> const</span>
<a name="l02052"></a>02052 <span class="keyword"></span>{
<a name="l02053"></a>02053    <span class="comment">// Control sentence (if debug)</span>
<a name="l02054"></a>02054 
<a name="l02055"></a>02055 <span class="preprocessor">   #ifdef _DEBUG </span>
<a name="l02056"></a>02056 <span class="preprocessor"></span>
<a name="l02057"></a>02057    <span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> size = layer_combinations.size();
<a name="l02058"></a>02058 
<a name="l02059"></a>02059    <span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> layer_perceptrons_number = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#ea970635dd856cb0f9acdf458177312b">layers</a>[layer_index].count_perceptrons_number();
<a name="l02060"></a>02060 
<a name="l02061"></a>02061    <span class="keywordflow">if</span>(size != layer_perceptrons_number) 
<a name="l02062"></a>02062    {
<a name="l02063"></a>02063       std::ostringstream buffer;
<a name="l02064"></a>02064 
<a name="l02065"></a>02065       buffer &lt;&lt; <span class="stringliteral">"OpenNN Exception: MultilayerPerceptron class.\n"</span>
<a name="l02066"></a>02066              &lt;&lt; <span class="stringliteral">"Vector&lt;double&gt; calculate_output_layer_combination(const unsigned int&amp;, const Vector&lt;double&gt;&amp;) const method.\n"</span>
<a name="l02067"></a>02067              &lt;&lt; <span class="stringliteral">"Size must be equal to layer size.\n"</span>;
<a name="l02068"></a>02068 
<a name="l02069"></a>02069           <span class="keywordflow">throw</span> std::logic_error(buffer.str());
<a name="l02070"></a>02070    }   
<a name="l02071"></a>02071    
<a name="l02072"></a>02072 <span class="preprocessor">   #endif</span>
<a name="l02073"></a>02073 <span class="preprocessor"></span>
<a name="l02074"></a>02074    <span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> layers_number = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#e5f41a6d170161f9b2896e95bb186423" title="This method returns the number of layers in the multilayer perceptron.">count_layers_number</a>();
<a name="l02075"></a>02075 
<a name="l02076"></a>02076    <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt;double&gt;</a> outputs = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#ea970635dd856cb0f9acdf458177312b">layers</a>[layer_index].calculate_activation(layer_combinations);
<a name="l02077"></a>02077 
<a name="l02078"></a>02078    <span class="keywordflow">if</span>(layer_index &lt; layers_number)
<a name="l02079"></a>02079    {
<a name="l02080"></a>02080       <span class="keywordflow">for</span>(<span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> i = layer_index+1; i &lt; layers_number; i++)
<a name="l02081"></a>02081       {
<a name="l02082"></a>02082          outputs = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#ea970635dd856cb0f9acdf458177312b">layers</a>[i].calculate_outputs(outputs);
<a name="l02083"></a>02083       }
<a name="l02084"></a>02084    }
<a name="l02085"></a>02085 
<a name="l02086"></a>02086    <span class="keywordflow">return</span>(outputs);
<a name="l02087"></a>02087 }
<a name="l02088"></a>02088 
<a name="l02089"></a>02089 
<a name="l02090"></a>02090 <span class="comment">// Vector&lt; Matrix&lt;double&gt; &gt; calculate_output_layers_delta(const Vector&lt; Vector&lt;double&gt; &gt;&amp;, const Vector&lt;double&gt;&amp;) method</span>
<a name="l02091"></a>02091 
<a name="l02095"></a>02095 
<a name="l02096"></a><a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#ff6b02bd37f90603c24b8f266ba926c6">02096</a> <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt; Matrix&lt;double&gt;</a> &gt; <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#ff6b02bd37f90603c24b8f266ba926c6">MultilayerPerceptron::calculate_output_layers_delta</a>(<span class="keyword">const</span> <a class="code" href="class_open_n_n_1_1_vector.html">Vector</a>&lt; <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt;double&gt;</a> &gt;&amp; layers_activation_derivative)<span class="keyword"> const</span>
<a name="l02097"></a>02097 <span class="keyword"></span>{
<a name="l02098"></a>02098    <span class="comment">// Control sentence (if debug)</span>
<a name="l02099"></a>02099 
<a name="l02100"></a>02100    <span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> layers_number = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#e5f41a6d170161f9b2896e95bb186423" title="This method returns the number of layers in the multilayer perceptron.">count_layers_number</a>();
<a name="l02101"></a>02101    <span class="keyword">const</span> <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt;unsigned int&gt;</a> layers_size = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#bac4febc8f59639eadd9d8b896148f5e" title="This method returns a vector with the size of each layer.">arrange_layers_perceptrons_numbers</a>();
<a name="l02102"></a>02102 
<a name="l02103"></a>02103    <span class="comment">// Control sentence (if debug)</span>
<a name="l02104"></a>02104 
<a name="l02105"></a>02105 <span class="preprocessor">   #ifdef _DEBUG </span>
<a name="l02106"></a>02106 <span class="preprocessor"></span>
<a name="l02107"></a>02107    <span class="comment">// Forward propagation activation derivative size</span>
<a name="l02108"></a>02108 
<a name="l02109"></a>02109    <span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> layers_activation_derivative_size = layers_activation_derivative.size();
<a name="l02110"></a>02110 
<a name="l02111"></a>02111    <span class="keywordflow">if</span>(layers_activation_derivative_size != layers_number)
<a name="l02112"></a>02112    {
<a name="l02113"></a>02113       std::ostringstream buffer;
<a name="l02114"></a>02114 
<a name="l02115"></a>02115       buffer &lt;&lt; <span class="stringliteral">"OpenNN Exception: MultilayerPerceptron class.\n"</span>
<a name="l02116"></a>02116              &lt;&lt; <span class="stringliteral">"Vector&lt; Vector&lt;double&gt; &gt; calculate_output_layers_delta(const Vector&lt; Vector&lt;double&gt; &gt;&amp;) method.\n"</span>
<a name="l02117"></a>02117              &lt;&lt; <span class="stringliteral">"Size of forward propagation activation derivative vector must be equal to number of layers.\n"</span>;
<a name="l02118"></a>02118 
<a name="l02119"></a>02119       <span class="keywordflow">throw</span> std::logic_error(buffer.str().c_str());
<a name="l02120"></a>02120    }
<a name="l02121"></a>02121 
<a name="l02122"></a>02122 <span class="preprocessor">   #endif</span>
<a name="l02123"></a>02123 <span class="preprocessor"></span>
<a name="l02124"></a>02124    <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt; Matrix&lt;double&gt;</a> &gt; output_layers_delta(layers_number);
<a name="l02125"></a>02125 
<a name="l02126"></a>02126    <span class="keywordflow">if</span>(layers_number &gt; 0)
<a name="l02127"></a>02127    {
<a name="l02128"></a>02128       <span class="comment">// Output layer</span>
<a name="l02129"></a>02129 
<a name="l02130"></a>02130       output_layers_delta[layers_number-1] = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#ea970635dd856cb0f9acdf458177312b">layers</a>[layers_number-1].arrange_activation_Jacobian(layers_activation_derivative[layers_number-1]);
<a name="l02131"></a>02131 
<a name="l02132"></a>02132       <span class="comment">// Rest of layers</span>
<a name="l02133"></a>02133 
<a name="l02134"></a>02134       <span class="keywordflow">for</span>(<span class="keywordtype">int</span> i = layers_number-2; i &gt;= 0; i--) 
<a name="l02135"></a>02135       {   
<a name="l02136"></a>02136                  output_layers_delta[i] = output_layers_delta[i+1].<a class="code" href="class_open_n_n_1_1_vector.html#0af2b14634f3dc1cea8ce692f77eb94e">dot</a>(<a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#ea970635dd856cb0f9acdf458177312b">layers</a>[i+1].arrange_synaptic_weights()).dot(<a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#ea970635dd856cb0f9acdf458177312b">layers</a>[i].arrange_activation_Jacobian(layers_activation_derivative[i]));
<a name="l02137"></a>02137           }
<a name="l02138"></a>02138    }
<a name="l02139"></a>02139 
<a name="l02140"></a>02140    <span class="keywordflow">return</span>(output_layers_delta);
<a name="l02141"></a>02141 }
<a name="l02142"></a>02142 
<a name="l02143"></a>02143 
<a name="l02144"></a>02144 <span class="comment">// Matrix&lt; Vector&lt; Matrix&lt;double&gt; &gt; &gt; calculate_output_interlayers_Delta(void) method </span>
<a name="l02145"></a>02145 
<a name="l02150"></a>02150 
<a name="l02151"></a>02151 <a class="code" href="class_open_n_n_1_1_matrix.html">Matrix&lt; Vector&lt; Matrix&lt;double&gt;</a> &gt; &gt; <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#5e93fa28d708caded7f766a56fb6b997">MultilayerPerceptron::calculate_output_interlayers_Delta</a>
<a name="l02152"></a><a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#5e93fa28d708caded7f766a56fb6b997">02152</a> (<span class="keyword">const</span> <a class="code" href="class_open_n_n_1_1_vector.html">Vector</a>&lt; <a class="code" href="class_open_n_n_1_1_vector.html">Vector</a>&lt; <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt;double&gt;</a> &gt; &gt;&amp; second_order_forward_propagation, 
<a name="l02153"></a>02153  <span class="keyword">const</span> <a class="code" href="class_open_n_n_1_1_matrix.html">Matrix</a>&lt; <a class="code" href="class_open_n_n_1_1_matrix.html">Matrix&lt;double&gt;</a> &gt;&amp; interlayers_combination_combination_Jacobian,
<a name="l02154"></a>02154  <span class="keyword">const</span> <a class="code" href="class_open_n_n_1_1_vector.html">Vector</a>&lt; <a class="code" href="class_open_n_n_1_1_matrix.html">Matrix&lt;double&gt;</a> &gt;&amp; output_layers_delta) <span class="keyword">const</span>
<a name="l02155"></a>02155 {
<a name="l02156"></a>02156    <span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> layers_number = count_layers_number();
<a name="l02157"></a>02157    <span class="keyword">const</span> <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt;unsigned int&gt;</a> layers_size = arrange_layers_perceptrons_numbers();
<a name="l02158"></a>02158    <span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> outputs_number = count_outputs_number();
<a name="l02159"></a>02159 
<a name="l02160"></a>02160    <span class="comment">// Control sentence (if debug)</span>
<a name="l02161"></a>02161 
<a name="l02162"></a>02162 <span class="preprocessor">   #ifdef _DEBUG </span>
<a name="l02163"></a>02163 <span class="preprocessor"></span>
<a name="l02164"></a>02164    std::ostringstream buffer;
<a name="l02165"></a>02165 
<a name="l02166"></a>02166    <span class="comment">// Second order forward propagation</span>
<a name="l02167"></a>02167 
<a name="l02168"></a>02168    <span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> second_order_forward_propagation_size = second_order_forward_propagation.size();
<a name="l02169"></a>02169 
<a name="l02170"></a>02170    <span class="keywordflow">if</span>(second_order_forward_propagation_size != 3)
<a name="l02171"></a>02171    {
<a name="l02172"></a>02172       buffer &lt;&lt; <span class="stringliteral">"OpenNN Exception: MultilayerPerceptron class.\n"</span>
<a name="l02173"></a>02173              &lt;&lt; <span class="stringliteral">"Matrix&lt; Vector&lt; Matrix&lt;double&gt; &gt; &gt; calculate_output_interlayers_delta(@todo) method.\n"</span>
<a name="l02174"></a>02174              &lt;&lt; <span class="stringliteral">"Size of second order forward propagation must be three.\n"</span>;
<a name="l02175"></a>02175 
<a name="l02176"></a>02176       <span class="keywordflow">throw</span> std::logic_error(buffer.str().c_str());
<a name="l02177"></a>02177    }
<a name="l02178"></a>02178 
<a name="l02179"></a>02179    <span class="comment">// Interlayers combination-combination Jacobian</span>
<a name="l02180"></a>02180 
<a name="l02181"></a>02181    <span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> interlayers_combination_combination_Jacobian_rows_number = interlayers_combination_combination_Jacobian.get_rows_number();
<a name="l02182"></a>02182 
<a name="l02183"></a>02183    <span class="keywordflow">if</span>(interlayers_combination_combination_Jacobian_rows_number != layers_number)
<a name="l02184"></a>02184    {
<a name="l02185"></a>02185       buffer &lt;&lt; <span class="stringliteral">"OpenNN Exception: MultilayerPerceptron class.\n"</span>
<a name="l02186"></a>02186              &lt;&lt; <span class="stringliteral">"Matrix&lt; Vector&lt; Matrix&lt;double&gt; &gt; &gt; calculate_output_interlayers_delta(@todo) method.\n"</span>
<a name="l02187"></a>02187              &lt;&lt; <span class="stringliteral">"Number of rows of interlayers combination-combination Jacobian must be equal to number of layers.\n"</span>;
<a name="l02188"></a>02188 
<a name="l02189"></a>02189       <span class="keywordflow">throw</span> std::logic_error(buffer.str().c_str());
<a name="l02190"></a>02190    }
<a name="l02191"></a>02191 
<a name="l02192"></a>02192    <span class="comment">// MultilayerPerceptron outputs layers delta</span>
<a name="l02193"></a>02193 
<a name="l02194"></a>02194    <span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> output_layers_delta_size = output_layers_delta.size();
<a name="l02195"></a>02195 
<a name="l02196"></a>02196    <span class="keywordflow">if</span>(output_layers_delta_size != layers_number)
<a name="l02197"></a>02197    {
<a name="l02198"></a>02198       buffer &lt;&lt; <span class="stringliteral">"OpenNN Exception: MultilayerPerceptron class.\n"</span>
<a name="l02199"></a>02199              &lt;&lt; <span class="stringliteral">"Matrix&lt; Vector&lt; Matrix&lt;double&gt; &gt; &gt; calculate_output_interlayers_delta(@todo) method.\n"</span>
<a name="l02200"></a>02200              &lt;&lt; <span class="stringliteral">"Size of multilayer_perceptron_pointer outputs layers delta must be equal to number of layers.\n"</span>;
<a name="l02201"></a>02201 
<a name="l02202"></a>02202       <span class="keywordflow">throw</span> std::logic_error(buffer.str().c_str());
<a name="l02203"></a>02203    }
<a name="l02204"></a>02204 
<a name="l02205"></a>02205 <span class="preprocessor">   #endif</span>
<a name="l02206"></a>02206 <span class="preprocessor"></span>
<a name="l02207"></a>02207    <span class="keyword">const</span> <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt; Matrix&lt;double&gt;</a> &gt; layers_synaptic_weights = arrange_layers_synaptic_weights();
<a name="l02208"></a>02208 
<a name="l02209"></a>02209    <span class="keyword">const</span> <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt; Vector&lt;double&gt;</a> &gt;&amp; layers_activation_derivative = second_order_forward_propagation[1];
<a name="l02210"></a>02210    <span class="keyword">const</span> <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt; Vector&lt;double&gt;</a> &gt;&amp; layers_activation_second_derivative = second_order_forward_propagation[2];
<a name="l02211"></a>02211 
<a name="l02212"></a>02212    <span class="comment">// The Delta form consists of a square matrix of size the number of layers</span>
<a name="l02213"></a>02213 
<a name="l02214"></a>02214    <a class="code" href="class_open_n_n_1_1_matrix.html">Matrix&lt; Vector&lt; Matrix&lt;double&gt;</a> &gt; &gt; output_interlayers_Delta(layers_number, layers_number);
<a name="l02215"></a>02215 
<a name="l02216"></a>02216    <span class="comment">// Each Delta element is a vector of size the number of outputs</span>
<a name="l02217"></a>02217 
<a name="l02218"></a>02218    <span class="keywordflow">for</span>(<span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> i = 0; i &lt; layers_number; i++)
<a name="l02219"></a>02219    {
<a name="l02220"></a>02220       <span class="keywordflow">for</span>(<span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> j = 0; j &lt; layers_number; j++)
<a name="l02221"></a>02221       {
<a name="l02222"></a>02222              output_interlayers_Delta[i][j].<a class="code" href="class_open_n_n_1_1_matrix.html#2f3b762afad2ac1274da1aea2ce2852c" title="This method set the numbers of rows and columns of the matrix to zero.">set</a>(outputs_number);
<a name="l02223"></a>02223       }
<a name="l02224"></a>02224    }
<a name="l02225"></a>02225 
<a name="l02226"></a>02226    <span class="comment">// The subelements are matrices with rows and columns numbers the sizes of the first and the second layers</span>
<a name="l02227"></a>02227 
<a name="l02228"></a>02228    <span class="keywordflow">for</span>(<span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> i = 0; i &lt; layers_number; i++)
<a name="l02229"></a>02229    {
<a name="l02230"></a>02230       <span class="keywordflow">for</span>(<span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> j = 0; j &lt; layers_number; j++)
<a name="l02231"></a>02231       {
<a name="l02232"></a>02232              <span class="keywordflow">for</span>(<span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> k = 0; k &lt; outputs_number; k++)
<a name="l02233"></a>02233                  {
<a name="l02234"></a>02234                     output_interlayers_Delta[i][j][k].<a class="code" href="class_open_n_n_1_1_matrix.html#2f3b762afad2ac1274da1aea2ce2852c" title="This method set the numbers of rows and columns of the matrix to zero.">set</a>(layers_size[i], layers_size[j]);
<a name="l02235"></a>02235                  }
<a name="l02236"></a>02236       }
<a name="l02237"></a>02237    }
<a name="l02238"></a>02238 
<a name="l02239"></a>02239    <span class="keywordflow">if</span>(layers_number &gt; 0)
<a name="l02240"></a>02240    {
<a name="l02241"></a>02241       <span class="comment">// Output-outputs layer (OK)</span>
<a name="l02242"></a>02242 
<a name="l02243"></a>02243       output_interlayers_Delta[layers_number-1][layers_number-1] = layers[layers_number-1].arrange_activation_Hessian_form(layers_activation_second_derivative[layers_number-1]);      
<a name="l02244"></a>02244 
<a name="l02245"></a>02245       <span class="comment">// Rest of hidden layers</span>
<a name="l02246"></a>02246 
<a name="l02247"></a>02247       <span class="keywordtype">double</span> sum_1;
<a name="l02248"></a>02248       <span class="keywordtype">double</span> sum_2;
<a name="l02249"></a>02249 
<a name="l02250"></a>02250       <span class="keywordflow">for</span>(<span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> L = layers_number-1; L != 0; L--) 
<a name="l02251"></a>02251       {   
<a name="l02252"></a>02252          <span class="keywordflow">for</span>(<span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> M = layers_number-1; M &gt;= L; M--) 
<a name="l02253"></a>02253          {   
<a name="l02254"></a>02254             <span class="keywordflow">if</span>(!(L == layers_number-1 &amp;&amp; M == layers_number-1))
<a name="l02255"></a>02255             {
<a name="l02256"></a>02256               <span class="keywordflow">for</span>(<span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> i = 0; i &lt; outputs_number; i++)
<a name="l02257"></a>02257                    {
<a name="l02258"></a>02258                   <span class="keywordflow">for</span>(<span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> j = 0; j &lt; layers_size[L]; j++)
<a name="l02259"></a>02259                           {      
<a name="l02260"></a>02260                      sum_1 = 0.0;
<a name="l02261"></a>02261          
<a name="l02262"></a>02262                      <span class="keywordflow">for</span>(<span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> l = 0; l &lt; layers_size[L+1]; l++)
<a name="l02263"></a>02263                                  {
<a name="l02264"></a>02264                                     sum_1 += output_layers_delta[L+1][i][l]*layers_synaptic_weights[L+1][l][j];
<a name="l02265"></a>02265                                  }
<a name="l02266"></a>02266 
<a name="l02267"></a>02267                      <span class="keywordflow">for</span>(<span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> k = 0; k &lt; layers_size[M]; k++)
<a name="l02268"></a>02268                              {
<a name="l02269"></a>02269                                     sum_2 = 0.0;
<a name="l02270"></a>02270 
<a name="l02271"></a>02271                         <span class="keywordflow">for</span>(<span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> l = 0; l &lt; layers_size[L+1]; l++)
<a name="l02272"></a>02272                                     {
<a name="l02273"></a>02273                                        sum_2 += output_interlayers_Delta[L+1][M][i][l][k]*layers_synaptic_weights[L+1][l][j];              
<a name="l02274"></a>02274                                     }
<a name="l02275"></a>02275 
<a name="l02276"></a>02276                         output_interlayers_Delta[L][M][i][j][k] 
<a name="l02277"></a>02277                                     = layers_activation_second_derivative[L][j]*interlayers_combination_combination_Jacobian[L][M][j][k]*sum_1
<a name="l02278"></a>02278                                     + layers_activation_derivative[L][j]*sum_2;
<a name="l02279"></a>02279 
<a name="l02280"></a>02280                         output_interlayers_Delta[M][L][i][k][j] = output_interlayers_Delta[L][M][i][j][k];    
<a name="l02281"></a>02281                              }           
<a name="l02282"></a>02282                           }
<a name="l02283"></a>02283                    }
<a name="l02284"></a>02284                         }
<a name="l02285"></a>02285                  }               
<a name="l02286"></a>02286           }
<a name="l02287"></a>02287    }
<a name="l02288"></a>02288 
<a name="l02289"></a>02289    <span class="keywordflow">return</span>(output_interlayers_Delta);
<a name="l02290"></a>02290 }
<a name="l02291"></a>02291 
<a name="l02292"></a>02292 
<a name="l02293"></a>02293 <span class="comment">// Matrix&lt;double&gt; calculate_parameters_Jacobian(const Vector&lt;double&gt;&amp;) const method</span>
<a name="l02294"></a>02294 
<a name="l02297"></a>02297 
<a name="l02298"></a><a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#7fb79104322e3d8745a059ff6b0d785b">02298</a> <a class="code" href="class_open_n_n_1_1_matrix.html">Matrix&lt;double&gt;</a> <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#7fb79104322e3d8745a059ff6b0d785b">MultilayerPerceptron::calculate_parameters_Jacobian</a>(<span class="keyword">const</span> <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt;double&gt;</a>&amp; inputs, <span class="keyword">const</span> <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt;double&gt;</a>&amp;)<span class="keyword"> const</span>
<a name="l02299"></a>02299 <span class="keyword"></span>{   
<a name="l02300"></a>02300 <span class="preprocessor">   #ifdef _DEBUG </span>
<a name="l02301"></a>02301 <span class="preprocessor"></span>
<a name="l02302"></a>02302    <span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> inputs_number = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#0998a82ea1845b0fd26872218b02b3f4" title="This method returns the number of inputs to the multilayer perceptron.">count_inputs_number</a>();
<a name="l02303"></a>02303    <span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> size = inputs.size();
<a name="l02304"></a>02304 
<a name="l02305"></a>02305    <span class="keywordflow">if</span>(size != inputs_number)
<a name="l02306"></a>02306    {
<a name="l02307"></a>02307       std::ostringstream buffer;
<a name="l02308"></a>02308 
<a name="l02309"></a>02309       buffer &lt;&lt; <span class="stringliteral">"OpenNN Exception: MultilayerPerceptron class.\n"</span>
<a name="l02310"></a>02310              &lt;&lt; <span class="stringliteral">"void calculate_parameters_Jacobian(Vector&lt;double&gt;&amp;) const method.\n"</span>
<a name="l02311"></a>02311              &lt;&lt; <span class="stringliteral">"Size must be equal to number of inputs.\n"</span>;
<a name="l02312"></a>02312 
<a name="l02313"></a>02313           <span class="keywordflow">throw</span> std::logic_error(buffer.str());
<a name="l02314"></a>02314    }
<a name="l02315"></a>02315 
<a name="l02316"></a>02316 <span class="preprocessor">   #endif</span>
<a name="l02317"></a>02317 <span class="preprocessor"></span>
<a name="l02318"></a>02318    <span class="comment">// Neural network stuff</span>
<a name="l02319"></a>02319 
<a name="l02320"></a>02320    <span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> layers_number = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#e5f41a6d170161f9b2896e95bb186423" title="This method returns the number of layers in the multilayer perceptron.">count_layers_number</a>();
<a name="l02321"></a>02321    <span class="keyword">const</span> <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt;unsigned int&gt;</a> layers_size = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#bac4febc8f59639eadd9d8b896148f5e" title="This method returns a vector with the size of each layer.">arrange_layers_perceptrons_numbers</a>();
<a name="l02322"></a>02322 
<a name="l02323"></a>02323    <span class="comment">// Calculate required quantities</span>
<a name="l02324"></a>02324 
<a name="l02325"></a>02325    <span class="keyword">const</span> <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt; Vector&lt; Vector&lt;double&gt;</a> &gt; &gt; first_order_forward_propagation = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#502cacdc7e9372cb636150133db135cd">calculate_first_order_forward_propagation</a>(inputs);
<a name="l02326"></a>02326    <span class="keyword">const</span> <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt; Vector&lt;double&gt;</a> &gt;&amp; layers_activation = first_order_forward_propagation[0];
<a name="l02327"></a>02327    <span class="keyword">const</span> <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt; Vector&lt;double&gt;</a> &gt;&amp; layers_activation_derivative = first_order_forward_propagation[1];
<a name="l02328"></a>02328 
<a name="l02329"></a>02329    <span class="keyword">const</span> <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt; Vector&lt;double&gt;</a> &gt; layers_inputs = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#948098df97672af318d7b763738b9a15">arrange_layers_input</a>(inputs, layers_activation);
<a name="l02330"></a>02330 
<a name="l02331"></a>02331    <span class="keyword">const</span> <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt; Matrix&lt;double&gt;</a> &gt; layers_combination_parameters_Jacobian = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#c4e7602d949194eb7048a10785a17565">calculate_layers_combination_parameters_Jacobian</a>(layers_inputs);
<a name="l02332"></a>02332 
<a name="l02333"></a>02333    <span class="keyword">const</span> <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt; Matrix&lt;double&gt;</a> &gt; output_layers_delta = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#ff6b02bd37f90603c24b8f266ba926c6">calculate_output_layers_delta</a>(layers_activation_derivative);
<a name="l02334"></a>02334 
<a name="l02335"></a>02335    <a class="code" href="class_open_n_n_1_1_matrix.html">Matrix&lt;double&gt;</a> parameters_Jacobian = output_layers_delta[0].<a class="code" href="class_open_n_n_1_1_vector.html#0af2b14634f3dc1cea8ce692f77eb94e">dot</a>(layers_combination_parameters_Jacobian[0]);
<a name="l02336"></a>02336 
<a name="l02337"></a>02337    <span class="keywordflow">for</span>(<span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> i = 1; i &lt; layers_number; i++)
<a name="l02338"></a>02338    {
<a name="l02339"></a>02339       parameters_Jacobian = parameters_Jacobian.<a class="code" href="class_open_n_n_1_1_matrix.html#608197f252cbda6688ddfa6032740189">get_assembly_columns</a>(output_layers_delta[i].dot(layers_combination_parameters_Jacobian[i]));
<a name="l02340"></a>02340    }
<a name="l02341"></a>02341 
<a name="l02342"></a>02342    <span class="keywordflow">return</span>(parameters_Jacobian);
<a name="l02343"></a>02343 }
<a name="l02344"></a>02344 
<a name="l02345"></a>02345 
<a name="l02346"></a>02346 <span class="comment">// Vector&lt; Matrix&lt;double&gt; &gt; calculate_parameters_Hessian_form(const Vector&lt;double&gt;&amp;) const</span>
<a name="l02347"></a>02347 
<a name="l02350"></a>02350 
<a name="l02351"></a><a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#6534a5c9a95f563f2bd67d82c315fe04">02351</a> <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt; Matrix&lt;double&gt;</a> &gt; <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#6534a5c9a95f563f2bd67d82c315fe04">MultilayerPerceptron::calculate_parameters_Hessian_form</a>(<span class="keyword">const</span> <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt;double&gt;</a>&amp; inputs, <span class="keyword">const</span> <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt;double&gt;</a>&amp;)<span class="keyword"> const</span>
<a name="l02352"></a>02352 <span class="keyword"></span>{
<a name="l02353"></a>02353    <span class="comment">// Neural network stuff</span>
<a name="l02354"></a>02354 
<a name="l02355"></a>02355    <span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> layers_number = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#e5f41a6d170161f9b2896e95bb186423" title="This method returns the number of layers in the multilayer perceptron.">count_layers_number</a>();
<a name="l02356"></a>02356    <span class="keyword">const</span> <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt;unsigned int&gt;</a> layers_size = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#bac4febc8f59639eadd9d8b896148f5e" title="This method returns a vector with the size of each layer.">arrange_layers_perceptrons_numbers</a>();
<a name="l02357"></a>02357    <span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> outputs_number = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#d73e53afdf816e7df8ae4cb450ea5be7" title="This method returns the number of outputs neurons in the multilayer perceptron.">count_outputs_number</a>();
<a name="l02358"></a>02358 
<a name="l02359"></a>02359    <span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> parameters_number = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#591e0e7ee4ae2c15d09e135652e30797" title="This method returns the number of parameters (biases and synaptic weights) in the...">count_parameters_number</a>();
<a name="l02360"></a>02360 
<a name="l02361"></a>02361    <span class="keyword">const</span> <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt; Matrix&lt;double&gt;</a> &gt; layers_synaptic_weights = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#724c4181d557355c39041940129cbc3e">arrange_layers_synaptic_weights</a>();
<a name="l02362"></a>02362 
<a name="l02363"></a>02363    <span class="comment">// Calculate required quantities</span>
<a name="l02364"></a>02364 
<a name="l02365"></a>02365    <span class="keyword">const</span> <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt; Vector&lt; Vector&lt;double&gt;</a> &gt; &gt; second_order_forward_propagation = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#52ecb5cf7502479a9cf83ff9c9dd1789">calculate_second_order_forward_propagation</a>(inputs);
<a name="l02366"></a>02366 
<a name="l02367"></a>02367    <span class="keyword">const</span> <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt; Vector&lt;double&gt;</a> &gt;&amp; layers_activation = second_order_forward_propagation[0];
<a name="l02368"></a>02368    <span class="keyword">const</span> <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt; Vector&lt;double&gt;</a> &gt;&amp; layers_activation_derivative = second_order_forward_propagation[1];
<a name="l02369"></a>02369 <span class="comment">//   const Vector&lt; Vector&lt;double&gt; &gt;&amp; layers_activation_second_derivative = second_order_forward_propagation[2];</span>
<a name="l02370"></a>02370 
<a name="l02371"></a>02371    <span class="keyword">const</span> <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt; Vector&lt;double&gt;</a> &gt; layers_inputs = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#948098df97672af318d7b763738b9a15">arrange_layers_input</a>(inputs, layers_activation);
<a name="l02372"></a>02372 
<a name="l02373"></a>02373    <span class="keyword">const</span> <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt; Vector&lt; Vector&lt;double&gt;</a> &gt; &gt; perceptrons_combination_parameters_gradient = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#5c4fe7003630ba75c9f6eed459035148">calculate_perceptrons_combination_parameters_gradient</a>(layers_inputs);
<a name="l02374"></a>02374 
<a name="l02375"></a>02375    <span class="keyword">const</span> <a class="code" href="class_open_n_n_1_1_matrix.html">Matrix&lt; Matrix&lt;double&gt;</a> &gt; interlayers_combination_combination_Jacobian = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#340d2954d200c8e690df333c91f76d18">calculate_interlayers_combination_combination_Jacobian</a>(inputs);
<a name="l02376"></a>02376 
<a name="l02377"></a>02377    <span class="keyword">const</span> <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt; Matrix&lt;double&gt;</a> &gt; output_layers_delta = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#ff6b02bd37f90603c24b8f266ba926c6">calculate_output_layers_delta</a>(layers_activation_derivative);
<a name="l02378"></a>02378 
<a name="l02379"></a>02379    <span class="keyword">const</span> <a class="code" href="class_open_n_n_1_1_matrix.html">Matrix&lt; Vector&lt; Matrix&lt;double&gt;</a> &gt; &gt; output_interlayers_Delta
<a name="l02380"></a>02380    = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#5e93fa28d708caded7f766a56fb6b997">calculate_output_interlayers_Delta</a>(second_order_forward_propagation, interlayers_combination_combination_Jacobian, output_layers_delta);
<a name="l02381"></a>02381 
<a name="l02382"></a>02382    <span class="comment">// Size multilayer_perceptron_pointer parameters Hessian form </span>
<a name="l02383"></a>02383 
<a name="l02384"></a>02384    <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt; Matrix&lt;double&gt;</a> &gt; parameters_Hessian_form(outputs_number);
<a name="l02385"></a>02385 
<a name="l02386"></a>02386    <span class="keywordflow">for</span>(<span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> i = 0; i &lt; outputs_number; i++)
<a name="l02387"></a>02387    {
<a name="l02388"></a>02388       parameters_Hessian_form[i].<a class="code" href="class_open_n_n_1_1_vector.html#78a81ff993befcd4e75ab75da2976a9a" title="This method sets the size of a vector to zero.">set</a>(parameters_number, parameters_number);
<a name="l02389"></a>02389    }
<a name="l02390"></a>02390 
<a name="l02391"></a>02391    <span class="comment">// Calculate Hessian form elements</span>
<a name="l02392"></a>02392 
<a name="l02393"></a>02393    <span class="keywordflow">if</span>(layers_number &gt; 0)
<a name="l02394"></a>02394    {
<a name="l02395"></a>02395       <a class="code" href="class_open_n_n_1_1_matrix.html">Matrix&lt;unsigned int&gt;</a> parameters_indices = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#b81eaefa02c5050823a3d2d48cec9147">arrange_parameters_indices</a>();
<a name="l02396"></a>02396 
<a name="l02397"></a>02397       <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> layer_j;
<a name="l02398"></a>02398       <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> neuron_j;
<a name="l02399"></a>02399       <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> parameter_j;
<a name="l02400"></a>02400 
<a name="l02401"></a>02401       <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> layer_k;
<a name="l02402"></a>02402       <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> neuron_k;
<a name="l02403"></a>02403       <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> parameter_k;
<a name="l02404"></a>02404 
<a name="l02405"></a>02405       <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt;double&gt;</a> neuron_j_combination_parameters_gradient;
<a name="l02406"></a>02406       <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt;double&gt;</a> neuron_k_combination_parameters_gradient;
<a name="l02407"></a>02407 
<a name="l02408"></a>02408       <span class="keywordflow">for</span>(<span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> i = 0; i &lt; outputs_number; i++)
<a name="l02409"></a>02409       {
<a name="l02410"></a>02410          <span class="keywordflow">for</span>(<span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> j = 0; j &lt; parameters_number; j++)
<a name="l02411"></a>02411          {
<a name="l02412"></a>02412             layer_j = parameters_indices[j][0];
<a name="l02413"></a>02413             neuron_j = parameters_indices[j][1];
<a name="l02414"></a>02414             parameter_j = parameters_indices[j][2];
<a name="l02415"></a>02415 
<a name="l02416"></a>02416                 <span class="keywordflow">for</span>(<span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> k = j; k &lt; parameters_number; k++)
<a name="l02417"></a>02417                     {
<a name="l02418"></a>02418                layer_k = parameters_indices[k][0];
<a name="l02419"></a>02419                neuron_k = parameters_indices[k][1];
<a name="l02420"></a>02420                parameter_k = parameters_indices[k][2];
<a name="l02421"></a>02421                                            
<a name="l02422"></a>02422                            parameters_Hessian_form[i][j][k] =
<a name="l02423"></a>02423                            output_interlayers_Delta[layer_j][layer_k][i][neuron_j][neuron_k]
<a name="l02424"></a>02424                            *perceptrons_combination_parameters_gradient[layer_j][neuron_j][parameter_j]
<a name="l02425"></a>02425                            *perceptrons_combination_parameters_gradient[layer_k][neuron_k][parameter_k]
<a name="l02426"></a>02426                            ;
<a name="l02427"></a>02427 
<a name="l02428"></a>02428                            <span class="keywordflow">if</span>(layer_j != 0 &amp;&amp; parameter_j != 0) <span class="comment">// Neither the first layer nor parameter is a bias</span>
<a name="l02429"></a>02429                            {
<a name="l02430"></a>02430                               <span class="comment">//parameters_Hessian_form[i][j][k] +=</span>
<a name="l02431"></a>02431                               <span class="comment">//output_layers_delta[layer_j][i][neuron_j]</span>
<a name="l02432"></a>02432                                   <span class="comment">//*layers_activation_derivative[layer_j-1][parameter_j-1]</span>
<a name="l02433"></a>02433                                   <span class="comment">//*interlayers_combination_combination_Jacobian[layer_j-1][layer_k][parameter_j-1][neuron_k]</span>
<a name="l02434"></a>02434                               <span class="comment">//*perceptrons_combination_parameters_gradient[layer_k][neuron_k][parameter_k]</span>
<a name="l02435"></a>02435                           ;                               
<a name="l02436"></a>02436                            }
<a name="l02437"></a>02437 
<a name="l02438"></a>02438                            <span class="keywordflow">if</span>(layer_k != 0 &amp;&amp; parameter_k != 0)
<a name="l02439"></a>02439                            {
<a name="l02440"></a>02440                              parameters_Hessian_form[i][j][k] +=
<a name="l02441"></a>02441                              output_layers_delta[layer_k][i][neuron_k]
<a name="l02442"></a>02442                              *layers_activation_derivative[layer_k-1][parameter_k-1]
<a name="l02443"></a>02443                              *interlayers_combination_combination_Jacobian[layer_k-1][layer_j][parameter_k-1][neuron_j]
<a name="l02444"></a>02444                              *perceptrons_combination_parameters_gradient[layer_j][neuron_j][parameter_j]
<a name="l02445"></a>02445                              ;             
<a name="l02446"></a>02446                            }  
<a name="l02447"></a>02447 
<a name="l02448"></a>02448                            parameters_Hessian_form[i][k][j] = parameters_Hessian_form[i][j][k];
<a name="l02449"></a>02449             }
<a name="l02450"></a>02450              }
<a name="l02451"></a>02451       }
<a name="l02452"></a>02452    }
<a name="l02453"></a>02453 
<a name="l02454"></a>02454    <span class="keywordflow">return</span>(parameters_Hessian_form);
<a name="l02455"></a>02455 }
<a name="l02456"></a>02456 
<a name="l02457"></a>02457 
<a name="l02458"></a>02458 <span class="comment">// Vector&lt; Vector&lt;double&gt; &gt; arrange_layers_input(const Vector&lt;double&gt;&amp;, const Vector&lt; Vector&lt;double&gt; &gt;&amp;) const method</span>
<a name="l02459"></a>02459 
<a name="l02466"></a>02466 
<a name="l02467"></a><a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#948098df97672af318d7b763738b9a15">02467</a> <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt; Vector&lt;double&gt;</a> &gt; <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#948098df97672af318d7b763738b9a15">MultilayerPerceptron::arrange_layers_input</a>(<span class="keyword">const</span> <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt;double&gt;</a>&amp; inputs, <span class="keyword">const</span> <a class="code" href="class_open_n_n_1_1_vector.html">Vector</a>&lt; <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt;double&gt;</a> &gt;&amp; layers_activation)<span class="keyword"> const</span>
<a name="l02468"></a>02468 <span class="keyword"></span>{
<a name="l02469"></a>02469    <span class="comment">// Neural network stuff</span>
<a name="l02470"></a>02470 
<a name="l02471"></a>02471    <span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> layers_number = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#e5f41a6d170161f9b2896e95bb186423" title="This method returns the number of layers in the multilayer perceptron.">count_layers_number</a>();
<a name="l02472"></a>02472 
<a name="l02473"></a>02473 <span class="preprocessor">   #ifdef _DEBUG </span>
<a name="l02474"></a>02474 <span class="preprocessor"></span>
<a name="l02475"></a>02475    <span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> inputs_number = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#0998a82ea1845b0fd26872218b02b3f4" title="This method returns the number of inputs to the multilayer perceptron.">count_inputs_number</a>();
<a name="l02476"></a>02476    <span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> inputs_size = inputs.size();
<a name="l02477"></a>02477 
<a name="l02478"></a>02478    <span class="keywordflow">if</span>(inputs_size != inputs_number)
<a name="l02479"></a>02479    {
<a name="l02480"></a>02480       std::ostringstream buffer;
<a name="l02481"></a>02481 
<a name="l02482"></a>02482       buffer &lt;&lt; <span class="stringliteral">"OpenNN Exception: MultilayerPerceptron class.\n"</span>
<a name="l02483"></a>02483              &lt;&lt; <span class="stringliteral">"Vector&lt; Vector&lt;double&gt; &gt; arrange_layers_input(const Vector&lt;double&gt;&amp;, const Vector&lt; Vector&lt;double&gt; &gt;&amp;) const method.\n"</span>
<a name="l02484"></a>02484              &lt;&lt; <span class="stringliteral">"Size must be equal to number of inputs.\n"</span>;
<a name="l02485"></a>02485 
<a name="l02486"></a>02486           <span class="keywordflow">throw</span> std::logic_error(buffer.str());
<a name="l02487"></a>02487    }
<a name="l02488"></a>02488 
<a name="l02489"></a>02489    <span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> layers_activation_size = layers_activation.size();
<a name="l02490"></a>02490 
<a name="l02491"></a>02491    <span class="keywordflow">if</span>(layers_activation_size != layers_number)
<a name="l02492"></a>02492    {
<a name="l02493"></a>02493       std::ostringstream buffer;
<a name="l02494"></a>02494 
<a name="l02495"></a>02495       buffer &lt;&lt; <span class="stringliteral">"OpenNN Exception: MultilayerPerceptron class.\n"</span>
<a name="l02496"></a>02496              &lt;&lt; <span class="stringliteral">"Vector&lt; Vector&lt;double&gt; &gt; arrange_layers_input(const Vector&lt;double&gt;&amp;, const Vector&lt; Vector&lt;double&gt; &gt;&amp;) const method.\n"</span>
<a name="l02497"></a>02497              &lt;&lt; <span class="stringliteral">"Size must be equal to number of inputs.\n"</span>;
<a name="l02498"></a>02498 
<a name="l02499"></a>02499           <span class="keywordflow">throw</span> std::logic_error(buffer.str());
<a name="l02500"></a>02500    }
<a name="l02501"></a>02501 
<a name="l02502"></a>02502 <span class="preprocessor">   #endif</span>
<a name="l02503"></a>02503 <span class="preprocessor"></span>
<a name="l02504"></a>02504    <span class="comment">// Arrange layers inputs</span>
<a name="l02505"></a>02505 
<a name="l02506"></a>02506    <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt; Vector&lt;double&gt;</a> &gt; layers_inputs(layers_number);
<a name="l02507"></a>02507 
<a name="l02508"></a>02508    <span class="keywordflow">if</span>(layers_number != 0)
<a name="l02509"></a>02509    {
<a name="l02510"></a>02510       layers_inputs[0] = inputs;
<a name="l02511"></a>02511 
<a name="l02512"></a>02512       <span class="keywordflow">for</span>(<span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> j = 1; j &lt; layers_number; j++)
<a name="l02513"></a>02513       {
<a name="l02514"></a>02514          layers_inputs[j] = layers_activation[j-1];
<a name="l02515"></a>02515       }
<a name="l02516"></a>02516    }
<a name="l02517"></a>02517 
<a name="l02518"></a>02518    <span class="keywordflow">return</span>(layers_inputs);
<a name="l02519"></a>02519 }
<a name="l02520"></a>02520 
<a name="l02521"></a>02521 <span class="comment">// Vector&lt; Vector&lt;double&gt; &gt; calculate_layers_input(const Vector&lt;double&gt;&amp;) const method</span>
<a name="l02522"></a>02522 
<a name="l02526"></a>02526 
<a name="l02527"></a><a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#32f66a63c5e61353305c7a28a4c1f466">02527</a> <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt; Vector&lt;double&gt;</a> &gt; <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#32f66a63c5e61353305c7a28a4c1f466">MultilayerPerceptron::calculate_layers_input</a>(<span class="keyword">const</span> <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt;double&gt;</a>&amp; inputs)<span class="keyword"> const</span>
<a name="l02528"></a>02528 <span class="keyword"></span>{
<a name="l02529"></a>02529    <span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> layers_number = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#e5f41a6d170161f9b2896e95bb186423" title="This method returns the number of layers in the multilayer perceptron.">count_layers_number</a>();
<a name="l02530"></a>02530 
<a name="l02531"></a>02531    <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt; Vector&lt;double&gt;</a> &gt; layers_inputs(layers_number);
<a name="l02532"></a>02532 
<a name="l02533"></a>02533    layers_inputs[0] = inputs;
<a name="l02534"></a>02534 
<a name="l02535"></a>02535    <span class="keywordflow">for</span>(<span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> i = 1; i &lt; layers_number; i++)
<a name="l02536"></a>02536    {
<a name="l02537"></a>02537       layers_inputs[i] = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#ea970635dd856cb0f9acdf458177312b">layers</a>[i-1].calculate_outputs(layers_inputs[i-1]);
<a name="l02538"></a>02538    }
<a name="l02539"></a>02539 
<a name="l02540"></a>02540    <span class="keywordflow">return</span>(layers_inputs);
<a name="l02541"></a>02541 }
<a name="l02542"></a>02542 
<a name="l02543"></a>02543 
<a name="l02544"></a>02544 <span class="comment">// Vector&lt; Vector&lt;double&gt; &gt; calculate_layers_combination(const Vector&lt;double&gt;&amp;) const method</span>
<a name="l02545"></a>02545 
<a name="l02549"></a>02549 
<a name="l02550"></a><a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#04018070fb619f5b6e77d046634cdadc">02550</a> <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt; Vector&lt;double&gt;</a> &gt; <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#04018070fb619f5b6e77d046634cdadc">MultilayerPerceptron::calculate_layers_combination</a>(<span class="keyword">const</span> <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt;double&gt;</a>&amp; inputs)<span class="keyword"> const</span>
<a name="l02551"></a>02551 <span class="keyword"></span>{
<a name="l02552"></a>02552    <span class="comment">// Control sentence (if debug)</span>
<a name="l02553"></a>02553 
<a name="l02554"></a>02554 <span class="preprocessor">   #ifdef _DEBUG </span>
<a name="l02555"></a>02555 <span class="preprocessor"></span>
<a name="l02556"></a>02556    <span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> inputs_size = inputs.size();
<a name="l02557"></a>02557 
<a name="l02558"></a>02558    <span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> inputs_number = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#0998a82ea1845b0fd26872218b02b3f4" title="This method returns the number of inputs to the multilayer perceptron.">count_inputs_number</a>();
<a name="l02559"></a>02559 
<a name="l02560"></a>02560    <span class="keywordflow">if</span>(inputs_size != inputs_number)
<a name="l02561"></a>02561    {
<a name="l02562"></a>02562       std::ostringstream buffer;
<a name="l02563"></a>02563 
<a name="l02564"></a>02564       buffer &lt;&lt; <span class="stringliteral">"OpenNN Exception: MultilayerPerceptron class.\n"</span>
<a name="l02565"></a>02565              &lt;&lt; <span class="stringliteral">"Vector&lt; Vector&lt;double&gt; &gt; calculate_layers_combination(const Vector&lt;double&gt;&amp;) const method.\n"</span>
<a name="l02566"></a>02566              &lt;&lt; <span class="stringliteral">"Size must be equal to number of inputs.\n"</span>;
<a name="l02567"></a>02567 
<a name="l02568"></a>02568           <span class="keywordflow">throw</span> std::logic_error(buffer.str());
<a name="l02569"></a>02569    }
<a name="l02570"></a>02570 
<a name="l02571"></a>02571 <span class="preprocessor">   #endif</span>
<a name="l02572"></a>02572 <span class="preprocessor"></span>
<a name="l02573"></a>02573    <span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> layers_number = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#e5f41a6d170161f9b2896e95bb186423" title="This method returns the number of layers in the multilayer perceptron.">count_layers_number</a>();
<a name="l02574"></a>02574 
<a name="l02575"></a>02575    <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt; Vector&lt;double&gt;</a> &gt; layers_combination(layers_number);
<a name="l02576"></a>02576 
<a name="l02577"></a>02577    <span class="keywordflow">if</span>(layers_number &gt; 0)
<a name="l02578"></a>02578    {
<a name="l02579"></a>02579       <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt; Vector&lt;double&gt;</a> &gt; layers_activation(layers_number);
<a name="l02580"></a>02580 
<a name="l02581"></a>02581       layers_combination[0] = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#ea970635dd856cb0f9acdf458177312b">layers</a>[0].calculate_combination(inputs);
<a name="l02582"></a>02582 
<a name="l02583"></a>02583       layers_activation[0] = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#ea970635dd856cb0f9acdf458177312b">layers</a>[0].calculate_activation(layers_combination[0]);
<a name="l02584"></a>02584 
<a name="l02585"></a>02585       <span class="keywordflow">for</span>(<span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> i = 1; i &lt; layers_number; i++)
<a name="l02586"></a>02586       {
<a name="l02587"></a>02587          layers_combination[i] = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#ea970635dd856cb0f9acdf458177312b">layers</a>[i].calculate_combination(layers_activation[i-1]);
<a name="l02588"></a>02588 
<a name="l02589"></a>02589          layers_activation[i] = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#ea970635dd856cb0f9acdf458177312b">layers</a>[i].calculate_activation(layers_combination[i]);
<a name="l02590"></a>02590       }
<a name="l02591"></a>02591    }
<a name="l02592"></a>02592 
<a name="l02593"></a>02593    <span class="keywordflow">return</span>(layers_combination);
<a name="l02594"></a>02594 }
<a name="l02595"></a>02595 
<a name="l02596"></a>02596 
<a name="l02597"></a>02597 <span class="comment">// Vector&lt; Matrix&lt;double&gt; &gt; calculate_layers_combination_Jacobian(const Vector&lt;double&gt;&amp;) const method</span>
<a name="l02598"></a>02598 
<a name="l02601"></a>02601 
<a name="l02602"></a><a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#d3fc189748ab0148e684c5bc32579bf5">02602</a> <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt; Matrix&lt;double&gt;</a> &gt; <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#d3fc189748ab0148e684c5bc32579bf5">MultilayerPerceptron::calculate_layers_combination_Jacobian</a>(<span class="keyword">const</span> <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt;double&gt;</a>&amp; inputs)<span class="keyword"> const</span>
<a name="l02603"></a>02603 <span class="keyword"></span>{
<a name="l02604"></a>02604    <span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> layers_number = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#e5f41a6d170161f9b2896e95bb186423" title="This method returns the number of layers in the multilayer perceptron.">count_layers_number</a>();
<a name="l02605"></a>02605 
<a name="l02606"></a>02606    <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt; Matrix&lt;double&gt;</a> &gt; layers_combination_Jacobian(layers_number-2);
<a name="l02607"></a>02607 
<a name="l02608"></a>02608    <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt; Vector&lt;double&gt;</a> &gt; layers_output(layers_number);
<a name="l02609"></a>02609 
<a name="l02610"></a>02610    <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt; Matrix&lt;double&gt;</a> &gt; layers_Jacobian(layers_number);
<a name="l02611"></a>02611 
<a name="l02612"></a>02612    <span class="comment">// Hidden and outputs layers Jacobian</span>
<a name="l02613"></a>02613 
<a name="l02614"></a>02614    layers_output[0] = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#ea970635dd856cb0f9acdf458177312b">layers</a>[0].calculate_outputs(inputs);   
<a name="l02615"></a>02615 
<a name="l02616"></a>02616    layers_combination_Jacobian[0] = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#ea970635dd856cb0f9acdf458177312b">layers</a>[0].calculate_combination_Jacobian(inputs);
<a name="l02617"></a>02617 
<a name="l02618"></a>02618    <span class="keywordflow">for</span>(<span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> i = 1; i &lt; layers_number; i++)
<a name="l02619"></a>02619    {
<a name="l02620"></a>02620       layers_output[i] = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#ea970635dd856cb0f9acdf458177312b">layers</a>[i].calculate_outputs(layers_output[i-1]);         
<a name="l02621"></a>02621 
<a name="l02622"></a>02622       layers_Jacobian[i] = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#ea970635dd856cb0f9acdf458177312b">layers</a>[i].calculate_Jacobian(layers_output[i-1]);
<a name="l02623"></a>02623    }
<a name="l02624"></a>02624 
<a name="l02625"></a>02625    <a class="code" href="class_open_n_n_1_1_matrix.html">Matrix&lt;double&gt;</a> output_layer_Jacobian = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#ea970635dd856cb0f9acdf458177312b">layers</a>[layers_number-1].calculate_Jacobian(layers_output[layers_number-1]);
<a name="l02626"></a>02626 
<a name="l02627"></a>02627    <span class="comment">// Calculate forward propagation Jacobian</span>
<a name="l02628"></a>02628 
<a name="l02629"></a>02629    layers_Jacobian[layers_number] = output_layer_Jacobian;
<a name="l02630"></a>02630 
<a name="l02631"></a>02631    <span class="keywordflow">for</span>(<span class="keywordtype">int</span> i = layers_number-1; i &gt; -1; i--)
<a name="l02632"></a>02632    {
<a name="l02633"></a>02633       layers_Jacobian[layers_number] = layers_Jacobian[layers_number].<a class="code" href="class_open_n_n_1_1_vector.html#0af2b14634f3dc1cea8ce692f77eb94e">dot</a>(layers_Jacobian[i]);   
<a name="l02634"></a>02634    }
<a name="l02635"></a>02635 
<a name="l02636"></a>02636    <span class="keywordflow">for</span>(<span class="keywordtype">int</span> i = layers_number-1; i &gt; -1; i--)
<a name="l02637"></a>02637    {
<a name="l02638"></a>02638       layers_Jacobian[i] = layers_Jacobian[i];
<a name="l02639"></a>02639 
<a name="l02640"></a>02640           <span class="keywordflow">for</span>(<span class="keywordtype">int</span> j = i-1; j &gt; -1; j--)
<a name="l02641"></a>02641           {
<a name="l02642"></a>02642          layers_Jacobian[i] = layers_Jacobian[i].<a class="code" href="class_open_n_n_1_1_vector.html#0af2b14634f3dc1cea8ce692f77eb94e">dot</a>(layers_Jacobian[j]);     
<a name="l02643"></a>02643           }      
<a name="l02644"></a>02644    }
<a name="l02645"></a>02645 
<a name="l02646"></a>02646    <span class="keywordflow">return</span>(layers_combination_Jacobian);
<a name="l02647"></a>02647 }
<a name="l02648"></a>02648 
<a name="l02649"></a>02649 
<a name="l02650"></a>02650 <span class="comment">// Vector&lt; Matrix&lt;double&gt; &gt; calculate_layers_combination_parameters_Jacobian(const Vector&lt; Vector&lt;double&gt; &gt;&amp;) const method</span>
<a name="l02651"></a>02651 
<a name="l02656"></a>02656 
<a name="l02657"></a><a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#c4e7602d949194eb7048a10785a17565">02657</a> <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt; Matrix&lt;double&gt;</a> &gt; <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#c4e7602d949194eb7048a10785a17565">MultilayerPerceptron::calculate_layers_combination_parameters_Jacobian</a>(<span class="keyword">const</span> <a class="code" href="class_open_n_n_1_1_vector.html">Vector</a>&lt; <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt;double&gt;</a> &gt;&amp; layers_inputs)<span class="keyword"> const</span>
<a name="l02658"></a>02658 <span class="keyword"></span>{
<a name="l02659"></a>02659    <span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> layers_number = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#e5f41a6d170161f9b2896e95bb186423" title="This method returns the number of layers in the multilayer perceptron.">count_layers_number</a>();
<a name="l02660"></a>02660 
<a name="l02661"></a>02661    <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt; Matrix&lt;double&gt;</a> &gt; layers_combination_parameters_Jacobian(layers_number);
<a name="l02662"></a>02662 
<a name="l02663"></a>02663    <span class="keyword">const</span> <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt;double&gt;</a> dummy;
<a name="l02664"></a>02664 
<a name="l02665"></a>02665    <span class="keywordflow">for</span>(<span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> i = 0; i &lt; layers_number; i++)
<a name="l02666"></a>02666    {
<a name="l02667"></a>02667       layers_combination_parameters_Jacobian[i] = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#ea970635dd856cb0f9acdf458177312b">layers</a>[i].calculate_combination_parameters_Jacobian(layers_inputs[i], dummy);         
<a name="l02668"></a>02668    }
<a name="l02669"></a>02669 
<a name="l02670"></a>02670    <span class="keywordflow">return</span>(layers_combination_parameters_Jacobian);
<a name="l02671"></a>02671 }
<a name="l02672"></a>02672 
<a name="l02673"></a>02673 
<a name="l02674"></a>02674 <span class="comment">// Vector&lt; Vector&lt; Vector&lt;double&gt; &gt; &gt; calculate_perceptrons_combination_parameters_gradient(const Vector&lt; Vector&lt;double&gt; &gt;&amp;) const method</span>
<a name="l02675"></a>02675 
<a name="l02683"></a>02683 
<a name="l02684"></a><a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#5c4fe7003630ba75c9f6eed459035148">02684</a> <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt; Vector&lt; Vector&lt;double&gt;</a> &gt; &gt; <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#5c4fe7003630ba75c9f6eed459035148">MultilayerPerceptron::calculate_perceptrons_combination_parameters_gradient</a>(<span class="keyword">const</span> <a class="code" href="class_open_n_n_1_1_vector.html">Vector</a>&lt; <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt;double&gt;</a> &gt;&amp; layers_inputs)<span class="keyword"> const</span>
<a name="l02685"></a>02685 <span class="keyword"></span>{
<a name="l02686"></a>02686    <span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> layers_number = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#e5f41a6d170161f9b2896e95bb186423" title="This method returns the number of layers in the multilayer perceptron.">count_layers_number</a>();
<a name="l02687"></a>02687 
<a name="l02688"></a>02688    <span class="comment">// Control sentence (if debug)</span>
<a name="l02689"></a>02689 
<a name="l02690"></a>02690 <span class="preprocessor">   #ifdef _DEBUG </span>
<a name="l02691"></a>02691 <span class="preprocessor"></span>
<a name="l02692"></a>02692    <span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> layers_input_size = layers_inputs.size();
<a name="l02693"></a>02693 
<a name="l02694"></a>02694    <span class="keywordflow">if</span>(layers_input_size != layers_number)
<a name="l02695"></a>02695    {
<a name="l02696"></a>02696       std::ostringstream buffer;
<a name="l02697"></a>02697 
<a name="l02698"></a>02698       buffer &lt;&lt; <span class="stringliteral">"OpenNN Exception: MultilayerPerceptron class.\n"</span>
<a name="l02699"></a>02699              &lt;&lt; <span class="stringliteral">"Vector&lt; Vector&lt; Vector&lt;double&gt; &gt; &gt; calculate_perceptrons_combination_parameters_gradient(const Vector&lt; Vector&lt;double&gt; &gt;&amp;) const method.\n"</span>
<a name="l02700"></a>02700              &lt;&lt; <span class="stringliteral">"Size must be equal to number of layers.\n"</span>;
<a name="l02701"></a>02701 
<a name="l02702"></a>02702           <span class="keywordflow">throw</span> std::logic_error(buffer.str());
<a name="l02703"></a>02703    }
<a name="l02704"></a>02704 
<a name="l02705"></a>02705 <span class="preprocessor">   #endif</span>
<a name="l02706"></a>02706 <span class="preprocessor"></span>
<a name="l02707"></a>02707    <span class="keyword">const</span> <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt;unsigned int&gt;</a> layers_inputs_number = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#73f046edc741cadc3d54c10cd9cf3a89" title="This method returns a vector with the number of inputs of each layer.">get_layers_inputs_number</a>();
<a name="l02708"></a>02708 
<a name="l02709"></a>02709 <span class="preprocessor">   #ifdef _DEBUG </span>
<a name="l02710"></a>02710 <span class="preprocessor"></span>
<a name="l02711"></a>02711    <span class="keywordflow">for</span>(<span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> i = 0; i &lt; layers_number; i++)
<a name="l02712"></a>02712    {
<a name="l02713"></a>02713       <span class="keywordflow">if</span>(layers_inputs[i].size() != layers_inputs_number[i])
<a name="l02714"></a>02714       {
<a name="l02715"></a>02715          std::ostringstream buffer;
<a name="l02716"></a>02716 
<a name="l02717"></a>02717          buffer &lt;&lt; <span class="stringliteral">"OpenNN Exception: MultilayerPerceptron class.\n"</span>
<a name="l02718"></a>02718                 &lt;&lt; <span class="stringliteral">"Vector&lt; Vector&lt; Vector&lt;double&gt; &gt; &gt; calculate_perceptrons_combination_parameters_gradient(const Vector&lt; Vector&lt;double&gt; &gt;&amp;) const method.\n"</span>
<a name="l02719"></a>02719                 &lt;&lt; <span class="stringliteral">"Size of inputs to layer "</span> &lt;&lt; i &lt;&lt; <span class="stringliteral">" must be equal to size of that layer.\n"</span>;
<a name="l02720"></a>02720 
<a name="l02721"></a>02721              <span class="keywordflow">throw</span> std::logic_error(buffer.str());
<a name="l02722"></a>02722       }
<a name="l02723"></a>02723    }
<a name="l02724"></a>02724 
<a name="l02725"></a>02725 <span class="preprocessor">   #endif</span>
<a name="l02726"></a>02726 <span class="preprocessor"></span>
<a name="l02727"></a>02727    <span class="keyword">const</span> <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt;unsigned int&gt;</a> layers_size = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#bac4febc8f59639eadd9d8b896148f5e" title="This method returns a vector with the size of each layer.">arrange_layers_perceptrons_numbers</a>();
<a name="l02728"></a>02728 
<a name="l02729"></a>02729    <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt; Vector&lt; Vector&lt;double&gt;</a> &gt; &gt; perceptrons_combination_parameters_gradient(layers_number);
<a name="l02730"></a>02730 
<a name="l02731"></a>02731    <span class="keywordflow">for</span>(<span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> i = 0; i &lt; layers_number; i++)
<a name="l02732"></a>02732    {
<a name="l02733"></a>02733       perceptrons_combination_parameters_gradient[i].<a class="code" href="class_open_n_n_1_1_vector.html#78a81ff993befcd4e75ab75da2976a9a" title="This method sets the size of a vector to zero.">set</a>(layers_size[i]);   
<a name="l02734"></a>02734 
<a name="l02735"></a>02735       <span class="keywordflow">for</span>(<span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> j = 0; j &lt; layers_size[i]; j++)
<a name="l02736"></a>02736       {
<a name="l02737"></a>02737                   <span class="keyword">const</span> <a class="code" href="class_open_n_n_1_1_perceptron.html">Perceptron</a>&amp; perceptron = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#ea970635dd856cb0f9acdf458177312b">layers</a>[i].get_perceptron(j);
<a name="l02738"></a>02738 
<a name="l02739"></a>02739           perceptrons_combination_parameters_gradient[i][j] = perceptron.<a class="code" href="class_open_n_n_1_1_perceptron.html#d73c63467f7b0da6c622dd2fc029e070">calculate_combination_parameters_gradient</a>(layers_inputs[i]);   
<a name="l02740"></a>02740       }
<a name="l02741"></a>02741    }
<a name="l02742"></a>02742 
<a name="l02743"></a>02743    <span class="keywordflow">return</span>(perceptrons_combination_parameters_gradient);
<a name="l02744"></a>02744 }
<a name="l02745"></a>02745 
<a name="l02746"></a>02746 
<a name="l02747"></a>02747 <span class="comment">// Vector&lt; Vector&lt;double&gt; &gt; calculate_layers_activation(const Vector&lt;double&gt;&amp;) const method</span>
<a name="l02748"></a>02748 
<a name="l02752"></a>02752 
<a name="l02753"></a><a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#540c00db106b499da8a6ab48d3c6668e">02753</a> <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt; Vector&lt;double&gt;</a> &gt; <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#540c00db106b499da8a6ab48d3c6668e">MultilayerPerceptron::calculate_layers_activation</a>(<span class="keyword">const</span> <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt;double&gt;</a>&amp; inputs)<span class="keyword"> const</span>
<a name="l02754"></a>02754 <span class="keyword"></span>{
<a name="l02755"></a>02755    <span class="comment">// Control sentence (if debug)</span>
<a name="l02756"></a>02756 
<a name="l02757"></a>02757 <span class="preprocessor">   #ifdef _DEBUG </span>
<a name="l02758"></a>02758 <span class="preprocessor"></span>
<a name="l02759"></a>02759    <span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> inputs_size = inputs.size();
<a name="l02760"></a>02760 
<a name="l02761"></a>02761    <span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> inputs_number = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#0998a82ea1845b0fd26872218b02b3f4" title="This method returns the number of inputs to the multilayer perceptron.">count_inputs_number</a>();
<a name="l02762"></a>02762 
<a name="l02763"></a>02763    <span class="keywordflow">if</span>(inputs_size != inputs_number)
<a name="l02764"></a>02764    {
<a name="l02765"></a>02765       std::ostringstream buffer;
<a name="l02766"></a>02766 
<a name="l02767"></a>02767       buffer &lt;&lt; <span class="stringliteral">"OpenNN Exception: MultilayerPerceptron class.\n"</span>
<a name="l02768"></a>02768              &lt;&lt; <span class="stringliteral">"Vector&lt; Vector&lt;double&gt; &gt; calculate_layers_activation(const Vector&lt;double&gt;&amp;) const method.\n"</span>
<a name="l02769"></a>02769              &lt;&lt; <span class="stringliteral">"Size must be equal to number of inputs.\n"</span>;
<a name="l02770"></a>02770 
<a name="l02771"></a>02771           <span class="keywordflow">throw</span> std::logic_error(buffer.str());
<a name="l02772"></a>02772    }
<a name="l02773"></a>02773 
<a name="l02774"></a>02774 <span class="preprocessor">   #endif</span>
<a name="l02775"></a>02775 <span class="preprocessor"></span>
<a name="l02776"></a>02776    <span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> layers_number = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#e5f41a6d170161f9b2896e95bb186423" title="This method returns the number of layers in the multilayer perceptron.">count_layers_number</a>();
<a name="l02777"></a>02777 
<a name="l02778"></a>02778    <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt; Vector&lt;double&gt;</a> &gt; layers_combination(layers_number);
<a name="l02779"></a>02779    <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt; Vector&lt;double&gt;</a> &gt; layers_activation(layers_number);
<a name="l02780"></a>02780 
<a name="l02781"></a>02781    layers_combination[0] = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#ea970635dd856cb0f9acdf458177312b">layers</a>[0].calculate_combination(inputs);
<a name="l02782"></a>02782    layers_activation[0] = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#ea970635dd856cb0f9acdf458177312b">layers</a>[0].calculate_activation(layers_combination[0]);
<a name="l02783"></a>02783 
<a name="l02784"></a>02784    <span class="keywordflow">for</span>(<span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> i = 1; i &lt; layers_number; i++)
<a name="l02785"></a>02785    {
<a name="l02786"></a>02786       layers_combination[i] = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#ea970635dd856cb0f9acdf458177312b">layers</a>[i].calculate_combination(layers_activation[i-1]);
<a name="l02787"></a>02787       layers_activation[i] = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#ea970635dd856cb0f9acdf458177312b">layers</a>[i].calculate_activation(layers_combination[i]);
<a name="l02788"></a>02788    }
<a name="l02789"></a>02789 
<a name="l02790"></a>02790    <span class="keywordflow">return</span>(layers_activation);
<a name="l02791"></a>02791 }
<a name="l02792"></a>02792 
<a name="l02793"></a>02793 
<a name="l02794"></a>02794 <span class="comment">// Vector&lt; Vector&lt;double&gt; &gt; calculate_layers_activation_derivative(const Vector&lt;double&gt;&amp;) const method</span>
<a name="l02795"></a>02795 
<a name="l02799"></a>02799 
<a name="l02800"></a><a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#77647025463336b34462e06faed86c2f">02800</a> <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt; Vector&lt;double&gt;</a> &gt; <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#77647025463336b34462e06faed86c2f">MultilayerPerceptron::calculate_layers_activation_derivative</a>(<span class="keyword">const</span> <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt;double&gt;</a>&amp; inputs)<span class="keyword"> const</span>
<a name="l02801"></a>02801 <span class="keyword"></span>{
<a name="l02802"></a>02802    <span class="comment">// Control sentence (if debug)</span>
<a name="l02803"></a>02803 
<a name="l02804"></a>02804 <span class="preprocessor">   #ifdef _DEBUG </span>
<a name="l02805"></a>02805 <span class="preprocessor"></span>
<a name="l02806"></a>02806    <span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> inputs_size = inputs.size();
<a name="l02807"></a>02807    <span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> inputs_number = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#0998a82ea1845b0fd26872218b02b3f4" title="This method returns the number of inputs to the multilayer perceptron.">count_inputs_number</a>();
<a name="l02808"></a>02808 
<a name="l02809"></a>02809    <span class="keywordflow">if</span>(inputs_size != inputs_number)
<a name="l02810"></a>02810    {
<a name="l02811"></a>02811       std::ostringstream buffer;
<a name="l02812"></a>02812 
<a name="l02813"></a>02813       buffer &lt;&lt; <span class="stringliteral">"OpenNN Exception: MultilayerPerceptron class.\n"</span>
<a name="l02814"></a>02814              &lt;&lt; <span class="stringliteral">"Vector&lt; Vector&lt;double&gt; &gt; calculate_layers_activation_derivative(const Vector&lt;double&gt;&amp;) const method.\n"</span>
<a name="l02815"></a>02815              &lt;&lt; <span class="stringliteral">"Size must be equal to number of inputs.\n"</span>;
<a name="l02816"></a>02816 
<a name="l02817"></a>02817           <span class="keywordflow">throw</span> std::logic_error(buffer.str());
<a name="l02818"></a>02818    }
<a name="l02819"></a>02819 
<a name="l02820"></a>02820 <span class="preprocessor">   #endif</span>
<a name="l02821"></a>02821 <span class="preprocessor"></span>
<a name="l02822"></a>02822    <span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> layers_number = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#e5f41a6d170161f9b2896e95bb186423" title="This method returns the number of layers in the multilayer perceptron.">count_layers_number</a>();
<a name="l02823"></a>02823 
<a name="l02824"></a>02824    <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt; Vector&lt;double&gt;</a> &gt; layers_combination(layers_number);
<a name="l02825"></a>02825    <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt; Vector&lt;double&gt;</a> &gt; layers_activation(layers_number);
<a name="l02826"></a>02826    <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt; Vector&lt;double&gt;</a> &gt; layers_activation_derivative(layers_number);
<a name="l02827"></a>02827 
<a name="l02828"></a>02828    <span class="keywordflow">if</span>(layers_number != 0)
<a name="l02829"></a>02829    {   
<a name="l02830"></a>02830       layers_combination[0] = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#ea970635dd856cb0f9acdf458177312b">layers</a>[0].calculate_combination(inputs);
<a name="l02831"></a>02831       layers_activation[0] = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#ea970635dd856cb0f9acdf458177312b">layers</a>[0].calculate_activation(layers_combination[0]);
<a name="l02832"></a>02832       layers_activation_derivative[0] = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#ea970635dd856cb0f9acdf458177312b">layers</a>[0].calculate_activation_derivative(layers_combination[0]);
<a name="l02833"></a>02833   
<a name="l02834"></a>02834       <span class="keywordflow">for</span>(<span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> i = 1; i &lt; layers_number; i++)
<a name="l02835"></a>02835       {
<a name="l02836"></a>02836          layers_combination[i] = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#ea970635dd856cb0f9acdf458177312b">layers</a>[i].calculate_combination(layers_activation[i-1]);   
<a name="l02837"></a>02837          layers_activation[i] = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#ea970635dd856cb0f9acdf458177312b">layers</a>[i].calculate_activation(layers_combination[i]);
<a name="l02838"></a>02838          layers_activation_derivative[i] = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#ea970635dd856cb0f9acdf458177312b">layers</a>[i].calculate_activation_derivative(layers_combination[i]);         
<a name="l02839"></a>02839       }
<a name="l02840"></a>02840    }
<a name="l02841"></a>02841 
<a name="l02842"></a>02842    <span class="keywordflow">return</span>(layers_activation_derivative);
<a name="l02843"></a>02843 }
<a name="l02844"></a>02844 
<a name="l02845"></a>02845 
<a name="l02846"></a>02846 <span class="comment">// Vector&lt; Vector&lt;double&gt; &gt; calculate_layers_activation_second_derivative(const Vector&lt;double&gt;&amp;) const method</span>
<a name="l02847"></a>02847 
<a name="l02856"></a>02856 
<a name="l02857"></a><a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#3b1cf20d8044673769f8fea64e7b78ec">02857</a> <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt; Vector&lt;double&gt;</a> &gt; <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#3b1cf20d8044673769f8fea64e7b78ec">MultilayerPerceptron::calculate_layers_activation_second_derivative</a>(<span class="keyword">const</span> <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt;double&gt;</a>&amp; inputs)<span class="keyword"> const</span>
<a name="l02858"></a>02858 <span class="keyword"></span>{
<a name="l02859"></a>02859    <span class="comment">// Control sentence (if debug)</span>
<a name="l02860"></a>02860 
<a name="l02861"></a>02861 <span class="preprocessor">   #ifdef _DEBUG </span>
<a name="l02862"></a>02862 <span class="preprocessor"></span>
<a name="l02863"></a>02863    <span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> inputs_size = inputs.size();
<a name="l02864"></a>02864 
<a name="l02865"></a>02865    <span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> inputs_number = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#0998a82ea1845b0fd26872218b02b3f4" title="This method returns the number of inputs to the multilayer perceptron.">count_inputs_number</a>();
<a name="l02866"></a>02866 
<a name="l02867"></a>02867    <span class="keywordflow">if</span>(inputs_size != inputs_number)
<a name="l02868"></a>02868    {
<a name="l02869"></a>02869       std::ostringstream buffer;
<a name="l02870"></a>02870 
<a name="l02871"></a>02871       buffer &lt;&lt; <span class="stringliteral">"OpenNN Exception: MultilayerPerceptron class.\n"</span>
<a name="l02872"></a>02872              &lt;&lt; <span class="stringliteral">"Vector&lt; Vector&lt;double&gt; &gt; calculate_layers_activation_second_derivative(const Vector&lt;double&gt;&amp;) const method.\n"</span>
<a name="l02873"></a>02873              &lt;&lt; <span class="stringliteral">"Size must be equal to number of inputs.\n"</span>;
<a name="l02874"></a>02874 
<a name="l02875"></a>02875           <span class="keywordflow">throw</span> std::logic_error(buffer.str());
<a name="l02876"></a>02876    }
<a name="l02877"></a>02877 
<a name="l02878"></a>02878 <span class="preprocessor">   #endif</span>
<a name="l02879"></a>02879 <span class="preprocessor"></span>
<a name="l02880"></a>02880    <span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> layers_number = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#e5f41a6d170161f9b2896e95bb186423" title="This method returns the number of layers in the multilayer perceptron.">count_layers_number</a>();
<a name="l02881"></a>02881 
<a name="l02882"></a>02882    <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt; Vector&lt;double&gt;</a> &gt; layers_combination(layers_number);
<a name="l02883"></a>02883    <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt; Vector&lt;double&gt;</a> &gt; layers_activation(layers_number);
<a name="l02884"></a>02884    <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt; Vector&lt;double&gt;</a> &gt; layers_activation_second_derivative(layers_number);
<a name="l02885"></a>02885 
<a name="l02886"></a>02886    layers_combination[0] = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#ea970635dd856cb0f9acdf458177312b">layers</a>[0].calculate_combination(inputs);
<a name="l02887"></a>02887    layers_activation[0] = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#ea970635dd856cb0f9acdf458177312b">layers</a>[0].calculate_activation(layers_combination[0]);
<a name="l02888"></a>02888    layers_activation_second_derivative[0] = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#ea970635dd856cb0f9acdf458177312b">layers</a>[0].calculate_activation_second_derivative(layers_combination[0]);
<a name="l02889"></a>02889   
<a name="l02890"></a>02890    <span class="keywordflow">for</span>(<span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> i = 1; i &lt; layers_number; i++)
<a name="l02891"></a>02891    {
<a name="l02892"></a>02892       layers_combination[i] = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#ea970635dd856cb0f9acdf458177312b">layers</a>[i].calculate_combination(layers_activation[i-1]);
<a name="l02893"></a>02893    
<a name="l02894"></a>02894       layers_activation[i] = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#ea970635dd856cb0f9acdf458177312b">layers</a>[i].calculate_activation(layers_combination[i]);
<a name="l02895"></a>02895 
<a name="l02896"></a>02896       layers_activation_second_derivative[i] = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#ea970635dd856cb0f9acdf458177312b">layers</a>[i].calculate_activation_second_derivative(layers_combination[i]);         
<a name="l02897"></a>02897    }
<a name="l02898"></a>02898 
<a name="l02899"></a>02899    <span class="keywordflow">return</span>(layers_activation_second_derivative);
<a name="l02900"></a>02900 }
<a name="l02901"></a>02901 
<a name="l02902"></a>02902 
<a name="l02903"></a>02903 <span class="comment">// Vector&lt; Matrix&lt;double&gt; &gt; calculate_layers_Jacobian(const Vector&lt;double&gt;&amp;) const method</span>
<a name="l02904"></a>02904 
<a name="l02909"></a>02909 
<a name="l02910"></a><a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#53f1a4eb6b4349c26dfeb874113f37d0">02910</a> <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt; Matrix&lt;double&gt;</a> &gt; <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#53f1a4eb6b4349c26dfeb874113f37d0">MultilayerPerceptron::calculate_layers_Jacobian</a>(<span class="keyword">const</span> <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt;double&gt;</a>&amp; inputs)<span class="keyword"> const</span>
<a name="l02911"></a>02911 <span class="keyword"></span>{
<a name="l02912"></a>02912    <span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> layers_number = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#e5f41a6d170161f9b2896e95bb186423" title="This method returns the number of layers in the multilayer perceptron.">count_layers_number</a>();
<a name="l02913"></a>02913 
<a name="l02914"></a>02914    <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt;Vector&lt;double&gt;</a> &gt; layers_output(layers_number);
<a name="l02915"></a>02915    <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt; Matrix&lt;double&gt;</a> &gt; layers_Jacobian(layers_number);
<a name="l02916"></a>02916 
<a name="l02917"></a>02917    layers_output[0] = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#ea970635dd856cb0f9acdf458177312b">layers</a>[0].calculate_outputs(inputs);   
<a name="l02918"></a>02918    layers_Jacobian[0] = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#ea970635dd856cb0f9acdf458177312b">layers</a>[0].calculate_Jacobian(inputs);
<a name="l02919"></a>02919 
<a name="l02920"></a>02920    <span class="keywordflow">for</span>(<span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> i = 1; i &lt; layers_number; i++)
<a name="l02921"></a>02921    {
<a name="l02922"></a>02922       layers_output[i] = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#ea970635dd856cb0f9acdf458177312b">layers</a>[i].calculate_outputs(layers_output[i-1]);         
<a name="l02923"></a>02923 
<a name="l02924"></a>02924       layers_Jacobian[i] = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#ea970635dd856cb0f9acdf458177312b">layers</a>[i].calculate_Jacobian(layers_output[i-1]);
<a name="l02925"></a>02925    }
<a name="l02926"></a>02926 
<a name="l02927"></a>02927    <span class="keywordflow">return</span>(layers_Jacobian);
<a name="l02928"></a>02928 }
<a name="l02929"></a>02929 
<a name="l02930"></a>02930 
<a name="l02931"></a>02931 <span class="comment">// Vector&lt; Matrix&lt;double&gt; &gt; calculate_layers_Jacobian(const Vector&lt;double&gt;&amp;) const method</span>
<a name="l02932"></a>02932 
<a name="l02937"></a>02937 
<a name="l02938"></a><a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#cd80d80291d14b9e677da6fcbeefb674">02938</a> <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt; Vector&lt; Matrix&lt;double&gt;</a> &gt; &gt; <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#cd80d80291d14b9e677da6fcbeefb674">MultilayerPerceptron::calculate_layers_Hessian_form</a>(<span class="keyword">const</span> <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt;double&gt;</a>&amp; inputs)<span class="keyword"> const</span>
<a name="l02939"></a>02939 <span class="keyword"></span>{
<a name="l02940"></a>02940    <span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> layers_number = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#e5f41a6d170161f9b2896e95bb186423" title="This method returns the number of layers in the multilayer perceptron.">count_layers_number</a>();
<a name="l02941"></a>02941 
<a name="l02942"></a>02942    <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt;Vector&lt;double&gt;</a> &gt; layers_output(layers_number);
<a name="l02943"></a>02943    <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt; Vector&lt; Matrix&lt;double&gt;</a> &gt; &gt; layers_Hessian_form(layers_number);
<a name="l02944"></a>02944 
<a name="l02945"></a>02945    layers_output[0] = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#ea970635dd856cb0f9acdf458177312b">layers</a>[0].calculate_outputs(inputs);   
<a name="l02946"></a>02946    layers_Hessian_form[0] = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#ea970635dd856cb0f9acdf458177312b">layers</a>[0].calculate_Hessian_form(inputs);
<a name="l02947"></a>02947 
<a name="l02948"></a>02948    <span class="keywordflow">for</span>(<span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> i = 1; i &lt; layers_number; i++)
<a name="l02949"></a>02949    {
<a name="l02950"></a>02950       layers_output[i] = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#ea970635dd856cb0f9acdf458177312b">layers</a>[i].calculate_outputs(layers_output[i-1]);         
<a name="l02951"></a>02951 
<a name="l02952"></a>02952       layers_Hessian_form[i] = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#ea970635dd856cb0f9acdf458177312b">layers</a>[i].calculate_Hessian_form(layers_output[i-1]);
<a name="l02953"></a>02953    }
<a name="l02954"></a>02954 
<a name="l02955"></a>02955    <span class="keywordflow">return</span>(layers_Hessian_form);
<a name="l02956"></a>02956 }
<a name="l02957"></a>02957 
<a name="l02958"></a>02958 
<a name="l02959"></a>02959 <span class="comment">// Matrix&lt; Matrix&lt;double&gt; &gt; calculate_interlayers_combination_combination_Jacobian(const Vector&lt;double&gt;&amp;) const method</span>
<a name="l02960"></a>02960 
<a name="l02964"></a>02964 
<a name="l02965"></a><a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#340d2954d200c8e690df333c91f76d18">02965</a> <a class="code" href="class_open_n_n_1_1_matrix.html">Matrix&lt; Matrix&lt;double&gt;</a> &gt; <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#340d2954d200c8e690df333c91f76d18">MultilayerPerceptron::calculate_interlayers_combination_combination_Jacobian</a>(<span class="keyword">const</span> <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt;double&gt;</a>&amp; inputs)<span class="keyword"> const  </span>
<a name="l02966"></a>02966 <span class="keyword"></span>{
<a name="l02967"></a>02967 <span class="preprocessor">   #ifdef _DEBUG </span>
<a name="l02968"></a>02968 <span class="preprocessor"></span>
<a name="l02969"></a>02969    <span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> size = inputs.size();
<a name="l02970"></a>02970 
<a name="l02971"></a>02971    <span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> inputs_number = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#0998a82ea1845b0fd26872218b02b3f4" title="This method returns the number of inputs to the multilayer perceptron.">count_inputs_number</a>();
<a name="l02972"></a>02972 
<a name="l02973"></a>02973    <span class="keywordflow">if</span>(size != inputs_number)
<a name="l02974"></a>02974    {
<a name="l02975"></a>02975       std::ostringstream buffer;
<a name="l02976"></a>02976 
<a name="l02977"></a>02977       buffer &lt;&lt; <span class="stringliteral">"OpenNN Exception: MultilayerPerceptron class.\n"</span>
<a name="l02978"></a>02978              &lt;&lt; <span class="stringliteral">"Matrix&lt; Matrix&lt;double&gt; &gt; calculate_interlayers_combination_combination_Jacobian(const Vector&lt;double&gt;&amp;) const method.\n"</span>
<a name="l02979"></a>02979              &lt;&lt; <span class="stringliteral">"Size of inpouts must be equal to number of inputs.\n"</span>;
<a name="l02980"></a>02980 
<a name="l02981"></a>02981           <span class="keywordflow">throw</span> std::logic_error(buffer.str());
<a name="l02982"></a>02982    }
<a name="l02983"></a>02983 
<a name="l02984"></a>02984 <span class="preprocessor">   #endif</span>
<a name="l02985"></a>02985 <span class="preprocessor"></span>
<a name="l02986"></a>02986    <span class="keyword">const</span> <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt; Vector&lt;double&gt;</a> &gt; layers_combination = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#04018070fb619f5b6e77d046634cdadc">calculate_layers_combination</a>(inputs);
<a name="l02987"></a>02987 
<a name="l02988"></a>02988    <span class="keywordflow">return</span>(<a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#340d2954d200c8e690df333c91f76d18">calculate_interlayers_combination_combination_Jacobian</a>(layers_combination));
<a name="l02989"></a>02989 }
<a name="l02990"></a>02990 
<a name="l02991"></a>02991 
<a name="l02992"></a>02992 <span class="comment">// Matrix &lt;Matrix&lt;double&gt; &gt; calculate_interlayers_combination_combination_Jacobian(const Vector&lt; Vector&lt;double&gt; &gt;&amp;) const method</span>
<a name="l02993"></a>02993 
<a name="l02997"></a>02997 
<a name="l02998"></a><a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#9613d62fe2046ac289b5a8057acefdef">02998</a> <a class="code" href="class_open_n_n_1_1_matrix.html">Matrix &lt; Matrix&lt;double&gt;</a> &gt; <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#340d2954d200c8e690df333c91f76d18">MultilayerPerceptron::calculate_interlayers_combination_combination_Jacobian</a>(<span class="keyword">const</span> <a class="code" href="class_open_n_n_1_1_vector.html">Vector</a>&lt; <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt;double&gt;</a> &gt;&amp; layers_combination)<span class="keyword"> const   </span>
<a name="l02999"></a>02999 <span class="keyword"></span>{
<a name="l03000"></a>03000    <span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> layers_number = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#e5f41a6d170161f9b2896e95bb186423" title="This method returns the number of layers in the multilayer perceptron.">count_layers_number</a>();
<a name="l03001"></a>03001 
<a name="l03002"></a>03002 <span class="preprocessor">   #ifdef _DEBUG </span>
<a name="l03003"></a>03003 <span class="preprocessor"></span>
<a name="l03004"></a>03004    <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> size;
<a name="l03005"></a>03005 
<a name="l03006"></a>03006    <span class="keyword">const</span> <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt;unsigned int&gt;</a> layers_size = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#bac4febc8f59639eadd9d8b896148f5e" title="This method returns a vector with the size of each layer.">arrange_layers_perceptrons_numbers</a>();
<a name="l03007"></a>03007 
<a name="l03008"></a>03008    <span class="keywordflow">for</span>(<span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> i = 0; i &lt; layers_number; i++)
<a name="l03009"></a>03009    {
<a name="l03010"></a>03010       size = layers_combination[i].size();
<a name="l03011"></a>03011 
<a name="l03012"></a>03012       <span class="keywordflow">if</span>(size != layers_size[i])
<a name="l03013"></a>03013       {
<a name="l03014"></a>03014          std::ostringstream buffer;
<a name="l03015"></a>03015 
<a name="l03016"></a>03016          buffer &lt;&lt; <span class="stringliteral">"OpenNN Exception: MultilayerPerceptron class.\n"</span>
<a name="l03017"></a>03017                 &lt;&lt; <span class="stringliteral">"Matrix&lt; Matrix&lt;double&gt; &gt; calculate_interlayers_combination_combination_Jacobian(const Vector&lt; Vector&lt;double&gt; &gt;&amp;) const method.\n"</span>
<a name="l03018"></a>03018                 &lt;&lt; <span class="stringliteral">"Size must be equal to size of layer.\n"</span>;
<a name="l03019"></a>03019 
<a name="l03020"></a>03020              <span class="keywordflow">throw</span> std::logic_error(buffer.str());
<a name="l03021"></a>03021       }
<a name="l03022"></a>03022    }
<a name="l03023"></a>03023 
<a name="l03024"></a>03024 <span class="preprocessor">   #endif</span>
<a name="l03025"></a>03025 <span class="preprocessor"></span>
<a name="l03026"></a>03026    <span class="comment">// Calculate interlayers combination combination Jacobian</span>
<a name="l03027"></a>03027 
<a name="l03028"></a>03028    <a class="code" href="class_open_n_n_1_1_matrix.html">Matrix&lt; Matrix&lt;double&gt;</a> &gt; interlayers_combination_combination_Jacobian(layers_number, layers_number);
<a name="l03029"></a>03029 
<a name="l03030"></a>03030    <span class="keywordflow">for</span>(<span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> image_index = 0; image_index &lt; layers_number; image_index++)
<a name="l03031"></a>03031    {
<a name="l03032"></a>03032       <span class="keywordflow">for</span>(<span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> domain_index = 0; domain_index &lt; layers_number; domain_index++)
<a name="l03033"></a>03033       {
<a name="l03034"></a>03034          interlayers_combination_combination_Jacobian[image_index][domain_index] = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#c6e766fbd7845f7d47b83da12705d866">calculate_interlayer_combination_combination_Jacobian</a>(domain_index, image_index, layers_combination[domain_index]); 
<a name="l03035"></a>03035       }
<a name="l03036"></a>03036    }
<a name="l03037"></a>03037 
<a name="l03038"></a>03038    <span class="keywordflow">return</span>(interlayers_combination_combination_Jacobian);
<a name="l03039"></a>03039 }
<a name="l03040"></a>03040 
<a name="l03041"></a>03041 
<a name="l03042"></a>03042 <span class="comment">// Vector&lt; Vector&lt; Vector&lt;double&gt; &gt; &gt; calculate_first_order_forward_propagation(const Vector&lt;double&gt;&amp;) const method</span>
<a name="l03043"></a>03043 
<a name="l03051"></a>03051 
<a name="l03052"></a><a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#502cacdc7e9372cb636150133db135cd">03052</a> <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt; Vector&lt; Vector&lt;double&gt;</a> &gt; &gt; <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#502cacdc7e9372cb636150133db135cd">MultilayerPerceptron::calculate_first_order_forward_propagation</a>(<span class="keyword">const</span> <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt;double&gt;</a>&amp; inputs)<span class="keyword"> const</span>
<a name="l03053"></a>03053 <span class="keyword"></span>{
<a name="l03054"></a>03054    <span class="comment">// Control sentence (if debug)</span>
<a name="l03055"></a>03055 
<a name="l03056"></a>03056 <span class="preprocessor">   #ifdef _DEBUG </span>
<a name="l03057"></a>03057 <span class="preprocessor"></span>
<a name="l03058"></a>03058    <span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> inputs_size = inputs.size();
<a name="l03059"></a>03059 
<a name="l03060"></a>03060    <span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> inputs_number = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#0998a82ea1845b0fd26872218b02b3f4" title="This method returns the number of inputs to the multilayer perceptron.">count_inputs_number</a>();
<a name="l03061"></a>03061 
<a name="l03062"></a>03062    <span class="keywordflow">if</span>(inputs_size != inputs_number)
<a name="l03063"></a>03063    {
<a name="l03064"></a>03064       std::ostringstream buffer;
<a name="l03065"></a>03065 
<a name="l03066"></a>03066       buffer &lt;&lt; <span class="stringliteral">"OpenNN Exception: MultilayerPerceptron class.\n"</span>
<a name="l03067"></a>03067              &lt;&lt; <span class="stringliteral">"Vector&lt; Vector&lt; Vector&lt;double&gt; &gt; &gt; calculate_first_order_forward_propagation(const Vector&lt;double&gt;&amp;) const method.\n"</span>
<a name="l03068"></a>03068              &lt;&lt; <span class="stringliteral">"Size must be equal to number of inputs.\n"</span>;
<a name="l03069"></a>03069 
<a name="l03070"></a>03070           <span class="keywordflow">throw</span> std::logic_error(buffer.str());
<a name="l03071"></a>03071    }
<a name="l03072"></a>03072 
<a name="l03073"></a>03073 <span class="preprocessor">   #endif</span>
<a name="l03074"></a>03074 <span class="preprocessor"></span>
<a name="l03075"></a>03075    <span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> layers_number = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#e5f41a6d170161f9b2896e95bb186423" title="This method returns the number of layers in the multilayer perceptron.">count_layers_number</a>();
<a name="l03076"></a>03076 
<a name="l03077"></a>03077    <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt; Vector&lt;double&gt;</a> &gt; layers_combination(layers_number);
<a name="l03078"></a>03078 
<a name="l03079"></a>03079    <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt; Vector&lt; Vector&lt;double&gt;</a> &gt; &gt; first_order_forward_propagation(2);
<a name="l03080"></a>03080 
<a name="l03081"></a>03081    first_order_forward_propagation[0].<a class="code" href="class_open_n_n_1_1_vector.html#78a81ff993befcd4e75ab75da2976a9a" title="This method sets the size of a vector to zero.">set</a>(layers_number);
<a name="l03082"></a>03082    first_order_forward_propagation[1].<a class="code" href="class_open_n_n_1_1_vector.html#78a81ff993befcd4e75ab75da2976a9a" title="This method sets the size of a vector to zero.">set</a>(layers_number);
<a name="l03083"></a>03083 
<a name="l03084"></a>03084    layers_combination[0] = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#ea970635dd856cb0f9acdf458177312b">layers</a>[0].calculate_combination(inputs);
<a name="l03085"></a>03085 
<a name="l03086"></a>03086    first_order_forward_propagation[0][0] = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#ea970635dd856cb0f9acdf458177312b">layers</a>[0].calculate_activation(layers_combination[0]);
<a name="l03087"></a>03087 
<a name="l03088"></a>03088    first_order_forward_propagation[1][0] = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#ea970635dd856cb0f9acdf458177312b">layers</a>[0].calculate_activation_derivative(layers_combination[0]);
<a name="l03089"></a>03089 
<a name="l03090"></a>03090    <span class="keywordflow">for</span>(<span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> i = 1; i &lt; layers_number; i++)
<a name="l03091"></a>03091    {
<a name="l03092"></a>03092       layers_combination[i] = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#ea970635dd856cb0f9acdf458177312b">layers</a>[i].calculate_combination(first_order_forward_propagation[0][i-1]);
<a name="l03093"></a>03093 
<a name="l03094"></a>03094       first_order_forward_propagation[0][i] = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#ea970635dd856cb0f9acdf458177312b">layers</a>[i].calculate_activation(layers_combination[i]);
<a name="l03095"></a>03095 
<a name="l03096"></a>03096       first_order_forward_propagation[1][i] = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#ea970635dd856cb0f9acdf458177312b">layers</a>[i].calculate_activation_derivative(layers_combination[i]);
<a name="l03097"></a>03097    }
<a name="l03098"></a>03098 
<a name="l03099"></a>03099    <span class="keywordflow">return</span>(first_order_forward_propagation);
<a name="l03100"></a>03100 }
<a name="l03101"></a>03101 
<a name="l03102"></a>03102 
<a name="l03103"></a>03103 <span class="comment">// Vector&lt; Vector&lt; Vector&lt;double&gt; &gt; &gt; calculate_second_order_forward_propagation(const Vector&lt;double&gt;&amp;) const method</span>
<a name="l03104"></a>03104 
<a name="l03112"></a>03112 
<a name="l03113"></a><a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#52ecb5cf7502479a9cf83ff9c9dd1789">03113</a> <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt; Vector&lt; Vector&lt;double&gt;</a> &gt; &gt; <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#52ecb5cf7502479a9cf83ff9c9dd1789">MultilayerPerceptron::calculate_second_order_forward_propagation</a>(<span class="keyword">const</span> <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt;double&gt;</a>&amp; inputs)<span class="keyword"> const</span>
<a name="l03114"></a>03114 <span class="keyword"></span>{
<a name="l03115"></a>03115    <span class="comment">// Control sentence (if debug)</span>
<a name="l03116"></a>03116 
<a name="l03117"></a>03117 <span class="preprocessor">   #ifdef _DEBUG </span>
<a name="l03118"></a>03118 <span class="preprocessor"></span>
<a name="l03119"></a>03119    <span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> inputs_size = inputs.size();
<a name="l03120"></a>03120 
<a name="l03121"></a>03121    <span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> inputs_number = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#0998a82ea1845b0fd26872218b02b3f4" title="This method returns the number of inputs to the multilayer perceptron.">count_inputs_number</a>();
<a name="l03122"></a>03122 
<a name="l03123"></a>03123    <span class="keywordflow">if</span>(inputs_size != inputs_number)
<a name="l03124"></a>03124    {
<a name="l03125"></a>03125       std::ostringstream buffer;
<a name="l03126"></a>03126 
<a name="l03127"></a>03127       buffer &lt;&lt; <span class="stringliteral">"OpenNN Exception: MultilayerPerceptron class.\n"</span>
<a name="l03128"></a>03128              &lt;&lt; <span class="stringliteral">"Vector&lt; Vector&lt; Vector&lt;double&gt; &gt; &gt; calculate_second_order_forward_propagation(const Vector&lt;double&gt;&amp;) const method.\n"</span>
<a name="l03129"></a>03129              &lt;&lt; <span class="stringliteral">"Size of multilayer_perceptron_pointer inputs must be equal to number of inputs.\n"</span>;
<a name="l03130"></a>03130 
<a name="l03131"></a>03131           <span class="keywordflow">throw</span> std::logic_error(buffer.str());
<a name="l03132"></a>03132    }
<a name="l03133"></a>03133 
<a name="l03134"></a>03134 <span class="preprocessor">   #endif</span>
<a name="l03135"></a>03135 <span class="preprocessor"></span>
<a name="l03136"></a>03136    <span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> layers_number = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#e5f41a6d170161f9b2896e95bb186423" title="This method returns the number of layers in the multilayer perceptron.">count_layers_number</a>();
<a name="l03137"></a>03137 
<a name="l03138"></a>03138    <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt; Vector&lt;double&gt;</a> &gt; layers_combination(layers_number);
<a name="l03139"></a>03139 
<a name="l03140"></a>03140    <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt; Vector&lt; Vector&lt;double&gt;</a> &gt; &gt; second_order_forward_propagation(3);
<a name="l03141"></a>03141 
<a name="l03142"></a>03142    second_order_forward_propagation[0].<a class="code" href="class_open_n_n_1_1_vector.html#78a81ff993befcd4e75ab75da2976a9a" title="This method sets the size of a vector to zero.">set</a>(layers_number);
<a name="l03143"></a>03143    second_order_forward_propagation[1].<a class="code" href="class_open_n_n_1_1_vector.html#78a81ff993befcd4e75ab75da2976a9a" title="This method sets the size of a vector to zero.">set</a>(layers_number);
<a name="l03144"></a>03144    second_order_forward_propagation[2].<a class="code" href="class_open_n_n_1_1_vector.html#78a81ff993befcd4e75ab75da2976a9a" title="This method sets the size of a vector to zero.">set</a>(layers_number);
<a name="l03145"></a>03145 
<a name="l03146"></a>03146    layers_combination[0] = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#ea970635dd856cb0f9acdf458177312b">layers</a>[0].calculate_combination(inputs);
<a name="l03147"></a>03147 
<a name="l03148"></a>03148    second_order_forward_propagation[0][0] = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#ea970635dd856cb0f9acdf458177312b">layers</a>[0].calculate_activation(layers_combination[0]);
<a name="l03149"></a>03149   
<a name="l03150"></a>03150    second_order_forward_propagation[1][0] = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#ea970635dd856cb0f9acdf458177312b">layers</a>[0].calculate_activation_derivative(layers_combination[0]);
<a name="l03151"></a>03151 
<a name="l03152"></a>03152    second_order_forward_propagation[2][0] = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#ea970635dd856cb0f9acdf458177312b">layers</a>[0].calculate_activation_second_derivative(layers_combination[0]);
<a name="l03153"></a>03153 
<a name="l03154"></a>03154    <span class="keywordflow">for</span>(<span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> i = 1; i &lt; layers_number; i++)
<a name="l03155"></a>03155    {
<a name="l03156"></a>03156       layers_combination[i] = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#ea970635dd856cb0f9acdf458177312b">layers</a>[i].calculate_combination(second_order_forward_propagation[0][i-1]);
<a name="l03157"></a>03157 
<a name="l03158"></a>03158       second_order_forward_propagation[0][i] = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#ea970635dd856cb0f9acdf458177312b">layers</a>[i].calculate_activation(layers_combination[i]);
<a name="l03159"></a>03159 
<a name="l03160"></a>03160       second_order_forward_propagation[1][i] = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#ea970635dd856cb0f9acdf458177312b">layers</a>[i].calculate_activation_derivative(layers_combination[i]);
<a name="l03161"></a>03161 
<a name="l03162"></a>03162       second_order_forward_propagation[2][i] = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#ea970635dd856cb0f9acdf458177312b">layers</a>[i].calculate_activation_second_derivative(layers_combination[i]);
<a name="l03163"></a>03163    }
<a name="l03164"></a>03164 
<a name="l03165"></a>03165    <span class="keywordflow">return</span>(second_order_forward_propagation);
<a name="l03166"></a>03166 }
<a name="l03167"></a>03167 
<a name="l03168"></a>03168 
<a name="l03169"></a>03169 <span class="comment">// std::string to_string(void) const method</span>
<a name="l03170"></a>03170 
<a name="l03172"></a>03172 
<a name="l03173"></a><a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#fd0656a5ad5ce080223e196b4891bcd3">03173</a> std::string <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#fd0656a5ad5ce080223e196b4891bcd3" title="This method returns a string representation of the current multilayer perceptron...">MultilayerPerceptron::to_string</a>(<span class="keywordtype">void</span>)<span class="keyword"> const</span>
<a name="l03174"></a>03174 <span class="keyword"></span>{
<a name="l03175"></a>03175    std::ostringstream buffer;
<a name="l03176"></a>03176 
<a name="l03177"></a>03177    buffer &lt;&lt; <span class="stringliteral">"MultilayerPerceptron\n"</span>
<a name="l03178"></a>03178           &lt;&lt; <span class="stringliteral">"Architecture: "</span> &lt;&lt; <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#29504bd86365a7f4786e018b1db06cdb">arrange_architecture</a>() &lt;&lt; <span class="stringliteral">"\n"</span>
<a name="l03179"></a>03179           &lt;&lt; <span class="stringliteral">"Layers activation function: "</span> &lt;&lt; <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#b138e01b62f7638306d8d48d37d5347d">write_layers_activation_function</a>() &lt;&lt; <span class="stringliteral">"\n"</span>
<a name="l03180"></a>03180           &lt;&lt; <span class="stringliteral">"Parameters: "</span> &lt;&lt; <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#598b7b498c5f6adf417f84abad92f9fc" title="This method returns the values of all the biases and synaptic weights in the multilayer...">arrange_parameters</a>() &lt;&lt; <span class="stringliteral">"\n"</span>
<a name="l03181"></a>03181           &lt;&lt; <span class="stringliteral">"Display: "</span> &lt;&lt; <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#24c63c4f903e9cbde9beabca81a6682f" title="Display messages to screen.">display</a> &lt;&lt; <span class="stringliteral">"\n"</span>;
<a name="l03182"></a>03182 
<a name="l03183"></a>03183    <span class="keywordflow">return</span>(buffer.str());
<a name="l03184"></a>03184 }
<a name="l03185"></a>03185 
<a name="l03186"></a>03186 
<a name="l03187"></a>03187 <span class="comment">// TiXmlElement* to_XML(void) const method</span>
<a name="l03188"></a>03188 
<a name="l03191"></a>03191 
<a name="l03192"></a><a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#271febe4614cc9389df264c189aebd7e">03192</a> TiXmlElement* <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#271febe4614cc9389df264c189aebd7e">MultilayerPerceptron::to_XML</a>(<span class="keywordtype">void</span>)<span class="keyword"> const</span>
<a name="l03193"></a>03193 <span class="keyword"></span>{
<a name="l03194"></a>03194    std::ostringstream buffer;
<a name="l03195"></a>03195 
<a name="l03196"></a>03196    TiXmlElement* multilayer_perceptron_element = <span class="keyword">new</span> TiXmlElement(<span class="stringliteral">"MultilayerPerceptron"</span>);
<a name="l03197"></a>03197    multilayer_perceptron_element-&gt;SetAttribute(<span class="stringliteral">"Version"</span>, 4);
<a name="l03198"></a>03198 
<a name="l03199"></a>03199    <span class="comment">// Architecture</span>
<a name="l03200"></a>03200    {
<a name="l03201"></a>03201       TiXmlElement* architecture_element = <span class="keyword">new</span> TiXmlElement(<span class="stringliteral">"Architecture"</span>);
<a name="l03202"></a>03202       multilayer_perceptron_element-&gt;LinkEndChild(architecture_element);
<a name="l03203"></a>03203 
<a name="l03204"></a>03204       std::string architecture_string = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#29504bd86365a7f4786e018b1db06cdb">arrange_architecture</a>().<a class="code" href="class_open_n_n_1_1_vector.html#daf46719944c88b9f888debc1bd947c1" title="This method returns a string representation of this vector.">to_string</a>();
<a name="l03205"></a>03205 
<a name="l03206"></a>03206       TiXmlText* architecture_text = <span class="keyword">new</span> TiXmlText(architecture_string.c_str());
<a name="l03207"></a>03207       architecture_element-&gt;LinkEndChild(architecture_text);
<a name="l03208"></a>03208    }
<a name="l03209"></a>03209 
<a name="l03210"></a>03210    <span class="comment">// Layers activation function</span>
<a name="l03211"></a>03211    {
<a name="l03212"></a>03212       TiXmlElement* layers_activation_function_element = <span class="keyword">new</span> TiXmlElement(<span class="stringliteral">"LayersActivationFunction"</span>);
<a name="l03213"></a>03213       multilayer_perceptron_element-&gt;LinkEndChild(layers_activation_function_element);
<a name="l03214"></a>03214 
<a name="l03215"></a>03215       std::string layers_activation_function_string = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#b138e01b62f7638306d8d48d37d5347d">write_layers_activation_function</a>().<a class="code" href="class_open_n_n_1_1_vector.html#daf46719944c88b9f888debc1bd947c1" title="This method returns a string representation of this vector.">to_string</a>();
<a name="l03216"></a>03216 
<a name="l03217"></a>03217       TiXmlText* layers_activation_function_text = <span class="keyword">new</span> TiXmlText(layers_activation_function_string.c_str());
<a name="l03218"></a>03218       layers_activation_function_element-&gt;LinkEndChild(layers_activation_function_text);
<a name="l03219"></a>03219    }
<a name="l03220"></a>03220 
<a name="l03221"></a>03221    <span class="comment">// Parameters </span>
<a name="l03222"></a>03222    {
<a name="l03223"></a>03223       TiXmlElement* parameters_element = <span class="keyword">new</span> TiXmlElement(<span class="stringliteral">"Parameters"</span>);
<a name="l03224"></a>03224       multilayer_perceptron_element-&gt;LinkEndChild(parameters_element);
<a name="l03225"></a>03225 
<a name="l03226"></a>03226       std::string parameters_string = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#598b7b498c5f6adf417f84abad92f9fc" title="This method returns the values of all the biases and synaptic weights in the multilayer...">arrange_parameters</a>().<a class="code" href="class_open_n_n_1_1_vector.html#daf46719944c88b9f888debc1bd947c1" title="This method returns a string representation of this vector.">to_string</a>();
<a name="l03227"></a>03227 
<a name="l03228"></a>03228       TiXmlText* parameters_text = <span class="keyword">new</span> TiXmlText(parameters_string.c_str());
<a name="l03229"></a>03229       parameters_element-&gt;LinkEndChild(parameters_text);
<a name="l03230"></a>03230    }
<a name="l03231"></a>03231 
<a name="l03232"></a>03232    <span class="comment">// Display</span>
<a name="l03233"></a>03233    {
<a name="l03234"></a>03234       TiXmlElement* display_element = <span class="keyword">new</span> TiXmlElement(<span class="stringliteral">"Display"</span>);
<a name="l03235"></a>03235       multilayer_perceptron_element-&gt;LinkEndChild(display_element);
<a name="l03236"></a>03236 
<a name="l03237"></a>03237       buffer.str(<span class="stringliteral">""</span>);
<a name="l03238"></a>03238       buffer &lt;&lt; <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#24c63c4f903e9cbde9beabca81a6682f" title="Display messages to screen.">display</a>;
<a name="l03239"></a>03239 
<a name="l03240"></a>03240       TiXmlText* display_text = <span class="keyword">new</span> TiXmlText(buffer.str().c_str());
<a name="l03241"></a>03241       display_element-&gt;LinkEndChild(display_text);
<a name="l03242"></a>03242    }
<a name="l03243"></a>03243 
<a name="l03244"></a>03244    <span class="keywordflow">return</span>(multilayer_perceptron_element);
<a name="l03245"></a>03245 }
<a name="l03246"></a>03246 
<a name="l03247"></a>03247 
<a name="l03248"></a>03248 <span class="comment">// void from_XML(TiXmlElement*) method</span>
<a name="l03249"></a>03249 
<a name="l03252"></a>03252 
<a name="l03253"></a><a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#f247ff15c6b71a5560689aa587fddab7">03253</a> <span class="keywordtype">void</span> <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#f247ff15c6b71a5560689aa587fddab7">MultilayerPerceptron::from_XML</a>(TiXmlElement* multilayer_perceptron_element)
<a name="l03254"></a>03254 {
<a name="l03255"></a>03255    <span class="keywordflow">if</span>(multilayer_perceptron_element)
<a name="l03256"></a>03256    {
<a name="l03257"></a>03257       <span class="comment">// Architecture</span>
<a name="l03258"></a>03258       {
<a name="l03259"></a>03259          TiXmlElement* architecture_element = multilayer_perceptron_element-&gt;FirstChildElement(<span class="stringliteral">"Architecture"</span>);
<a name="l03260"></a>03260 
<a name="l03261"></a>03261          <span class="keywordflow">if</span>(architecture_element)
<a name="l03262"></a>03262          {
<a name="l03263"></a>03263             <span class="keyword">const</span> <span class="keywordtype">char</span>* architecture_text = architecture_element-&gt;GetText();
<a name="l03264"></a>03264 
<a name="l03265"></a>03265             <span class="keywordflow">if</span>(architecture_text)
<a name="l03266"></a>03266             {
<a name="l03267"></a>03267                <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt;unsigned int&gt;</a> new_architecture;                  
<a name="l03268"></a>03268                new_architecture.<a class="code" href="class_open_n_n_1_1_vector.html#3ab772354ec4bfa71f17e1bd251dc2f4">parse</a>(architecture_text);
<a name="l03269"></a>03269 
<a name="l03270"></a>03270                <span class="keywordflow">try</span>
<a name="l03271"></a>03271                {
<a name="l03272"></a>03272                   <span class="keyword">set</span>(new_architecture);
<a name="l03273"></a>03273                }
<a name="l03274"></a>03274                <span class="keywordflow">catch</span>(std::exception&amp; e)
<a name="l03275"></a>03275                {
<a name="l03276"></a>03276                   std::cout &lt;&lt; e.what() &lt;&lt; std::endl;            
<a name="l03277"></a>03277                }
<a name="l03278"></a>03278             }
<a name="l03279"></a>03279          }
<a name="l03280"></a>03280       }
<a name="l03281"></a>03281 
<a name="l03282"></a>03282       <span class="comment">// Layers activation function</span>
<a name="l03283"></a>03283       {
<a name="l03284"></a>03284          TiXmlElement* layers_activation_function_element = multilayer_perceptron_element-&gt;FirstChildElement(<span class="stringliteral">"LayersActivationFunction"</span>);
<a name="l03285"></a>03285 
<a name="l03286"></a>03286          <span class="keywordflow">if</span>(layers_activation_function_element)
<a name="l03287"></a>03287          {      
<a name="l03288"></a>03288             <span class="keyword">const</span> <span class="keywordtype">char</span>* layers_activation_function_text = layers_activation_function_element-&gt;GetText();
<a name="l03289"></a>03289    
<a name="l03290"></a>03290             <span class="keywordflow">if</span>(layers_activation_function_text)
<a name="l03291"></a>03291             {
<a name="l03292"></a>03292                <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt;std::string&gt;</a> new_layers_activation_function;                  
<a name="l03293"></a>03293                new_layers_activation_function.<a class="code" href="class_open_n_n_1_1_vector.html#3ab772354ec4bfa71f17e1bd251dc2f4">parse</a>(layers_activation_function_text);
<a name="l03294"></a>03294 
<a name="l03295"></a>03295                <span class="keywordflow">try</span>
<a name="l03296"></a>03296                {
<a name="l03297"></a>03297                   <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#37e821e19f542937d190cb0c61845769">set_layers_activation_function</a>(new_layers_activation_function);
<a name="l03298"></a>03298                }
<a name="l03299"></a>03299                <span class="keywordflow">catch</span>(std::exception&amp; e)
<a name="l03300"></a>03300                {
<a name="l03301"></a>03301                   std::cout &lt;&lt; e.what() &lt;&lt; std::endl;            
<a name="l03302"></a>03302                }
<a name="l03303"></a>03303             }
<a name="l03304"></a>03304          }
<a name="l03305"></a>03305       }
<a name="l03306"></a>03306 
<a name="l03307"></a>03307       <span class="comment">// Parameters </span>
<a name="l03308"></a>03308       {
<a name="l03309"></a>03309          TiXmlElement* parameters_element = multilayer_perceptron_element-&gt;FirstChildElement(<span class="stringliteral">"Parameters"</span>);
<a name="l03310"></a>03310 
<a name="l03311"></a>03311          <span class="keywordflow">if</span>(parameters_element)
<a name="l03312"></a>03312          {
<a name="l03313"></a>03313             <span class="keyword">const</span> <span class="keywordtype">char</span>* parameters_text = parameters_element-&gt;GetText();
<a name="l03314"></a>03314 
<a name="l03315"></a>03315             <span class="keywordflow">if</span>(parameters_text)
<a name="l03316"></a>03316             {
<a name="l03317"></a>03317                <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt;double&gt;</a> new_parameters;                  
<a name="l03318"></a>03318                new_parameters.<a class="code" href="class_open_n_n_1_1_vector.html#3ab772354ec4bfa71f17e1bd251dc2f4">parse</a>(parameters_text);
<a name="l03319"></a>03319 
<a name="l03320"></a>03320                <span class="keywordflow">try</span>
<a name="l03321"></a>03321                {
<a name="l03322"></a>03322                   <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#b15a55807eb7d574061178c7d701985d">set_parameters</a>(new_parameters);
<a name="l03323"></a>03323                }
<a name="l03324"></a>03324                <span class="keywordflow">catch</span>(std::exception&amp; e)
<a name="l03325"></a>03325                {
<a name="l03326"></a>03326                   std::cout &lt;&lt; e.what() &lt;&lt; std::endl;            
<a name="l03327"></a>03327                }
<a name="l03328"></a>03328             }
<a name="l03329"></a>03329          }
<a name="l03330"></a>03330       }
<a name="l03331"></a>03331 
<a name="l03332"></a>03332       <span class="comment">// Display </span>
<a name="l03333"></a>03333       {         
<a name="l03334"></a>03334          TiXmlElement* display_element = multilayer_perceptron_element-&gt;FirstChildElement(<span class="stringliteral">"Display"</span>);
<a name="l03335"></a>03335 
<a name="l03336"></a>03336          <span class="keywordflow">if</span>(<a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#24c63c4f903e9cbde9beabca81a6682f" title="Display messages to screen.">display</a>)
<a name="l03337"></a>03337          {
<a name="l03338"></a>03338             std::string new_display_string = display_element-&gt;GetText();     
<a name="l03339"></a>03339 
<a name="l03340"></a>03340             <span class="keywordflow">try</span>
<a name="l03341"></a>03341             {
<a name="l03342"></a>03342                <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#b1dab55d760434a9243259492797ec82">set_display</a>(new_display_string != <span class="stringliteral">"0"</span>);
<a name="l03343"></a>03343             }
<a name="l03344"></a>03344             <span class="keywordflow">catch</span>(std::exception&amp; e)
<a name="l03345"></a>03345             {
<a name="l03346"></a>03346                std::cout &lt;&lt; e.what() &lt;&lt; std::endl;               
<a name="l03347"></a>03347             }
<a name="l03348"></a>03348          }
<a name="l03349"></a>03349       }
<a name="l03350"></a>03350    }
<a name="l03351"></a>03351 }
<a name="l03352"></a>03352 
<a name="l03353"></a>03353 
<a name="l03354"></a>03354 <span class="comment">// std::string write_expression(const Vector&lt;std::string&gt;&amp;, const Vector&lt;std::string&gt;&amp;) const method</span>
<a name="l03355"></a>03355 
<a name="l03358"></a>03358 
<a name="l03359"></a><a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#2835652ed82842f5e802f202c8fc0123">03359</a> std::string <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#2835652ed82842f5e802f202c8fc0123">MultilayerPerceptron::write_expression</a>(<span class="keyword">const</span> <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt;std::string&gt;</a>&amp; inputs_name, <span class="keyword">const</span> <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt;std::string&gt;</a>&amp; outputs_name)<span class="keyword"> const</span>
<a name="l03360"></a>03360 <span class="keyword"></span>{
<a name="l03361"></a>03361    <span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> layers_number = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#e5f41a6d170161f9b2896e95bb186423" title="This method returns the number of layers in the multilayer perceptron.">count_layers_number</a>();
<a name="l03362"></a>03362    <span class="keyword">const</span> <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt;unsigned int&gt;</a> layers_perceptrons_number = <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#bac4febc8f59639eadd9d8b896148f5e" title="This method returns a vector with the size of each layer.">arrange_layers_perceptrons_numbers</a>();
<a name="l03363"></a>03363 
<a name="l03364"></a>03364    std::ostringstream buffer;
<a name="l03365"></a>03365 
<a name="l03366"></a>03366    <span class="keywordflow">if</span>(layers_number == 0)
<a name="l03367"></a>03367    {
<a name="l03368"></a>03368    }
<a name="l03369"></a>03369    <span class="keywordflow">else</span> <span class="keywordflow">if</span>(layers_number == 1)
<a name="l03370"></a>03370    {
<a name="l03371"></a>03371       buffer &lt;&lt; <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#ea970635dd856cb0f9acdf458177312b">layers</a>[0].write_expression(inputs_name, outputs_name) &lt;&lt; <span class="stringliteral">"\n"</span>;        
<a name="l03372"></a>03372    }
<a name="l03373"></a>03373    <span class="keywordflow">else</span>
<a name="l03374"></a>03374    {
<a name="l03375"></a>03375       <a class="code" href="class_open_n_n_1_1_vector.html">Vector&lt; Vector&lt;std::string&gt;</a> &gt; layers_outputs_name(layers_number);
<a name="l03376"></a>03376 
<a name="l03377"></a>03377       <span class="keywordflow">for</span>(<span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> i = 0; i &lt; layers_number; i++)
<a name="l03378"></a>03378       {
<a name="l03379"></a>03379          layers_outputs_name[i].<a class="code" href="class_open_n_n_1_1_vector.html#78a81ff993befcd4e75ab75da2976a9a" title="This method sets the size of a vector to zero.">set</a>(layers_perceptrons_number[i]);
<a name="l03380"></a>03380 
<a name="l03381"></a>03381          <span class="keywordflow">for</span>(<span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> j = 0; j &lt; layers_perceptrons_number[i]; j++)
<a name="l03382"></a>03382          {
<a name="l03383"></a>03383             std::ostringstream new_buffer;
<a name="l03384"></a>03384             new_buffer &lt;&lt; <span class="stringliteral">"y_"</span> &lt;&lt; i+1 &lt;&lt; <span class="stringliteral">"_"</span> &lt;&lt; j+1;
<a name="l03385"></a>03385             layers_outputs_name[i][j] = new_buffer.str();
<a name="l03386"></a>03386          }
<a name="l03387"></a>03387       }
<a name="l03388"></a>03388 
<a name="l03389"></a>03389       buffer &lt;&lt; <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#ea970635dd856cb0f9acdf458177312b">layers</a>[0].write_expression(inputs_name, layers_outputs_name[0]);        
<a name="l03390"></a>03390    
<a name="l03391"></a>03391       <span class="keywordflow">for</span>(<span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> i = 1; i &lt; layers_number-1; i++)
<a name="l03392"></a>03392       {
<a name="l03393"></a>03393          buffer &lt;&lt; <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#ea970635dd856cb0f9acdf458177312b">layers</a>[i].write_expression(layers_outputs_name[i-1], layers_outputs_name[i]);      
<a name="l03394"></a>03394       }
<a name="l03395"></a>03395 
<a name="l03396"></a>03396       buffer &lt;&lt; <a class="code" href="class_open_n_n_1_1_multilayer_perceptron.html#ea970635dd856cb0f9acdf458177312b">layers</a>[layers_number-1].write_expression(layers_outputs_name[layers_number-2], outputs_name); 
<a name="l03397"></a>03397    }
<a name="l03398"></a>03398 
<a name="l03399"></a>03399    <span class="keywordflow">return</span>(buffer.str());
<a name="l03400"></a>03400 }
<a name="l03401"></a>03401 
<a name="l03402"></a>03402 }
<a name="l03403"></a>03403 
<a name="l03404"></a>03404 <span class="comment">// OpenNN: Open Neural MultilayerPerceptrons Library.</span>
<a name="l03405"></a>03405 <span class="comment">// Copyright (C) 2005-2012 Roberto Lopez </span>
<a name="l03406"></a>03406 <span class="comment">//</span>
<a name="l03407"></a>03407 <span class="comment">// This library is free software; you can redistribute it and/or</span>
<a name="l03408"></a>03408 <span class="comment">// modify it under the terms of the GNU Lesser General Public</span>
<a name="l03409"></a>03409 <span class="comment">// License as published by the Free Software Foundation; either</span>
<a name="l03410"></a>03410 <span class="comment">// version 2.1 of the License, or any later version.</span>
<a name="l03411"></a>03411 <span class="comment">//</span>
<a name="l03412"></a>03412 <span class="comment">// This library is distributed in the hope that it will be useful,</span>
<a name="l03413"></a>03413 <span class="comment">// but WITHOUT ANY WARRANTY; without even the implied warranty of</span>
<a name="l03414"></a>03414 <span class="comment">// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU</span>
<a name="l03415"></a>03415 <span class="comment">// Lesser General Public License for more details.</span>
<a name="l03416"></a>03416 
<a name="l03417"></a>03417 <span class="comment">// You should have received a copy of the GNU Lesser General Public</span>
<a name="l03418"></a>03418 <span class="comment">// License along with this library; if not, write to the Free Software</span>
<a name="l03419"></a>03419 <span class="comment">// Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA  02110-1301  USA</span>
</pre></div></div>
<hr size="1"><address style="text-align: right;"><small>Generated on Sun Aug 26 11:58:12 2012 for OpenNN by&nbsp;
<a href="http://www.doxygen.org/index.html">
<img src="doxygen.png" alt="doxygen" align="middle" border="0"></a> 1.5.9 </small></address>
</body>
</html>
